{"cells":[{"cell_type":"markdown","source":["# NCDR LAAO v1.3 & v1.4 Data Merge\n","This notebook uses the raw data exports from the NCDR system and merges the v1.3 & v1.4 versions together and create delta tables to push into a structured warehouse environment."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"69468b98-31e5-473d-ba47-77c7d89afa7f"},{"cell_type":"markdown","source":["## Required Packages"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f3d75b4a-8ea9-4869-a95c-62a7252d31eb"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, LongType, TimestampType, DoubleType\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":357,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:38.7486474Z","session_start_time":null,"execution_start_time":"2024-03-06T17:07:39.0955788Z","execution_finish_time":"2024-03-06T17:07:39.3119068Z","parent_msg_id":"938533c7-942d-42cd-b2c3-7e4820b0f445"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 357, Finished, Available)"},"metadata":{}}],"execution_count":355,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"93a7b3f3-96b8-40fa-9b3b-b1362378ca57"},{"cell_type":"markdown","source":["# v1.3 Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1ef90af5-8659-4733-81cb-1247c8c62e0c"},{"cell_type":"markdown","source":["### In-hospital Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"59107c9c-8c2d-4ff5-99db-617e3b4213ac"},{"cell_type":"code","source":["# import from Lakehouse file upload\n","# seperate each XLSX sheet\n","# add facility column with NCDR PID & custom column with hardocded natural key (Pat_ID)\n","# append multiple sheets into dataframes in a dictionary \n","\n","def read_excel_and_process_sheets(file_path):\n","    facility_code = file_path.split('/')[-1][4:10]\n","    sheets_dict = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')\n","    mrn_columns = ['OtherID']\n","    \n","    for sheet_name, df in sheets_dict.items():\n","        df['facility'] = facility_code\n","        \n","        for column in mrn_columns:\n","            if column in df.columns:\n","                df[column] = df[column].apply(str)\n","                \n","        # Ensure 'ArrivalDate' is in datetime format before formatting\n","        if 'ArrivalDate' in df.columns:\n","            df['ArrivalDate'] = pd.to_datetime(df['ArrivalDate'], errors='coerce')  # Convert to datetime, coercing errors\n","            df['ArrivalDate'] = df['ArrivalDate'].dt.strftime('%Y-%m-%d')  # Then format to string\n","        \n","        # Ensure 'NCDRPatientID' is string\n","        if 'NCDRPatientID' in df.columns:\n","            df['NCDRPatientID'] = df['NCDRPatientID'].astype(str)\n","        \n","        # Create 'Pat_ID'\n","        if 'NCDRPatientID' in df.columns and 'ArrivalDate' in df.columns:\n","            df['Pat_ID'] = df['NCDRPatientID'] + '_' + df['ArrivalDate'] + '_' + df['facility']\n","        \n","        sheets_dict[sheet_name] = df\n","    \n","    return sheets_dict\n","\n","def append_sheets_from_multiple_files(file_paths):\n","    all_sheets = {}\n","    \n","    for file_path in file_paths:\n","        sheets_dict = read_excel_and_process_sheets(file_path)\n","        \n","        for sheet_name, df in sheets_dict.items():\n","            if sheet_name in all_sheets:\n","                all_sheets[sheet_name] = pd.concat([all_sheets[sheet_name], df], ignore_index=True)\n","            else:\n","                all_sheets[sheet_name] = df\n","                \n","    return all_sheets\n","\n","# Example usage\n","file_paths = [\"/lakehouse/default/Files/LAAO/Version_1_3/LAAO136983-In-hospital-112017PAS.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO197501-In-hospital-112017SHY.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO410079-In-hospital-112017HAM.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO468377-In-hospital-112017ALT.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO697322-In-hospital-112017PUH.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO799953-In-hospital-112017PIN.xlsx\"]\n","\n","all_sheets_appended = append_sheets_from_multiple_files(file_paths)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":358,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:39.4143875Z","session_start_time":null,"execution_start_time":"2024-03-06T17:07:39.7370288Z","execution_finish_time":"2024-03-06T17:07:49.7039786Z","parent_msg_id":"05ac840a-5174-44fd-b7d7-2663185fbfb5"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 358, Finished, Available)"},"metadata":{}}],"execution_count":356,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"edfe20c8-430e-47c7-ba5e-1cc17cf5e7fa"},{"cell_type":"markdown","source":["### Follow up Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"80f6d4a3-5aa7-4376-90af-ca35f51fca77"},{"cell_type":"code","source":["# import from Lakehouse file upload\n","# seperate each XLSX sheet\n","# add facility column with NCDR PID & custom column with hardocded natural key (Pat_ID)\n","# append multiple sheets into dataframes in a dictionary \n","\n","def read_excel_and_process_sheets(file_path):\n","    \"\"\"\n","    Reads each sheet from an Excel file into a pandas DataFrame,\n","    adds a 'facility' column based on the file title, and stores them in a dictionary.\n","    \"\"\"\n","    # Extract facility code from the file title\n","    facility_code = file_path.split('/')[-1][4:10]  # Adjust based on your filenames\n","    \n","    # Read the Excel file into a dict of DataFrames\n","    sheets_dict = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')\n","    \n","    # Process each sheet\n","    for sheet_name, df in sheets_dict.items():\n","        df['facility'] = facility_code\n","        sheets_dict[sheet_name] = df\n","\n","        # Ensure 'ArrivalDate' is in datetime format before formatting\n","        if 'ArrivalDate' in df.columns:\n","            df['ArrivalDate'] = pd.to_datetime(df['ArrivalDate'], errors='coerce')  # Convert to datetime, coercing errors\n","            df['ArrivalDate'] = df['ArrivalDate'].dt.strftime('%Y-%m-%d')  # Then format to string\n","        \n","        # Ensure 'NCDRPatientID' is string\n","        if 'NCDRPatientID' in df.columns:\n","            df['NCDRPatientID'] = df['NCDRPatientID'].astype(str)\n","        \n","        # Create 'Pat_ID'\n","        if 'NCDRPatientID' in df.columns and 'ArrivalDate' in df.columns:\n","            df['Pat_ID'] = df['NCDRPatientID'] + '_' + df['ArrivalDate'] + '_' + df['facility']\n","\n","    return sheets_dict\n","\n","def append_sheets_from_multiple_files(file_paths_FU):\n","    \"\"\"\n","    Processes multiple Excel files, appending sheets with the same name across files.\n","    \"\"\"\n","    all_sheets = {}  # Dictionary to store appended sheets\n","    \n","    for file_path in file_paths_FU:\n","        # Process each file\n","        sheets_dict = read_excel_and_process_sheets(file_path)\n","        \n","        # Append sheets with the same name\n","        for sheet_name, df in sheets_dict.items():\n","            if sheet_name in all_sheets:\n","                all_sheets[sheet_name] = pd.concat([all_sheets[sheet_name], df], ignore_index=True)\n","            else:\n","                all_sheets[sheet_name] = df\n","                \n","    return all_sheets\n","\n","\n","# Example usage\n","file_paths_FU = [\"/lakehouse/default/Files/LAAO/Version_1_3/LAAO136983-Follow-up-112017PAS.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO197501-Follow-up-112017SHY.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO410079-Follow-up-112017HAM.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO468377-Follow-up-112017ALT.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO697322-Follow-up-112017PUH.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_3/LAAO799953-Follow-up-112017PIN.xlsx\"]\n","\n","all_sheets_appended_FU = append_sheets_from_multiple_files(file_paths_FU)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":359,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:40.358277Z","session_start_time":null,"execution_start_time":"2024-03-06T17:07:50.0249363Z","execution_finish_time":"2024-03-06T17:07:57.9085981Z","parent_msg_id":"a4d28595-14d0-46c4-85e8-91ed8c9c3532"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 359, Finished, Available)"},"metadata":{}}],"execution_count":357,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e002f4ad-ee91-4c9c-91a1-9ef000687804"},{"cell_type":"markdown","source":["## Feature Engineering\n","To align with v1.4 structure"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0c4598b9-68e3-4fb3-8821-0eed65e31fd7"},{"cell_type":"markdown","source":["### ProcedureStartDateTime In-Hospital"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3b11ea28-6f53-4885-abac-0e841200234b"},{"cell_type":"code","source":["# ProcedureStartDateTime (merges ProcedureStartDate and ProcedureStartTime across all dataframes)\n","\n","def combine_date_time(row):\n","    try:\n","        # Ensure the date is in datetime format\n","        date = pd.to_datetime(row['ProcedureStartDate'])\n","        \n","        # Explicitly format ProcedureStartTime as a string in case it's not\n","        time_str = str(row['ProcedureStartTime'])\n","        \n","        # Convert the time string to timedelta\n","        time_delta = pd.to_timedelta(time_str)\n","        \n","        # Combine the date and time into a single datetime object\n","        return date + time_delta\n","    except Exception as e:\n","        # Print row information to help diagnose the issue\n","        print(f\"Error processing row: {row}\")\n","        print(f\"Exception: {e}\")\n","        # Return a default value or handle the error as appropriate\n","        return pd.NaT\n","\n","# Apply the conversion and update the DataFrame\n","for sheet_name, df in all_sheets_appended.items():\n","    if 'ProcedureStartDate' in df.columns and 'ProcedureStartTime' in df.columns:\n","        df['ProcedureStartDateTime'] = df.apply(combine_date_time, axis=1)\n","        df.drop(columns=['ProcedureStartDate', 'ProcedureStartTime'], inplace=True)\n","        all_sheets_appended[sheet_name] = df\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":360,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:41.703361Z","session_start_time":null,"execution_start_time":"2024-03-06T17:07:58.2554517Z","execution_finish_time":"2024-03-06T17:07:58.9930104Z","parent_msg_id":"bab3146e-556e-43ea-9491-e633c1051b9d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 360, Finished, Available)"},"metadata":{}}],"execution_count":358,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b4196873-4d71-4bf6-bff3-8185cf11e0ba"},{"cell_type":"markdown","source":["### ProcedureStopDateTime In-Hospital"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f2f7221b-ed02-42d4-838c-e8fb53d3ceb6"},{"cell_type":"code","source":["# ProcedureStopDateTime (merges ProcedureStopDate and ProcedureStopTime across all dataframes)\n","\n","def combine_date_time(row):\n","    try:\n","        # Ensure the date is in datetime format\n","        date = pd.to_datetime(row['ProcedureStopDate'])\n","        \n","        # Explicitly format ProcedureStartTime as a string in case it's not\n","        time_str = str(row['ProcedureStopTime'])\n","        \n","        # Convert the time string to timedelta\n","        time_delta = pd.to_timedelta(time_str)\n","        \n","        # Combine the date and time into a single datetime object\n","        return date + time_delta\n","    except Exception as e:\n","        # Print row information to help diagnose the issue\n","        print(f\"Error processing row: {row}\")\n","        print(f\"Exception: {e}\")\n","        # Return a default value or handle the error as appropriate\n","        return pd.NaT\n","\n","# Apply the conversion and update the DataFrame\n","for sheet_name, df in all_sheets_appended.items():\n","    if 'ProcedureStopDate' in df.columns and 'ProcedureStopTime' in df.columns:\n","        df['ProcedureStopDateTime'] = df.apply(combine_date_time, axis=1)\n","        df.drop(columns=['ProcedureStopDate', 'ProcedureStopTime'], inplace=True)\n","        all_sheets_appended[sheet_name] = df\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":361,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:42.1099479Z","session_start_time":null,"execution_start_time":"2024-03-06T17:07:59.3404664Z","execution_finish_time":"2024-03-06T17:08:00.0749262Z","parent_msg_id":"04e24e02-3c04-466c-b676-544b214281ac"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 361, Finished, Available)"},"metadata":{}}],"execution_count":359,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"f9f03ba9-19d7-4a1d-9cbf-8ceda7cd6338"},{"cell_type":"markdown","source":["### ProcedureStartDate & PrcocedureStartTime Follow-up"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"303683e0-4e96-49a1-9f1f-cf62b4bce480"},{"cell_type":"code","source":["# ProcedureStartDateTime (merges ProcedureStartDate and ProcedureStartTime across all dataframes)\n","\n","def combine_date_time(row):\n","    try:\n","        # Ensure the date is in datetime format\n","        date = pd.to_datetime(row['ProcedureStartDate'])\n","        \n","        # Explicitly format ProcedureStartTime as a string in case it's not\n","        time_str = str(row['ProcedureStartTime'])\n","        \n","        # Convert the time string to timedelta\n","        time_delta = pd.to_timedelta(time_str)\n","        \n","        # Combine the date and time into a single datetime object\n","        return date + time_delta\n","    except Exception as e:\n","        # Print row information to help diagnose the issue\n","        print(f\"Error processing row: {row}\")\n","        print(f\"Exception: {e}\")\n","        # Return a default value or handle the error as appropriate\n","        return pd.NaT\n","\n","# Apply the conversion and update the DataFrame\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    if 'ProcedureStartDate' in df.columns and 'ProcedureStartTime' in df.columns:\n","        df['RefProcStartDateTime'] = df.apply(combine_date_time, axis=1)\n","        df.drop(columns=['ProcedureStartDate', 'ProcedureStartTime'], inplace=True)\n","        all_sheets_appended_FU[sheet_name] = df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":362,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:42.6046829Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:00.417423Z","execution_finish_time":"2024-03-06T17:08:01.854671Z","parent_msg_id":"85279e90-5ade-4770-9b4f-dbf999482c87"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 362, Finished, Available)"},"metadata":{}}],"execution_count":360,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4511dce8-31aa-4aea-a61a-271f157b9962"},{"cell_type":"markdown","source":["### ProcedureStopDateTime Follow-up"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9362a1a8-d03a-4bb8-b55d-ceaab68c9c8f"},{"cell_type":"code","source":["# ProcedureStopDateTime (merges ProcedureStopDate and ProcedureStopTime across all dataframes)\n","\n","def combine_date_time(row):\n","    try:\n","        # Ensure the date is in datetime format\n","        date = pd.to_datetime(row['ProcedureStopDate'])\n","        \n","        # Explicitly format ProcedureStartTime as a string in case it's not\n","        time_str = str(row['ProcedureStopTime'])\n","        \n","        # Convert the time string to timedelta\n","        time_delta = pd.to_timedelta(time_str)\n","        \n","        # Combine the date and time into a single datetime object\n","        return date + time_delta\n","    except Exception as e:\n","        # Print row information to help diagnose the issue\n","        print(f\"Error processing row: {row}\")\n","        print(f\"Exception: {e}\")\n","        # Return a default value or handle the error as appropriate\n","        return pd.NaT\n","\n","# Apply the conversion and update the DataFrame\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    if 'ProcedureStopDate' in df.columns and 'ProcedureStopTime' in df.columns:\n","        df['ProcedureStopDateTime'] = df.apply(combine_date_time, axis=1)\n","        df.drop(columns=['ProcedureStopDate', 'ProcedureStopTime'], inplace=True)\n","        all_sheets_appended_FU[sheet_name] = df\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":363,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:43.1919867Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:02.1925951Z","execution_finish_time":"2024-03-06T17:08:02.9385346Z","parent_msg_id":"e98c48c1-f12a-4d47-b998-5da0919c412c"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 363, Finished, Available)"},"metadata":{}}],"execution_count":361,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2542ad8f-9f08-46f2-9a33-5ac7c945215f"},{"cell_type":"markdown","source":["### Add HispOrig"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"04b1b8a9-4375-4fc5-a687-5a14201bbbf3"},{"cell_type":"code","source":["# HisOrig (converting 'HispEthnicityMexican','HispEthnicityPuertoRico', 'HispEthnicityCuban', \n","#'HispEthnicityOtherOrigin' columns into v1.4 compatability)\n","\n","def HispOrig(row):\n","    if row['HispEthnicityMexican'] == 'Yes':\n","        return 'Yes'\n","    elif row['HispEthnicityPuertoRico'] == 'Yes':\n","        return 'Yes'\n","    elif row ['HispEthnicityCuban'] == 'Yes':\n","        return 'Yes'\n","    elif row ['HispEthnicityOtherOrigin'] == 'Yes':\n","        return 'Yes'\n","    else:\n","        return 'No'\n","\n","#apply the function to each row to create a new column\n","all_sheets_appended['In-hospital']['HispOrig'] = all_sheets_appended['In-hospital'].apply(HispOrig, axis=1)\n","\n","# Drop the old columns from the 'In-hospital' DataFrame\n","all_sheets_appended['In-hospital'] = all_sheets_appended['In-hospital']\n","\n","# Display the head of the DataFrame to verify the new column\n","print(all_sheets_appended['In-hospital'].head())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":364,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:43.683477Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:03.267704Z","execution_finish_time":"2024-03-06T17:08:03.5070924Z","parent_msg_id":"7d15919f-e12f-46eb-807f-c2fc056054b8"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 364, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  NCDRPatientID  LastName FirstName MidName    OtherID          SSN SSNNA  \\\n0       1185318     SMITH     Basil       J  784565935  197422513.0    No   \n1       3903583    PEALER   MICHAEL       L  785314254          NaN   Yes   \n2       4914526    DISHER       JON       E  980510965          NaN   Yes   \n3       6087603  Stafford    Lonnie       L  970579558          NaN   Yes   \n4       6087684  Grealish    Robert       J  784976049          NaN   Yes   \n\n         DOB     Sex RaceWhite  ... ADJ_BleedDevRelated  \\\n0 1951-03-21    Male       Yes  ...                 NaN   \n1 1949-07-04    Male       Yes  ...                 NaN   \n2 1944-01-18    Male       Yes  ...                 NaN   \n3 1943-10-11  Female       Yes  ...                 NaN   \n4 1949-09-10    Male       Yes  ...                 NaN   \n\n  ADJ_SysThromboAdjStatus ADJ_SysThromboDeathDate ADJ_SysThromboDeathCause  \\\n0                     NaN                     NaN                      NaN   \n1                     NaN                     NaN                      NaN   \n2                     NaN                     NaN                      NaN   \n3                     NaN                     NaN                      NaN   \n4                     NaN                     NaN                      NaN   \n\n  ADJ_SysThromboHypoperfusion facility                     Pat_ID  \\\n0                         NaN   136983  1185318_2021-02-09_136983   \n1                         NaN   136983  3903583_2022-07-19_136983   \n2                         NaN   136983  4914526_2020-12-01_136983   \n3                         NaN   136983  6087603_2019-10-29_136983   \n4                         NaN   136983  6087684_2019-11-19_136983   \n\n  ProcedureStartDateTime ProcedureStopDateTime HispOrig  \n0    2021-02-09 11:55:00   2021-02-09 14:10:00       No  \n1    2022-07-19 10:47:00   2022-07-19 11:36:00       No  \n2    2020-12-01 11:56:00   2020-12-01 13:08:00       No  \n3    2019-10-29 07:55:00   2019-10-29 10:30:00       No  \n4    2019-11-19 12:56:00   2019-11-19 15:16:00       No  \n\n[5 rows x 202 columns]\n"]}],"execution_count":362,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7fd546c9-11c8-46bc-86d4-c5c596a40758"},{"cell_type":"markdown","source":["### DevSucdep"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4612f663-b292-4182-9d6d-15064cad122e"},{"cell_type":"code","source":["# DevSucdep (converting 'DeviceOutcome' column into v1.4 compatability)\n","\n","def devsucdep(row):\n","    if row['DeviceOutcome'] == 'Deployed, not released':\n","        return 'No'\n","    elif row['DeviceOutcome'] == 'Device retrieved':\n","        return 'No'\n","    elif row ['DeviceOutcome'] == 'Not Deployed':\n","        return 'No'\n","    elif row ['DeviceOutcome'] == 'Deployed, released':\n","        return 'Yes'\n","    else:\n","        return 'No'\n","\n","#apply the function to each row to create a new column\n","all_sheets_appended['AccessSysID']['DevSucdep'] = all_sheets_appended['AccessSysID'].apply(devsucdep, axis=1)\n","\n","# Drop the old columns from the 'AccessSysID' DataFrame\n","all_sheets_appended['AccessSysID'] = all_sheets_appended['AccessSysID']\n","\n","# Display the head of the DataFrame to verify the new column\n","print(all_sheets_appended['AccessSysID'].head())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":365,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:44.2283994Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:03.8399084Z","execution_finish_time":"2024-03-06T17:08:04.0723612Z","parent_msg_id":"3f58ef81-5816-4484-b806-41f24e5c9cca"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 365, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  NCDRPatientID LastName FirstName MidName    OtherID ArrivalDate     DCDate  \\\n0       1185318    SMITH     Basil       J  784565935  2021-02-09 2021-02-10   \n1       1185318    SMITH     Basil       J  784565935  2021-02-09 2021-02-10   \n2       1185318    SMITH     Basil       J  784565935  2021-02-09 2021-02-10   \n3       3903583   PEALER   MICHAEL       L  785314254  2022-07-19 2022-07-20   \n4       4914526   DISHER       JON       E  980510965  2020-12-01 2020-12-02   \n\n   AccessSysCounter                                      AccessSysID  \\\n0                 1  WATCHMAN TruSeal Double Curve 14F Access System   \n1                 1  WATCHMAN TruSeal Double Curve 14F Access System   \n2                 1  WATCHMAN TruSeal Double Curve 14F Access System   \n3                 1  WATCHMAN TruSeal Double Curve 14F Access System   \n4                 1  WATCHMAN TruSeal Double Curve 14F Access System   \n\n   DevCounter                               LAADevID  Dev_UDIDirectID  \\\n0           1  35 mm WATCHMAN FLX LAA Closure Device              NaN   \n1           2  31 mm WATCHMAN FLX LAA Closure Device              NaN   \n2           3       30mm WATCHMAN LAA Closure Device              NaN   \n3           1  24 mm WATCHMAN FLX LAA Closure Device              NaN   \n4           1  24 mm WATCHMAN FLX LAA Closure Device              NaN   \n\n  LAAIsolationApproach       DeviceOutcome facility  \\\n0         Percutaneous    Device retrieved   136983   \n1         Percutaneous    Device retrieved   136983   \n2         Percutaneous    Device retrieved   136983   \n3         Percutaneous  Deployed, released   136983   \n4         Percutaneous  Deployed, released   136983   \n\n                      Pat_ID ProcedureStartDateTime ProcedureStopDateTime  \\\n0  1185318_2021-02-09_136983    2021-02-09 11:55:00   2021-02-09 14:10:00   \n1  1185318_2021-02-09_136983    2021-02-09 11:55:00   2021-02-09 14:10:00   \n2  1185318_2021-02-09_136983    2021-02-09 11:55:00   2021-02-09 14:10:00   \n3  3903583_2022-07-19_136983    2022-07-19 10:47:00   2022-07-19 11:36:00   \n4  4914526_2020-12-01_136983    2020-12-01 11:56:00   2020-12-01 13:08:00   \n\n  DevSucdep  \n0        No  \n1        No  \n2        No  \n3       Yes  \n4       Yes  \n"]}],"execution_count":363,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1b12bb4e-6445-4a48-99d6-122e93bcaeca"},{"cell_type":"markdown","source":["### OutDevUnsucDepl"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"68f7d4da-c3e3-433f-b337-8a3b4cc174ef"},{"cell_type":"code","source":["# OutDevUnsucDepl (converting 'DeviceOutcome' column into v1.4 compatability)\n","\n","def OutDevUnsucDepl(row):\n","    if row['DeviceOutcome'] == 'Deployed, not released':\n","        return 'Deployed, not released'\n","    elif row['DeviceOutcome'] == 'Device retrieved':\n","        return 'Device retrieved'\n","    elif row ['DeviceOutcome'] == 'Not Deployed':\n","        return 'Not Deployed'\n","    else:\n","        return np.nan\n","\n","#apply the function to each row to create a new column\n","all_sheets_appended['AccessSysID']['OutDevUnsucDepl'] = all_sheets_appended['AccessSysID'].apply(OutDevUnsucDepl, axis=1)\n","\n","# Drop the old columns from the 'AccessSysID' DataFrame\n","all_sheets_appended['AccessSysID'] = all_sheets_appended['AccessSysID']\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":366,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:45.1734436Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:04.4442091Z","execution_finish_time":"2024-03-06T17:08:04.6752899Z","parent_msg_id":"d4eddc41-9baa-4295-a56f-8d565714d0aa"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 366, Finished, Available)"},"metadata":{}}],"execution_count":364,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"57dca4a7-1e31-4541-b6b5-415b69c7b9a5"},{"cell_type":"markdown","source":["## Rename Columns to Match v1.4\n","Includes labeling columns that are retired by noting which version they were retired with (i.e. \"1_3\" for version 1.3)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f8bbed72-7443-4e06-8ae6-1cc664932301"},{"cell_type":"code","source":["# Mapping of old column names to new column names\n","# Mappings for renaming\n","column_name_mapping_canceled = {\n","    'Anatomy not conducive for implant': 'ProcCanceledReason - Anatomy not conducive for implant',\n","    'Appendage too large (for device implant)': 'ProcCanceledReason - Appendage too large (for device implant)',\n","    'Appendage too small (for device implant)': 'ProcCanceledReason - Appendage too small (for device implant)',\n","    'Catheterization challenge': 'ProcCanceledReason - Catherization challenge',\n","    'Decompensation in patient condition': 'ProcCanceledReason - Decompensation in patient condition',\n","    'Epicardial access issue': 'ProcCanceledReason - Epicardial access issue',\n","    'Thrombus detected': 'ProcCanceledReason - Thrombus detected',\n","    'Unanticipated patient condition': 'ProcCanceledReason - Unanticipated patient condition',\n","    'Patient/Family choice': 'ProcCanceledReason -  Patient/Family choice'\n","}\n","\n","column_name_mapping_aborted = {\n","    'Anatomy not conducive for implant': 'ProcAbortedReason - Anatomy not conducive for implant',\n","    'Appendage too large (for device implant)': 'ProcAbortedReason - Appendage too large (for device implant)',\n","    'Appendage too small (for device implant)': 'ProcAbortedReason - Appendage too small (for device implant)',\n","    'Catheterization challenge': 'ProcAbortedReason - Catherization challenge',\n","    'Decompensation in patient condition': 'ProcAbortedReason - Decompensation in patient condition',\n","    'Device related': 'ProcAbortedReason -  Device related',\n","    'Transcatheter device retrieval': 'ProcAbortedReason - Transcatheter device retrieval',\n","    'Device release criteria not met': 'ProcAbortedReason - Device release criteria not met',\n","    'Epicardial access issue': 'ProcAbortedReason - Epicardial access issue',\n","    'Surgical device retrieval': 'ProcAbortedReason - Surgical device retrieval',\n","    'Device associated thrombus developed during procedure': 'ProcAbortedReason - Device associated thrombus developed during procedure',\n","    'Unanticipated patient condition': 'ProcAbortedReason - Unanticipated patient condition',\n","    'Patient/Family choice': 'ProcAbortedReason - Patient/Family choice'\n","}\n","\n","other_mapping = {\n","    'LAAOAdmission': 'LAAO_Adm',\n","    'IncreasedFallRisk': 'IncrFallRisk',\n","    'ConAntiCoagTherapy': 'ConAntiCoagTx',\n","    'AtrialFib': 'AFibInd',\n","    'AFibPriorAblStrategy': 'AFibPriorAblStrategyCode',\n","    'StrucIntervention': 'CardStrucInterv',\n","    'StrucInterventionType': 'CardStrucIntervType',\n","    'LAAIntervention': 'LAAOInterv',\n","    'LAAInterventionType': 'LAAOType',\n","    'EpicardialApproach': 'EpicardialAppCons',\n","    'EpiADLupus': 'LupusCons',\n","    'IEPerformed': 'ICEPerf',\n","    'AlbuminND': 'Albumin_ND',\n","    'PLTCount': 'PlateletCt',\n","    'PLTCountND': 'PlateletCtND',\n","    'RankinScaleNA': 'PostProc_RankinScaleNA',\n","    'MedAdmin': 'PreMedAdmin',\n","    'ProcTEEPerf': 'TEEPerfLAAO',\n","    'ProcTEEDate': 'TEEDateLAAO',\n","    'LAAOrificeMaxWidth': 'LAAO_OrWid',\n","    'ProcLocation': 'ProcedureLocation',\n","    'OperA_LastName': 'OperA_LastName2',\n","    'OperA_FirstName': 'OperA_FirstName2',\n","    'OperA_MidName': 'OperA_MidName2',\n","    'OperA_NPI': 'OperA_NPI2',\n","    'FluoroDoseDAP': 'FluoroDoseDAP2',\n","    'ProcHeparin': 'ProcHeparin2',\n","    'ProcHeparinInitAdmin': 'ProcHeparinInitAdminTime',\n","    'ProcBivalirudin': 'ProcBivalirudin2',\n","    'ProcOtherAnticoag': 'ProcOtherAnticoag2',\n","    'ProcEventOccurred': 'PostProcOccurred',\n","    'EventID': 'ProcEvents',\n","    'EventDate': 'IntraPostProcEventDate',\n","    'PostProcHgb': 'PostProcHgb2',\n","    'PostProcHgbND': 'PostProcHgbND2',\n","    'PostProcCreat': 'PostProcCreat2',\n","    'PostProcCreatND': 'PostProcCreatND2',\n","    'EOCSurgery': 'Sx_F',\n","    'F_FollowupInterval': 'FUInterv',\n","    'F_LVEFAssessed': 'FU_LVEF',\n","    'F_TTEPerf': 'TTEPerfFU',\n","    'F_TTEDate': 'TTEDate_F',\n","    'F_ResidualLeak': 'ResidualLeakFU',\n","    'F_ResidualLeakNA': 'ResidualLeakNAFU',\n","    'F_Creat': 'Creat_FU',\n","    'F_Hgb': 'LowHgbValue_F',\n","    'F_HgbND': 'HGBND_FU',\n","    'F_RankinScale': 'F_RankinScore',\n","    'F_RankinScaleNA': 'F_mRS_NA',\n","    'F_BIEToiletUse': 'F_BIEToilet',\n","    'F_MedAdmin': 'F_MedAdmin2',\n","    'F_MedDose': 'F_MedDose2',\n","    'F_NOACTherapyDiscontinued': 'F_DOACTherapyDiscontinued',\n","    'F_NOACTherapyDiscontinuedDate': 'F_DOACTherapyDiscontinuedDate',\n","    'F_NOACTherapyResumed': 'F_DOACTherapyResumed',\n","    'F_NOACTherapyResumedDate': 'F_DOACTherapyResumedDate',\n","    'F_FollowupEventOccurred': 'FupEvOccurred',\n","    'F_EventID': 'F_Event',\n","    'F_EventDate': 'FupEventDate',\n","    'F_ADJ_NeuroSxOnset': 'FU_ADJ_NeuroSxOnset',\n","    'F_ADJ_NeuroDeficit': 'FU_ADJ_NeuroDeficit',\n","    'F_ADJ_NeuroClinicPresent': 'FU_ADJ_NeuroClinicPresent',\n","    'F_ADJ_NeuroDxConfirmed': 'FU_ADJ_NeuroDxConfirmed',\n","    'F_ADJ_NeuroBrainImaging': 'FU_ADJ_NeuroBrainImaging',\n","    'F_ADJ_NeuroBrainImagingType': 'FU_ADJ_NeuroBrainImagingType',\n","    'F_ADJ_NeuroDeficitType': 'FU_ADJ_NeuroDeficitType',\n","    'F_ADJ_NeuroIntracranType': 'FU_ADJ_NeuroIntracranType',\n","    'F_ADJ_NeuroIVrTPA': 'FU_ADJ_NeuroIVrTPA',\n","    'F_ADJ_NeuroEndoTheraInter': 'FU_ADJ_NeuroEndoTheraInter',\n","    'F_ADJ_NeuroSxDuration': 'FU_ADJ_NeuroSxDuration',\n","    'F_ADJ_NeuroTrauma': 'FU_ADJ_NeuroTrauma',\n","    'F_ADJ_RankinScale': 'FU_ADJ_RankinScale',\n","    'F_ADJ_RankinScaleNA': 'FU_ADJ_RankinScaleNA',\n","    'F_ADJ_NeuroProcRelated': 'FU_ADJ_NeuroProcRelated',\n","    'F_ADJ_BleedDeathDate': 'FU_ADJ_BleedDeathDate',\n","    'F_ADJ_BleedInvInter': 'FU_ADJ_BleedInvInter',\n","    'F_ADJ_BleedRBCTransfusion': 'FU_ADJ_BleedRBCTransfusion',\n","    'F_ADJ_BleedRBCUnits': 'FU_ADJ_BleedRBCUnits',\n","    'F_ADJ_BleedPreTransHgb': 'FU_ADJ_BleedPreTransHgb',\n","    'F_ADJ_BleedImagePerf': 'FU_ADJ_BleedImagePerf',\n","    'F_ADJ_BleedEndOrganDamage': 'FU_ADJ_BleedEndOrganDamage',\n","    'F_ADJ_BleedPrimaryDC': 'FU_BleedReadm',\n","    'F_ADJ_BleedMajorSurgery': 'FU_ADJ_BleedMajorSurgery',\n","    'F_ADJ_BleedPCI': 'FU_ADJ_BleedPCI',\n","    'F_ADJ_BleedProcRelated': 'FU_ADJ_BleedProcRelated',\n","    'F_ADJ_BleedDevRelated': 'FU_ADJ_BleedDevRelated',\n","    'F_ADJ_MedID': 'FU_ADJ_MedID',\n","    'F_ADJ_MedAdmin': 'FU_ADJ_MedAdmin',\n","    'F_ADJ_SysThromboAdjStatus': 'FU_ADJ_SysThromboAdjStatus',\n","    'F_ADJ_SysThromboHypoperfusion': 'FU_ADJ_SysThromboHypoperfusion',\n","    'F_ADJ_SysThromboImagEvidence': 'FU_ADJ_SysThromboImagEvidence',\n","    'F_ADJ_SysThromboImagMethod': 'FU_ADJ_SysThromboImagMethod',\n","    'F_ADJ_SysThromboTheraInterv': 'FU_ADJ_SysThromboTheraInterv',\n","    'F_ADJ_SysThromboIntervType': 'FU_ADJ_SysThromboIntervType',\n","    'F_AspirinDiscontinued': 'F_AspirinTherapyDiscontinued',\n","    'F_AspirinDiscontinuedDate': 'F_AspirinTherapyDiscontinuedDate',\n","    'F_AspirinResumed': 'F_AspirinTherapyResumed',\n","    'F_AspirinResumedDate': 'F_AspirinTherapyResumedDate',\n","    'F_P2Y12Discontinued': 'F_P2Y12TherapyDiscontinued',\n","    'F_P2Y12DiscontinuedDate': 'F_P2Y12TherapyDiscontinuedDate',\n","    'F_P2Y12Resumed': 'F_P2Y12TherapyResumed',\n","    'F_P2Y12Date': 'F_P2Y12TherapyResumedDate',\n","    'RegistryVer': 'SchemaVersion',\n","    'RaceAsianIndian': 'RaceAsianIndian_RETIRED_1_3',\n","    'RaceChinese': 'RaceChinese_RETIRED_1_3',\n","    'RaceFilipino': 'RaceFilipino_RETIRED_1_3',\n","    'RaceJapanese': 'RaceJapanese_RETIRED_1_3',\n","    'RaceKorean': 'RaceKorean_RETIRED_1_3',\n","    'RaceVietnamese': 'RaceVietnamese_RETIRED_1_3',\n","    'RaceAsianOther': 'RaceAsianOther_RETIRED_1_3',\n","    'RaceNativeHawaii': 'RaceNativeHawaii_RETIRED_1_3',\n","    'RaceGuamChamorro': 'RaceGuamChamorro_RETIRED_1_3',\n","    'RaceSamoan': 'RaceSamoan_RETIRED_1_3',\n","    'RacePacificIslandOther': 'RacePacificIslandOther_RETIRED_1_3',\n","    'HispEthnicityMexican': 'HispEthnicityMexican_RETIRED_1_3',\n","    'HispEthnicityPuertoRico': 'HispEthnicityPuertoRico_RETIRED_1_3',\n","    'HispEthnicityCuban': 'HispEthnicityCuban_RETIRED_1_3',\n","    'HispEthnicityOtherOrigin': 'HispEthnicityOtherOrigin_RETIRED_1_3',\n","    'HIC': 'HIC_RETIRED_1_3',\n","    'PtRestriction': 'PtRestriction_RETIRED_1_3',\n","    'FluoroDoseDAP_Units': 'FluoroDoseDAP2_Units',\n","    'EventOccurred': 'EventOccurred_RETIRED_1_3',\n","    'PostProcMedStrategy_MedID': 'PostProcMedStrategy_MedID_RETIRED_1_3',\n","    'PostProcMedPlanStrategy': 'PostProcMedPlanStrategy_RETIRED_1_3',\n","    'PostProcMedStrategyReason': 'PostProcMedStrategyReason_RETIRED_1_3',\n","    'F_EventOccurred': 'F_EventOccurred_RETIRED_1_3',\n","    'Private Health Insurance': 'HIPS - Private Health Insurance',\n","    'Military Health Care': 'HIPS - Military Health Care',\n","    'State-Specific Plan (non-Medicaid)': 'HIPS - State-Specific Plan (non-Medicaid)',\n","    'Indian Health Service': 'HIPS - Indian Health Service',\n","    'Non-US Insurance': 'HIPS - Non-US Insurance',\n","    'Medicare Advantage': 'HIPS - Medicare Advantage',\n","    'Medicare': 'HIPS - Medicare',\n","    'Medicaid': 'HIPS - Medicaid',\n","    'Myocardial Infarction (MI)': 'PriorVD - Prior Myocardial Infarction (MI)',\n","    'Known Aortic Plaque': 'PriorVD - Known Aortic Plaque',\n","    'Peripheral arterial occlusive disease (PAD)': 'PriorVD - Peripheral Arterial Occlusive Disease (PAD)',\n","    'Coronary artery disease (CAD)': 'PriorVD - Coronary Artery Disease (CAD)*',\n","    'Percutaneous coronary intervention (PCI)': 'PriorVD - Percutaneous Coronary Intervention (PCI)*',\n","    'Coronary artery bypass graft (CABG)': 'PriorVD - Coronary Artery Bypass Graft (CABG)*',\n","    'Carotid disease': 'PriorVD - Carotid Artery Disease*',\n","    'BleedEventType (Intracranial)': 'BleedEventType - Intracranial Bleed',\n","    'BleedEventType (Epistaxis)': 'BleedEventType - Epistaxis',\n","    'BleedEventType (Gastrointestinal)': 'BleedEventType - Gastrointestinal Bleed',\n","    'BleedEventType (Other)': 'BleedEventType - Other',\n","    'Complex Fractionated Atrial Electrogram': 'AFibPriorAblStrategyCode - Complex Fractionated Atrial Electrogram',\n","    'Cryoablation': 'AFibPriorAblStrategyCode - Convergent Procedure',\n","    'Convergent Procedure': 'AFibPriorAblStrategyCode - Cryoablation',\n","    'Empiric LA Linear Lesions': 'AFibPriorAblStrategyCode - Empiric LA Linear Lesions',\n","    'Focal Ablation': 'AFibPriorAblStrategyCode - Focal Ablation',\n","    'Ganglion Plexus Ablation': 'AFibPriorAblStrategyCode - Ganglion Plexus Ablation',\n","    'Pulmonary Vein Isolation': 'AFibPriorAblStrategyCode - Pulmonary Vein Isolation',\n","    'Segmental PV Ablation': 'AFibPriorAblStrategyCode - Segmental PV Ablation',\n","    'Rotor Based Mapping': 'AFibPriorAblStrategyCode - Rotor Based Mapping',\n","    'Wide Area Circumferential Ablation': 'AFibPriorAblStrategyCode - Wide Area Circumferential Ablation',\n","    'Aortic Balloon Valvuloplasty': 'CardStrucIntervType - Aortic Balloon Valvuloplasty',\n","    'Transcatheter Aortic Valve Replacement (TAVR)': 'CardStrucIntervType - Transcatheter Aortic Valve Replacement (TAVR)',\n","    'Aortic Valve Replacement – Surgical': 'CardStrucIntervType - AV Replacement - Surgical',\n","    'Aortic Valve Repair – Surgical': 'CardStrucIntervType - AV Repair - Surgical',\n","    'Mitral Balloon Valvuloplasty': 'CardStrucIntervType - Mitral Balloon Valvuloplasty',\n","    'Transcatheter Mitral Valve Repair (TMVR)': 'CardStrucIntervType -  Transcatheter Mitral Valve Repair (TMVR)',\n","    'Mitral Valve Replacement – Surgical': 'CardStrucIntervType - MV Replacement - Surgical',\n","    'Mitral Valve Repair – Surgical': 'CardStrucIntervType - MV Repair - Surgical',\n","    'Mitral Annuloplasty Ring – Surgical': 'CardStrucIntervType - Mitral Annuloplasty Ring - Surgical',\n","    'Mitral Transcatheter – Valve-in-Valve': 'CardStrucIntervType - Mitral Transcatheter - Valve-in-valve',\n","    'Atrial Septal Defect Closure': 'CardStrucIntervType - ASD Closure',\n","    'Patent Foramen Ovale Closure': 'CardStrucIntervType - PFO Closure',\n","    'Pulmonic Replacement': 'CardStrucIntervType - Pulmonic Replacement',\n","    'Pulmonic Repair': 'CardStrucIntervType - Pulmonic Repair',\n","    'Tricuspid Replacement': 'CardStrucIntervType - Tricuspid Replacement',\n","    'Tricuspid Repair': 'CardStrucIntervType - Tricuspid Repair',\n","    'Epicardial Ligation': 'LAAOType - Epicardial Ligation',\n","    'Percutaneous Occlusion': 'LAAOType - Surgical Amputation',\n","    'Surgical Amputation': 'LAAOType - Surgical Ligation',\n","    'Surgical Closure Device': 'LAAOType - Percutaneous Occlusion',\n","    'Surgical Ligation': 'LAAOType - Surgical Closure Device',\n","    'Surgical Stapling': 'LAAOType - Surgical Stapling',\n","    'Non-ischemic cardiomyopathy': 'PriorCMType - Non-ischemic cardiomyopathy',\n","    'Ischemic cardiomyopathy': 'PriorCMType - Other cardiomyopathy type',\n","    'Restrictive cardiomyopathy': 'PriorCMType - Restrictive cardiomyopathy',\n","    'Hypertrophic cardiomyopathy': 'PriorCMType - Ischemic cardiomyopathy',\n","    'Other Cardiomyopathy Type': 'PriorCMType - Hypertrophic cardiomyopathy',\n","    'HemorrhagicStroke': 'HBStrokeType - Hemorrhagic Stroke',\n","    'IschemicStroke': 'HBStrokeType - Ischemic Stroke',\n","    'UndeterminedStroke': 'HBStrokeType - Undetermined Stroke',\n","    'EpiCardiacSurgery': 'MedCond - Cardiac Surgery', \n","    'EpiPericarditis': 'MedCond - Pericarditis', \n","    'EpiAccess': 'MedCond - Epicardial Access', \n","    'EpiAutoimmuneDisease': 'MedCond - Autoimmune Disease',\n","    'EpiThorRadTherapy': 'MedCond - Thoracic Radiation Therapy', \n","    'EpiPectusExcavatum': 'MedCond - Pectus Excavatum', \n","    'EpiEpigastricSurg': 'MedCond - Epigastric Surgery',\n","    'EpiHepatomegaly': 'MedCond - Hepatomegaly', \n","    'EpiHiatalHernia': 'MedCond - Hiatal Hernia',\n","    'Sinus node rhythm': 'AtrialRhythm - Sinus node rhythm', \n","    'Atrial fibrillation': 'AtrialRhythm - Atrial fibrillation', \n","    'Atrial tachycardia': 'AtrialRhythm - Atrial tachycardia', \n","    'Atrial flutter': 'AtrialRhythm - Atrial flutter', \n","    'Sinus arrest': 'AtrialRhythm - Sinus arrest', \n","    'Atrial paced': 'AtrialRhythm - Atrial paced', \n","    'Undocumented atrial rhythm': 'AtrialRhythm - Not Documented',\n","    'ProcedureStopDateTime' : 'ProcedureEndDateTime',\n","    'High fall risk': 'ProcLAAOInd - High fall risk',\n","    'History of major bleed': 'ProcLAAOInd - History of major bleed',\n","    'Increased thromboembolic stroke risk': 'ProcLAAOInd - Increased thromboembolic stroke risk',\n","    'Labile INR': 'ProcLAAOInd - Labile INR',\n","    'Non-compliance with anticoagulation therapy': 'ProcLAAOInd - Non-compliance with anticoagulation therapy',\n","    'Patient preference': 'ProcLAAOInd - Patient preference',\n","    'Fluoroscopy': 'GuidanceMethodID - Fluoroscopy',\n","    'Intracardiac three dimensional echocardiography': 'GuidanceMethodID - Intracardiac three dimensional echocardiography',\n","    'Electro Anatomic Mapping': 'GuidanceMethodID - Electro Anatomic Mapping',\n","    'Transesophageal Echocardiography (TEE) ': 'GuidanceMethodID - Transesophageal Echocardiogram (TEE)',\n","    'AFib Ablation': 'ConcomitantProcType - AFib Ablation',\n","    'ICD': 'ConcomitantProcType - ICD',\n","    'PCI': 'ConcomitantProcType - PCI',\n","    'TAVR': 'ConcomitantProcType - TAVR',\n","    'TMVR': 'ConcomitantProcType - TMVR',\n","    'ASD Closure Congenital': 'ConcomitantProcType - ASD Closure Congenital',\n","    'ASD Closure Iatrogenic': 'ConcomitantProcType - ASD Closure Iatrogenic',\n","    'PFO Closure Congenital': 'ConcomitantProcType - PFO Closure Congenital',\n","    'F_Method_Office': 'F_Method - Office Visit',\n","    'F_Method_MedRecord': 'F_Method - Medical Records',\n","    'F_Method_MedProvider': 'F_Method - Letter from Medical Provider',\n","    'F_Method_Phone': 'F_Method - Phone Call',\n","    'F_Method_SSFile': 'F_Method - Social Security Death Master File',\n","    'F_Method_Hospital': 'F_Method - Hospitalized',\n","    'F_Method_Other': 'F_Method - Other'\n","}\n","\n","def rename_columns(df, column_mapping):\n","    \"\"\"Function to rename columns for a single DataFrame.\"\"\"\n","    return df.rename(columns=column_mapping)\n","\n","# Example logic for determining which mapping to apply\n","def determine_mapping(sheet_name):\n","    \"\"\"Determine which column mapping to use based on sheet_name or other logic.\"\"\"\n","    if \"canceled\" in sheet_name.lower():\n","        return column_name_mapping_canceled\n","    elif \"aborted\" in sheet_name.lower():\n","        return column_name_mapping_aborted\n","    # Add additional conditions as needed\n","    else:\n","        return other_mapping  # Or return a default mapping if applicable\n","\n","# Apply renaming logic to each DataFrame in the dictionary\n","for sheet_name, df in all_sheets_appended.items():\n","    mapping_to_use = determine_mapping(sheet_name)\n","    if mapping_to_use is not None:\n","        all_sheets_appended[sheet_name] = rename_columns(df, mapping_to_use)\n","\n","# Repeat for any other dictionaries of DataFrames as needed\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    mapping_to_use = determine_mapping(sheet_name)\n","    if mapping_to_use is not None:\n","        all_sheets_appended_FU[sheet_name] = rename_columns(df, mapping_to_use)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":367,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:45.748729Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:05.0469094Z","execution_finish_time":"2024-03-06T17:08:05.2962075Z","parent_msg_id":"b7f2a5d9-3404-4ec2-ba28-962d126d60a5"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 367, Finished, Available)"},"metadata":{}}],"execution_count":365,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0815f022-6804-4018-8b0f-2269e99bb578"},{"cell_type":"markdown","source":["### Rename Specific Followup Columns Seperately"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f5b9a493-9267-4ef1-aa35-b182a1d92be6"},{"cell_type":"code","source":["# Rename Followup ArrivalDate and DischargeDate\n","# seperate because only want follow up tables renamed\n","\n","# Mapping of old column names to new column names\n","column_name_mapping = {\n","    'ArrivalDate': 'FURefArrivalDate', \n","    'DCDate': 'FU_RefDischargeDate'\n","    }\n","\n","# Loop through all DataFrames in the second dictionary and rename columns\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    all_sheets_appended_FU[sheet_name] = rename_columns(df, column_name_mapping)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":368,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:46.3004486Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:05.5655945Z","execution_finish_time":"2024-03-06T17:08:05.7698057Z","parent_msg_id":"321d9bfc-3661-4e4d-bc68-c7d6fe333fd6"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 368, Finished, Available)"},"metadata":{}}],"execution_count":366,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b0deb4f0-76b0-435d-afce-9b1e26fd27bd"},{"cell_type":"markdown","source":["## Write DFs back to files"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f82f613c-ffd9-45d5-98c9-e35947d023e6"},{"cell_type":"markdown","source":["### Adjust any columns that run into conflict with Parquet conversion to string type"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"efdc8e7d-9f89-4734-8d3c-4f4b550a94bb"},{"cell_type":"code","source":["def adjust_column_data_types(df, columns_to_adjust):\n","    \"\"\"\n","    Adjusts the data types of specified columns to string.\n","    \n","    Parameters:\n","    - df: DataFrame to process.\n","    - columns_to_adjust: List of column names to adjust to string type.\n","    \n","    Returns:\n","    - DataFrame with adjusted column types.\n","    \"\"\"\n","    for column in columns_to_adjust:\n","        if column in df.columns:\n","            df[column] = df[column].astype(str)\n","    return df\n","\n","# Specify columns that you know should be treated as strings\n","columns_to_adjust = ['HIC_RETIRED_1_3', 'MBI']\n","\n","# Before writing to Parquet, adjust the data types of specified columns\n","for sheet_name, df in all_sheets_appended.items():\n","    df = adjust_column_data_types(df, columns_to_adjust)  # Adjust data types\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":369,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:46.8107836Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:06.0704741Z","execution_finish_time":"2024-03-06T17:08:06.3174226Z","parent_msg_id":"e34d519a-f4a9-4082-a1fd-2dbaf4bb3970"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 369, Finished, Available)"},"metadata":{}}],"execution_count":367,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"76f120b4-7847-42a4-b4ed-715205583f5e"},{"cell_type":"code","source":["LAKEHOUSE_PATH = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged\"\n","\n","# Function to write DataFrame to parquet\n","def write_dataframe_to_parquet(df, path, filename):\n","    # Construct the full path\n","    full_path = os.path.join(path, filename)\n","    # Write the DataFrame to Parquet\n","    df.to_parquet(full_path, index=False, compression='snappy')\n","\n","# Loop through all DataFrames in the first dictionary and write them to Parquet\n","for sheet_name, df in all_sheets_appended.items():\n","    filename = f\"{sheet_name}.parquet\"  # Construct a filename based on the sheet name\n","    write_dataframe_to_parquet(df, LAKEHOUSE_PATH, filename)\n","\n","# Loop through all DataFrames in the second dictionary and write them to Parquet\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    filename = f\"{sheet_name}.parquet\"  # Construct a filename with a suffix for follow-up sheets\n","    write_dataframe_to_parquet(df, LAKEHOUSE_PATH, filename)\n","\n","# Now, all DataFrames from both dictionaries should be written to your lakehouse in Parquet format.\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":370,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:47.3590628Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:06.6792393Z","execution_finish_time":"2024-03-06T17:08:11.4032662Z","parent_msg_id":"e9bd3ef7-68d6-4657-9e2f-280b8d8e3342"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 370, Finished, Available)"},"metadata":{}}],"execution_count":368,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2918fe99-d68e-46bc-9bfc-12a52d9a3727"},{"cell_type":"markdown","source":["## Clean Data for v1.4 Merge"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ab8ab51d-2dca-4a1c-b94c-e33c717d1603"},{"cell_type":"markdown","source":["### Clean In-Hospital"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"979b9594-a43f-4530-9735-6a7046b99524"},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the data\n","in_hospital_df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\")\n","afib_strategy_df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AFibPriorAblStrategy.parquet\")\n","\n","# Perform a left join on the keys: 'facility', 'OtherID', 'NCDRPatientID'\n","merged_df = pd.merge(in_hospital_df, afib_strategy_df[['facility', 'OtherID', 'NCDRPatientID', 'PrevAFibTermCA']],\n","                     on=['facility', 'OtherID', 'NCDRPatientID'], how='left')\n","\n","# Convert \"LVEF\" from \"68\" to \"0.68\"\n","merged_df['LVEF'] = merged_df['LVEF'].astype(float) / 100\n","\n","# Drop the specified columns from the merged DataFrame\n","columns_to_drop = [\"PrevAFLTerm.1\", \"PrevAFibTermDC.1\"]\n","merged_df = merged_df.drop(columns=columns_to_drop, errors='ignore')\n","\n","# Correctly evaluate the conditions using pandas' `.any(axis=1)` method\n","merged_df['PrevAFibTerm'] = 'No'  # Default value\n","# Combine all conditions using the `|` operator, which acts as an OR operator on pandas Series\n","condition = (\n","    (merged_df['PrevAFibTermPC'] == 'Yes') |\n","    (merged_df['PrevAFibTermDC'] == 'Yes') |\n","    (merged_df['PrevAFibTermSA'] == 'Yes') |\n","    (merged_df['PrevAFibTermCA'] == 'Yes')\n",")\n","# Apply the condition for each row using `.any(axis=1)`\n","merged_df.loc[condition, 'PrevAFibTerm'] = 'Yes'  # Set to 'Yes' if any condition is met\n","\n","\n","# Remove duplicates based on the natural key while keeping the row with the most non-null values (original file ingested had duplicates)\n","def keep_max_non_null_row(df):\n","    return df.loc[df.notnull().sum(axis=1).idxmax()]\n","\n","# Assuming 'ArrivalDate' is a column in your DataFrame. If not, adjust the column names as necessary.\n","merged_df = merged_df.groupby(['NCDRPatientID', 'facility', 'ArrivalDate']).apply(keep_max_non_null_row).reset_index(drop=True)\n","\n","# List of columns to update\n","columns_to_update = [\n","    \"ProcOtherAnticoag2\",\n","    \"ProcBivalirudin2\",\n","    \"ProcHeparin2\",\n","    \"ProcedureLocation\",\n","    \"FluoroDoseDAP2_Units\",\n","    \"Sex\"\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    merged_df[column] = merged_df[column].replace({'Yes': 'Yes - Prescribed', 'No': 'No - Not Prescribed', 'Cath Lab': 'Cardiac Catheterization Laboratory',\n","    'Hybrid OR': 'Hybrid Operating Room Suite', 'Hybrid Cath Lab': 'Hybrid Catheterization Laboratory Suite',\n","    'cGy-cm2': 'cGy·cm²', 'Gy-cm2': 'Gy·cm²', 'mGy-cm2': 'mGy·cm²', 'dGy-cm2': 'dGy·cm²', 'µGy-M2': 'µGy·cm²', 'Female': 'F', 'Male': 'M'})\n","\n","# Overwrite the original file with the modified data\n","merged_df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\", index=False)\n","\n","print(\"File has been successfully modified.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":371,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:47.9464034Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:11.7405715Z","execution_finish_time":"2024-03-06T17:08:15.2015818Z","parent_msg_id":"88ba2745-a5ef-4f89-beaa-d1437a102f2e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 371, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully modified.\n"]}],"execution_count":369,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8411ab25-f292-4082-837b-bf3302411648"},{"cell_type":"markdown","source":["### Clean HIPS"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f5970810-1421-45dd-bfb5-92d350147b1d"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/HIPS.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    \"HIPS - Private Health Insurance\",\n","    \"HIPS - Medicare\",\n","    \"HIPS - Medicare Advantage\",\n","    \"HIPS - Medicaid\",\n","    \"HIPS - Military Health Care\",\n","    \"HIPS - State-Specific Plan (non-Medicaid)\",\n","    \"HIPS - Indian Health Service\",\n","    \"HIPS - Non-US Insurance\"\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/HIPS.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":372,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:48.4952175Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:15.5643531Z","execution_finish_time":"2024-03-06T17:08:16.3176703Z","parent_msg_id":"6becb85e-08db-410f-ac13-3ca108a76c3f"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 372, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":370,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"34122629-97d6-42fc-a254-46e640547c22"},{"cell_type":"markdown","source":["### Clean BleedEventType"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4ac364f2-e3ab-4c86-b000-2d482d05e095"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/BleedEventType.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    \"BleedEventType - Intracranial Bleed\",\n","    \"BleedEventType - Epistaxis\",\n","    \"BleedEventType - Gastrointestinal Bleed\",\n","    \"BleedEventType - Other\"\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/BleedEventType.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":373,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:49.0252508Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:16.6096221Z","execution_finish_time":"2024-03-06T17:08:17.3424392Z","parent_msg_id":"e558685d-cfa0-47e5-8917-75706fe6b952"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 373, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":371,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b27759fa-1c9e-421a-8696-2a422f444c7c"},{"cell_type":"markdown","source":["### Clean AtrialRhythm"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8c360a10-a141-4d5d-a817-5a3f82be78b3"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AtrialRhythm.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'AtrialRhythm - Sinus node rhythm', \n","    'AtrialRhythm - Atrial fibrillation', \n","    'AtrialRhythm - Atrial tachycardia', \n","    'AtrialRhythm - Atrial flutter', \n","    'AtrialRhythm - Sinus arrest', \n","    'AtrialRhythm - Atrial paced', \n","    'AtrialRhythm - Not Documented'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AtrialRhythm.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":374,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:49.5858844Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:17.648923Z","execution_finish_time":"2024-03-06T17:08:18.3714179Z","parent_msg_id":"28bfc347-3854-467e-b7fd-ee7addd89ebd"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 374, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":372,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"df58985c-c518-4afb-815b-69aedea1adc7"},{"cell_type":"markdown","source":["###  Clean StrucInterventionType"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b119a961-3830-4f52-a365-1506845b9f2a"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/StrucInterventionType.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'CardStrucIntervType - Aortic Balloon Valvuloplasty', \n","    'CardStrucIntervType - Transcatheter Aortic Valve Replacement (TAVR)', \n","    'CardStrucIntervType - AV Replacement - Surgical', \n","    'CardStrucIntervType - AV Repair - Surgical', \n","    'CardStrucIntervType - Mitral Balloon Valvuloplasty', \n","    'CardStrucIntervType -  Transcatheter Mitral Valve Repair (TMVR)', \n","    'CardStrucIntervType - MV Replacement - Surgical', \n","    'CardStrucIntervType - MV Repair - Surgical', \n","    'CardStrucIntervType - Mitral Annuloplasty Ring - Surgical', \n","    'CardStrucIntervType - Mitral Transcatheter - Valve-in-valve', \n","    'CardStrucIntervType - ASD Closure', \n","    'CardStrucIntervType - PFO Closure', \n","    'CardStrucIntervType - Pulmonic Replacement', \n","    'CardStrucIntervType - Pulmonic Repair', \n","    'CardStrucIntervType - Tricuspid Replacement', \n","    'CardStrucIntervType - Tricuspid Repair', \n","\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/StrucInterventionType.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":375,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:50.1237523Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:18.7172077Z","execution_finish_time":"2024-03-06T17:08:19.4577674Z","parent_msg_id":"0dcee4f4-865d-4a76-bfd3-5a572d32f978"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 375, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":373,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e8fc0f1e-f086-4c7d-9a0a-0403cbb4fa6b"},{"cell_type":"markdown","source":["### Clean PriorVD"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0a88a702-fd84-4973-8f7a-4ff3b0b8b216"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorVD.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'PriorVD - Prior Myocardial Infarction (MI)', \n","    'PriorVD - Peripheral Arterial Occlusive Disease (PAD)', \n","    'PriorVD - Known Aortic Plaque', \n","    'PriorVD - Coronary Artery Disease (CAD)*', \n","    'PriorVD - Percutaneous Coronary Intervention (PCI)*', \n","    'PriorVD - Coronary Artery Bypass Graft (CABG)*', \n","    'PriorVD - Carotid Artery Disease*'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorVD.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":376,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:50.8567373Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:19.7741057Z","execution_finish_time":"2024-03-06T17:08:20.5109071Z","parent_msg_id":"eca46ec0-5152-40cb-b060-c35e0164f458"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 376, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":374,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4dbdf471-292a-429e-9455-5ac84da1f77d"},{"cell_type":"markdown","source":["### Clean PriorCMType"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c38f4b20-8d15-4df2-97ce-b75a8e22ad67"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorCMType.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'PriorCMType - Non-ischemic cardiomyopathy', \n","    'PriorCMType - Ischemic cardiomyopathy', \n","    'PriorCMType - Restrictive cardiomyopathy', \n","    'PriorCMType - Hypertrophic cardiomyopathy', \n","    'PriorCMType - Other cardiomyopathy type'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorCMType.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":377,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:51.804274Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:20.822884Z","execution_finish_time":"2024-03-06T17:08:21.551647Z","parent_msg_id":"4269e269-2b8a-4dc6-9aae-800ceaf539f0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 377, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":375,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ead37b71-06a1-4af0-a014-f91801bbb591"},{"cell_type":"markdown","source":["### Clean LAAInterventionType"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9273a7d5-35cf-4e16-983e-1b738f560a48"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/LAAInterventionType.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'LAAOType - Epicardial Ligation', \n","    'LAAOType - Surgical Amputation', \n","    'LAAOType - Surgical Ligation', \n","    'LAAOType - Percutaneous Occlusion', \n","    'LAAOType - Surgical Closure Device', \n","    'LAAOType - Surgical Stapling'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/LAAInterventionType.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":378,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:52.3266012Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:21.8663027Z","execution_finish_time":"2024-03-06T17:08:22.1162527Z","parent_msg_id":"3ea1ae0c-d603-4ca6-b685-3214c5d703f5"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 378, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":376,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cd8021bd-9b3f-41a3-ab98-8422d92e2b2e"},{"cell_type":"markdown","source":["### ProcCanceledReason"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d3976b47-13d2-4ff1-9695-02062dd19a58"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcCanceledReason.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'ProcCanceledReason - Anatomy not conducive for implant', \n","    'ProcCanceledReason - Appendage too large (for device implant)', \n","    'ProcCanceledReason - Appendage too small (for device implant)', \n","    'ProcCanceledReason - Catherization challenge', \n","    'ProcCanceledReason - Decompensation in patient condition', \n","    'ProcCanceledReason - Epicardial access issue', \n","    'ProcCanceledReason - Thrombus detected', \n","    'ProcCanceledReason - Unanticipated patient condition', \n","    'ProcCanceledReason -  Patient/Family choice'\n","\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Remove duplicates based on 'NCDRPatientID', 'facility', 'ArrivalDate'\n","# Keep the first occurrence of each duplicate\n","df = df.drop_duplicates(subset=['NCDRPatientID', 'facility', 'ArrivalDate'], keep='first')\n","\n","# Overwrite the original parque file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcCanceledReason.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":379,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:52.8150036Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:22.4567141Z","execution_finish_time":"2024-03-06T17:08:23.1926903Z","parent_msg_id":"e2fb2af0-4f21-43f7-ad76-196f092d1d92"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 379, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":377,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"644424c8-ef3a-4bf0-b91d-9b5e7ec6dd73"},{"cell_type":"markdown","source":["### Clean ProcAbortedReason"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"07b6b037-a909-451e-a2a3-d97bc16dabad"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcAbortedReason.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'ProcAbortedReason - Anatomy not conducive for implant', \n","    'ProcAbortedReason - Appendage too large (for device implant)', \n","    'ProcAbortedReason - Appendage too small (for device implant)', \n","    'ProcAbortedReason - Catherization challenge', \n","    'ProcAbortedReason - Decompensation in patient condition', \n","    'ProcAbortedReason -  Device related', \n","    'ProcAbortedReason - Transcatheter device retrieval', \n","    'ProcAbortedReason - Device release criteria not met', \n","    'ProcAbortedReason - Epicardial access issue', \n","    'ProcAbortedReason - Surgical device retrieval', \n","    'ProcAbortedReason - Device associated thrombus developed during procedure', \n","    'ProcAbortedReason - Unanticipated patient condition', \n","    'ProcAbortedReason - Patient/Family choice'\n","\n","\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Remove duplicates based on 'NCDRPatientID', 'facility', 'ArrivalDate'\n","# Keep the first occurrence of each duplicate\n","df = df.drop_duplicates(\"Pat_ID\", keep='first')\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcAbortedReason.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":380,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:53.386311Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:23.5596035Z","execution_finish_time":"2024-03-06T17:08:24.322853Z","parent_msg_id":"088b7618-1092-4b83-ab60-f1c1d5a3b1b2"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 380, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":378,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2cc627fe-d5ea-416a-ba5b-39a95c9d2616"},{"cell_type":"markdown","source":["### Clean AfibPriorAblStrategy"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2f8ec7cb-2920-40e6-985a-d767f333219c"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AFibPriorAblStrategy.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'AFibPriorAblStrategyCode - Complex Fractionated Atrial Electrogram', \n","    'AFibPriorAblStrategyCode - Convergent Procedure', \n","    'AFibPriorAblStrategyCode - Cryoablation', \n","    'AFibPriorAblStrategyCode - Empiric LA Linear Lesions', \n","    'AFibPriorAblStrategyCode - Focal Ablation', \n","    'AFibPriorAblStrategyCode - Ganglion Plexus Ablation', \n","    'AFibPriorAblStrategyCode - Pulmonary Vein Isolation', \n","    'AFibPriorAblStrategyCode - Segmental PV Ablation', \n","    'AFibPriorAblStrategyCode - Rotor Based Mapping', \n","    'AFibPriorAblStrategyCode - Wide Area Circumferential Ablation' \n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AFibPriorAblStrategy.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":381,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:54.3884247Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:24.6319619Z","execution_finish_time":"2024-03-06T17:08:25.3680635Z","parent_msg_id":"59e1a238-d79c-4230-9375-a159e9c6a77e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 381, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":379,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2c446903-7e0e-40e7-8508-de1b34cf7c96"},{"cell_type":"markdown","source":["### Clean ConcomitantProcType"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4be1c159-c64d-43b4-ae81-e3d942a4ded1"},{"cell_type":"code","source":["\n","# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ConcomitantProcType.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'ConcomitantProcPerf', \n","    'ConcomitantProcType - AFib Ablation', \n","    'ConcomitantProcType - ICD', \n","    'ConcomitantProcType - PCI', \n","    'ConcomitantProcType - TAVR', \n","    'ConcomitantProcType - TMVR', \n","    'ConcomitantProcType - ASD Closure Congenital', \n","    'ConcomitantProcType - ASD Closure Iatrogenic', \n","    'ConcomitantProcType - PFO Closure Congenital'\n","\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Remove duplicates based on 'NCDRPatientID', 'facility', 'ArrivalDate'\n","# Keep the first occurrence of each duplicate\n","df = df.drop_duplicates(subset=['NCDRPatientID', 'facility', 'ArrivalDate'], keep='first')\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ConcomitantProcType.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":382,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:54.9173015Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:25.6849777Z","execution_finish_time":"2024-03-06T17:08:26.433563Z","parent_msg_id":"901b3fef-b866-45b4-80b2-b4159b424c67"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 382, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":380,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7cc28869-8520-4a27-9d0e-08fe721101cd"},{"cell_type":"markdown","source":["### Clean ProcLAAOInd"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ece45f92-21ca-4675-a3b4-1b7eb37c0bb8"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcLAAOInd.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'ProcLAAOInd - High fall risk', \n","    'ProcLAAOInd - History of major bleed', \n","    'ProcLAAOInd - Increased thromboembolic stroke risk', \n","    'ProcLAAOInd - Labile INR', \n","    'ProcLAAOInd - Non-compliance with anticoagulation therapy', \n","    'ProcLAAOInd - Patient preference'\n"," \n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Remove duplicates based on 'NCDRPatientID', 'facility', 'ArrivalDate'\n","# Keep the first occurrence of each duplicate\n","df = df.drop_duplicates(subset=['NCDRPatientID', 'facility', 'ArrivalDate'], keep='first')\n","\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcLAAOInd.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":383,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:55.3721254Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:26.7435483Z","execution_finish_time":"2024-03-06T17:08:27.4861356Z","parent_msg_id":"cd7eb51b-26a0-4f72-bf53-d685248e474e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 383, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":381,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"63f3419d-5a1f-46fc-ac3a-e42b1afa0852"},{"cell_type":"markdown","source":["### Clean GuidanceMethodID"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e96a31ce-b09a-492e-a3f4-640a3063c8a7"},{"cell_type":"code","source":["# Convert 'Y' & 'N' to \"Yes\" & \"No\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/GuidanceMethodID.parquet\")\n","\n","# List of columns to update\n","columns_to_update = [\n","    'GuidanceMethodID - Intracardiac three dimensional echocardiography', \n","    'GuidanceMethodID - Electro Anatomic Mapping', \n","    'GuidanceMethodID - Fluoroscopy',\n","    'GuidanceMethodID - Transesophageal Echocardiogram (TEE)'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Y': 'Yes', 'N': 'No', 'NULL': 'No'})\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/GuidanceMethodID.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":384,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:56.034939Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:27.797042Z","execution_finish_time":"2024-03-06T17:08:28.5501569Z","parent_msg_id":"2752c26f-f181-4797-bb9c-4211cb461014"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 384, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":382,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8a964c36-9a51-4a32-9adf-e079b74f9f7e"},{"cell_type":"markdown","source":["### Clean Follow-up"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"112c83d0-8ead-47b8-aa6c-e969a24b5689"},{"cell_type":"code","source":["# Convert LVEF form \"xx\" to \"0.xx\"\n","import pandas as pd\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/Follow-up.parquet\")\n","\n","# Remove duplicates based on 'NCDRPatientID', 'facility', 'FURefArrivalDate', 'F_AssessmentDate'\n","# multiple duplicates exist in original export form NCDR for same follow up visit \n","# duplicates were generated by entering readmissions into the follow up section\n","# Keep the first occurrence of each duplicate\n","df = df.drop_duplicates(subset=['NCDRPatientID', 'facility', 'FURefArrivalDate', 'F_AssessmentDate'], keep='first')\n","\n","# Remove the '%' sign and convert to numeric\n","df['F_LVEF'] = df['F_LVEF'].astype(float) / 100\n","\n","# List of columns to update\n","columns_to_update = [\n","    'Sex', 'F_WarfarinDiscontinued', 'F_DOACTherapyDiscontinued', 'F_AspirinTherapyDiscontinued', 'F_P2Y12TherapyDiscontinued'\n","]\n","\n","# Loop through each column and replace 'Y' with 'Yes' and 'N' with 'No'\n","for column in columns_to_update:\n","    df[column] = df[column].replace({'Female': 'F', 'Male': 'M', 'No': 'No - Not Discontinued', 'Yes': 'Yes - Discontinued'})\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_3/Merged/Follow-up.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":385,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:56.5917436Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:28.8984543Z","execution_finish_time":"2024-03-06T17:08:29.6342916Z","parent_msg_id":"508c20fb-44f3-44ca-bcb8-1f1facad0e17"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 385, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":383,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"3ced1753-399c-434e-9518-4d16007e5710"},{"cell_type":"markdown","source":["# v1.4 Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e1f45415-3760-4618-a388-7567c1bf5a90"},{"cell_type":"markdown","source":["## In-hospital Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"021b34ca-c539-405d-bcc6-ae49941fdf7b"},{"cell_type":"code","source":["# import from Lakehouse file upload\n","# seperate each XLSX sheet\n","# add facility column with NCDR PID & custom column with hardocded natural key (Pat_ID)\n","# append multiple sheets into one into dataframes in a dictionary \n","\n","def read_excel_and_process_sheets(file_path):\n","    \"\"\"\n","    Reads each sheet from an Excel file into a pandas DataFrame,\n","    adds a 'facility' column based on the file title, and converts ArrivalDate and DCDate to datetime format.\n","    \"\"\"\n","    # Extract facility code from the file title\n","    facility_code = file_path.split('/')[-1][4:10]  # Adjust based on your filenames\n","    \n","    # Read the Excel file into a dict of DataFrames\n","    sheets_dict = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')\n","\n","    # List of date columns to convert\n","    date_columns = [\n","        'ArrivalDate', 'DCDate', 'AFibCathAblDate', 'AFibSurgAblDate',\n","        'AFibFlutterCathAblDate', 'TTEDate', 'CTImagingDate', 'MRDate',\n","        'ICEDate', 'ProcedureStartDateTime', 'TEEDateLAAO',\n","        'ProcedureEndDateTime', 'IntraPostProcEventDate', 'AJ_EventDate',\n","        'ADJ_DeathDate', 'ADJ_BleedDeathDate', 'ADJ_SysThromboDeathDate', 'DOB'\n","    ]\n","    \n","    #list columns to convert to string for parquet formatting issues\n","    string_columns = ['OtherID']\n","\n","    # Process each sheet\n","    for sheet_name, df in sheets_dict.items():\n","        # Add 'facility' column\n","        df['facility'] = facility_code\n","        \n","        # Convert specified date columns to datetime if they exist\n","        for column in date_columns:\n","            if column in df.columns:\n","                df[column] = pd.to_datetime(df[column])\n","\n","        for column in string_columns:\n","            if column in df.columns:\n","                df[column] = df[column].astype(str)\n","\n","        # Ensure 'ArrivalDate' is in datetime format before formatting\n","        if 'ArrivalDate' in df.columns:\n","            df['ArrivalDate'] = pd.to_datetime(df['ArrivalDate'], errors='coerce')  # Convert to datetime, coercing errors\n","            df['ArrivalDate'] = df['ArrivalDate'].dt.strftime('%Y-%m-%d')  # Then format to string\n","        \n","        # Ensure 'NCDRPatientID' is string\n","        if 'NCDRPatientID' in df.columns:\n","            df['NCDRPatientID'] = df['NCDRPatientID'].astype(str)\n","        \n","        # Create 'Pat_ID'\n","        if 'NCDRPatientID' in df.columns and 'ArrivalDate' in df.columns:\n","            df['Pat_ID'] = df['NCDRPatientID'] + '_' + df['ArrivalDate'] + '_' + df['facility']\n","        \n","        sheets_dict[sheet_name] = df\n","    \n","    return sheets_dict\n","\n","def append_sheets_from_multiple_files(file_paths):\n","    \"\"\"\n","    Processes multiple Excel files, appending sheets with the same name across files.\n","    \"\"\"\n","    all_sheets = {}  # Dictionary to store appended sheets\n","    \n","    for file_path in file_paths:\n","        # Process each file\n","        sheets_dict = read_excel_and_process_sheets(file_path)\n","        \n","        # Append sheets with the same name\n","        for sheet_name, df in sheets_dict.items():\n","            if sheet_name in all_sheets:\n","                all_sheets[sheet_name] = pd.concat([all_sheets[sheet_name], df], ignore_index=True)\n","            else:\n","                all_sheets[sheet_name] = df\n","                \n","    return all_sheets\n","\n","\n","file_paths = [\"/lakehouse/default/Files/LAAO/Version_1_4/LAAO136983-BasePAS.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO197501-BaseSHY.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO410079-BaseHAM.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO468377-BaseALT.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO488281-BaseWMD.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO697322-BasePUH.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO799953-BasePIN.xlsx\"]\n","# Here, replace the file_paths list with the actual paths of your files\n","\n","all_sheets_appended = append_sheets_from_multiple_files(file_paths)\n","\n","# At this point, `all_sheets_appended` contains a DataFrame for each unique sheet name\n","# across all processed Excel files, with sheets having the same name appended together\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":386,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:57.1296862Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:30.2494769Z","execution_finish_time":"2024-03-06T17:08:42.256793Z","parent_msg_id":"2d5011ff-e7d9-4083-93df-d8eddb6147c4"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 386, Finished, Available)"},"metadata":{}}],"execution_count":384,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5a4a8206-d888-4359-880a-7361c443db6f"},{"cell_type":"markdown","source":["## FollowUp Ingestion"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"37a6d6e7-926a-489f-9b35-8353a0fe633f"},{"cell_type":"code","source":["# import from Lakehouse file upload\n","# seperate each XLSX sheet\n","# add facility column with NCDR PID & custom column with hardocded natural key (Pat_ID)\n","# append multiple sheets into one into dataframes in a dictionary \n","\n","def read_excel_and_process_sheets(file_path):\n","    \"\"\"\n","    Reads each sheet from an Excel file into a pandas DataFrame,\n","    adds a 'facility' column based on the file title, and stores them in a dictionary.\n","    \"\"\"\n","    # Extract facility code from the file title\n","    facility_code = file_path.split('/')[-1][4:10]  # Adjust based on your filenames\n","    \n","    # Read the Excel file into a dict of DataFrames\n","    sheets_dict = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')\n","\n","    # Date columns to convert\n","    date_columns = [\n","        'FURefArrivalDate', 'FU_RefDischargeDate', 'RefProcStartDateTime',\n","        'F_AssessmentDate', 'F_DeathDate', 'TTEDate_F', 'F_TEEDate',\n","        'F_CardiacCTDate', 'F_CardiacMRIDate', 'F_ICEDate',\n","        'F_WarfarinDiscontinuedDate', 'F_WarfarinResumedDate',\n","        'F_DOACTherapyDiscontinuedDate', 'F_DOACTherapyResumedDate',\n","        'F_AspirinTherapyDiscontinuedDate', 'F_AspirinTherapyResumedDate',\n","        'F_P2Y12TherapyDiscontinuedDate', 'F_P2Y12TherapyResumedDate',\n","        'FupEventDate', 'F_AJ_EventDate', 'F_ADJ_DeathDate',\n","        'FU_ADJ_BleedDeathDate', 'F_ADJ_SysThromboDeathDate'\n","    ]\n","\n","    #list columns to convert to string for parquet formatting issues\n","    string_columns = ['OtherID']\n","\n","    \n","    # Process each sheet\n","    for sheet_name, df in sheets_dict.items():\n","        df['facility'] = facility_code\n","        \n","\n","        # Convert specified date columns to datetime if they exist\n","        for column in date_columns:\n","            if column in df.columns:\n","                df[column] = pd.to_datetime(df[column]) #, errors='coerce')  # Using 'coerce' to handle invalid dates\n","        \n","        for column in string_columns:\n","            if column in df.columns:\n","                df[column] = df[column].astype(str)\n","        \n","        if 'FURefArrivalDate' in df.columns:\n","            df['FURefArrivalDate'] = pd.to_datetime(df['FURefArrivalDate'], errors='coerce')  # Convert to datetime, coercing errors\n","            df['FURefArrivalDate'] = df['FURefArrivalDate'].dt.strftime('%Y-%m-%d')  # Then format to string\n","        \n","        # Ensure 'NCDRPatientID' is string\n","        if 'NCDRPatientID' in df.columns:\n","            df['NCDRPatientID'] = df['NCDRPatientID'].astype(str)\n","        \n","        # Create 'Pat_ID'\n","        if 'NCDRPatientID' in df.columns and 'FURefArrivalDate' in df.columns:\n","            df['Pat_ID'] = df['NCDRPatientID'] + '_' + df['FURefArrivalDate'] + '_' + df['facility']\n","        \n","        sheets_dict[sheet_name] = df\n","\n","\n","        sheets_dict[sheet_name] = df\n","    \n","    return sheets_dict\n","\n","def append_sheets_from_multiple_files(file_paths_FU):\n","    \"\"\"\n","    Processes multiple Excel files, appending sheets with the same name across files.\n","    \"\"\"\n","    all_sheets = {}  # Dictionary to store appended sheets\n","    \n","    for file_path in file_paths_FU:\n","        # Process each file\n","        sheets_dict = read_excel_and_process_sheets(file_path)\n","        \n","        # Append sheets with the same name\n","        for sheet_name, df in sheets_dict.items():\n","            if sheet_name in all_sheets:\n","                all_sheets[sheet_name] = pd.concat([all_sheets[sheet_name], df], ignore_index=True)\n","            else:\n","                all_sheets[sheet_name] = df\n","                \n","    return all_sheets\n","\n","\n","# Example usage\n","file_paths_FU = [\"/lakehouse/default/Files/LAAO/Version_1_4/LAAO136983-FollowUpPAS.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO197501-FollowUpSHY.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO410079-FollowUpHAM.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO468377-FollowUpALT.xlsx\", \n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO488281-FollowUpWMD.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO697322-FollowUpPUH.xlsx\",\n","                \"/lakehouse/default/Files/LAAO/Version_1_4/LAAO799953-FollowUpPIN.xlsx\"]\n","# Here, replace the file_paths_FU list with the actual paths of your files\n","\n","all_sheets_appended_FU = append_sheets_from_multiple_files(file_paths_FU)\n","\n","# At this point, `all_sheets_appended_FU` contains a DataFrame for each unique sheet name\n","# across all processed Excel files, with sheets having the same name appended together\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":387,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:57.6662521Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:42.7369002Z","execution_finish_time":"2024-03-06T17:08:52.8655599Z","parent_msg_id":"cec65f7e-b62e-49c0-8f3c-3d5cfbdba996"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 387, Finished, Available)"},"metadata":{}}],"execution_count":385,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2afa1e0d-8b16-4187-8e7a-5ca059681248"},{"cell_type":"markdown","source":["## Write DFs back to files"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"33d5f19a-cdb2-4483-84df-5678001e9b88"},{"cell_type":"code","source":["LAKEHOUSE_PATH = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged\"\n","\n","# Function to write DataFrame to parquet without including the index\n","def write_dataframe_to_parquet(df, path, filename):\n","    # Construct the full path\n","    full_path = os.path.join(path, filename)\n","    # Write the DataFrame to parquet without the index\n","    df.to_parquet(full_path, index=False)\n","\n","# Loop through all DataFrames in the first dictionary and write them to parquet\n","for sheet_name, df in all_sheets_appended.items():\n","    filename = f\"{sheet_name}.parquet\"  # Construct a filename based on the sheet name\n","    write_dataframe_to_parquet(df, LAKEHOUSE_PATH, filename)\n","\n","# Loop through all DataFrames in the second dictionary and write them to parquet\n","for sheet_name, df in all_sheets_appended_FU.items():\n","    # Check if sheet name is 'Demographics' or 'Export_Criteria' and add '_FU' suffix only to them\n","    if sheet_name in ['Demographics', 'Export Criteria']:\n","        filename = f\"{sheet_name}_FU.parquet\"  # Add '_FU' suffix to these specific sheets\n","    else:\n","        filename = f\"{sheet_name}.parquet\"  # Keep original name for other sheets\n","    write_dataframe_to_parquet(df, LAKEHOUSE_PATH, filename)\n","\n","# Now, all DataFrames from both dictionaries should be written to your lakehouse in parquet format without the index column.\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":388,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:58.1838284Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:53.1810302Z","execution_finish_time":"2024-03-06T17:08:56.6339444Z","parent_msg_id":"cb5a31ec-4ae5-49a9-b566-b3b09f2f53fb"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 388, Finished, Available)"},"metadata":{}}],"execution_count":386,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b8ba6ce5-eac1-4d51-83b3-743a1069511c"},{"cell_type":"markdown","source":["## Data Cleaning"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"19a7b603-03ca-4d0b-bbd9-10bf1659f6ab"},{"cell_type":"markdown","source":["### Clean IPPEvents"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a5db7527-3b62-497f-a98d-0ac4a5aa692d"},{"cell_type":"code","source":["# Load data \n","df = pd.read_parquet(\"/lakehouse/default/\" + \"Files/LAAO/Version_1_4/Merged/IPPEvents.parquet\")\n","\n","# Function to remove \"(Complete Adjudication)\" and trim the string\n","def clean_event(event_str):\n","    cleaned_str = event_str.replace(\"(Complete Adjudication)\", \"\")  # Remove \"(Complete Adjudication)\"\n","    return cleaned_str.strip()  # Trim leading and trailing whitespace\n","\n","# Apply the cleaning function to the 'F_Event' column\n","df['ProcEvents'] = df['ProcEvents'].apply(clean_event)\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/IPPEvents.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":389,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:58.68149Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:56.9346552Z","execution_finish_time":"2024-03-06T17:08:57.6785574Z","parent_msg_id":"4b6a895c-7b15-4992-a926-86ca8a998ee6"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 389, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":387,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2bfd1a09-f154-416c-a61c-1e55a8b7e62b"},{"cell_type":"markdown","source":["### Clean PreProcLabs"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8fbd2aaf-77dd-4c47-8299-06617f659d72"},{"cell_type":"code","source":["# Remove measurement labels\n","\n","# Load data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PreProcLabs.parquet\")\n","\n","# List of columns to clean\n","columns_to_clean = ['Height', 'Weight', 'Pulse', 'SystolicBP', 'DiastolicBP', 'HGB', 'PT', 'PreProcCreat', 'Albumin', 'PlateletCt']\n","\n","# Clean the columns\n","for column in columns_to_clean:\n","    # Split the value and label, keep only the numeric value (first part)\n","    df[column] = df[column].str.split(' ').str[0]\n","    # Convert the cleaned values back to numeric type, in case they were not\n","    df[column] = pd.to_numeric(df[column], errors='coerce')  # 'coerce' will set invalid parsing to NaN\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PreProcLabs.parquet\", index=False)\n","\n","# If you print or display anything after this, it should show that the operation was successful\n","print(\"File has been successfully overwritten\")\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":390,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:07:59.6165468Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:58.040016Z","execution_finish_time":"2024-03-06T17:08:58.8559824Z","parent_msg_id":"ce9871f8-b527-489f-b390-d6a6510dce20"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 390, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":388,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1ce4db66-e5e1-4ca4-a7a1-5fb7a4a67cd5"},{"cell_type":"markdown","source":["### Clean PostProcLabs"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6390d06a-01ce-4c97-af7e-6e70a971d6fb"},{"cell_type":"code","source":["# Remove measurement Labels\n","\n","# Load data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PostProcLabs.parquet\")\n","\n","# List of columns to clean\n","columns_to_clean = ['PostProcPeakCreat', 'PostProcCreat2', 'PostProcHgb2']\n","\n","# Clean the columns\n","for column in columns_to_clean:\n","    # Split the value and label, keep only the numeric value (first part)\n","    df[column] = df[column].str.split(' ').str[0]\n","    # Convert the cleaned values back to numeric type, in case they were not\n","    df[column] = pd.to_numeric(df[column], errors='coerce')  # 'coerce' will set invalid parsing to NaN\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PostProcLabs.parquet\", index=False)\n","\n","# If you print or display anything after this, it should show that the operation was successful\n","print(\"File has been successfully overwritten\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":391,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:00.9349224Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:59.2143152Z","execution_finish_time":"2024-03-06T17:08:59.4298679Z","parent_msg_id":"49c8c9d5-d0ce-4e50-9878-98589a807b84"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 391, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":389,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9e090027-1116-4361-a59b-2e117acb95ab"},{"cell_type":"markdown","source":["### Clean LVEF"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"964c2fc6-e9ae-494c-b71a-b95cee4acd34"},{"cell_type":"code","source":["# Convert LVEF form \"xx %\" to \"0.xx\"\n","\n","# Load the data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Diagnostics.parquet\")\n","\n","# Remove the '%' sign and convert to numeric\n","df['LVEF'] = df['LVEF'].str.replace('%', '').astype(float) / 100\n","\n","# Overwrite the original parquet file with the modified data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Diagnostics.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":392,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:02.3252603Z","session_start_time":null,"execution_start_time":"2024-03-06T17:08:59.8377914Z","execution_finish_time":"2024-03-06T17:09:00.0585504Z","parent_msg_id":"ad10b52a-eb7f-4f96-b7fc-98d2614d87e7"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 392, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":390,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"46d594cb-7e99-49ea-af90-7340b167fb73"},{"cell_type":"markdown","source":["### Clean FollowUp (Labs & LVEF)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b65ff08a-2993-4b65-b89f-f44cce06bccc"},{"cell_type":"code","source":["# Remove measurement Labels & Convert LVEF form \"xx %\" to \"0.xx\"\n","\n","# Load data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FollowUp.parquet\")\n","\n","# List of columns to clean\n","columns_to_clean = ['ResidualLeakFU', 'Creat_FU', 'LowHgbValue_F']\n","\n","# Clean the columns\n","for column in columns_to_clean:\n","    # Ensure the column is of string type before splitting\n","    df[column] = df[column].astype(str).str.split(' ').str[0]\n","    # Convert the cleaned values back to numeric type, in case they were not\n","    df[column] = pd.to_numeric(df[column], errors='coerce')  # 'coerce' will set invalid parsing to NaN\n","\n","# For the 'F_LVEF' column, ensure it is a string, remove '%' signs, and safely convert to float\n","if 'F_LVEF' in df.columns:\n","    # Replace '%' with an empty string and convert 'None' or any non-numeric strings to NaN\n","    df['F_LVEF'] = df['F_LVEF'].astype(str).str.replace('%', '').apply(pd.to_numeric, errors='coerce') / 100\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FollowUp.parquet\", index=False)\n","\n","# If you print or display anything after this, it should show that the operation was successful\n","print(\"File has been successfully overwritten\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":393,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:03.8002321Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:00.4537591Z","execution_finish_time":"2024-03-06T17:09:00.6847703Z","parent_msg_id":"85b275e6-6b8a-49a4-868d-be20b30cc098"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 393, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":391,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d5f31cfd-2c72-40f2-9bbc-91b50bea28aa"},{"cell_type":"markdown","source":["### Clean ProcInfo"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"80943618-2e8c-4584-9391-d2b436f81e15"},{"cell_type":"code","source":["# Load data\n","df = pd.read_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/ProcInfo.parquet\")\n","\n","# List of columns to clean\n","columns_to_clean = ['LAAO_OrWid', 'ResidualLeak', 'FluoroDoseKerm', 'ContrastVol', 'FluoroDoseDAP2']\n","\n","# Clean the columns\n","for column in columns_to_clean:\n","    # Check if the column is one of those needing units extracted\n","    if column in ['FluoroDoseKerm', 'FluoroDoseDAP2']:\n","        # Split into two parts: value and unit, ensuring at least two columns are returned\n","        split_data = df[column].astype(str).str.split(' ', expand=True)\n","        df[column] = pd.to_numeric(split_data[0], errors='coerce')  # Convert value part back to numeric\n","        unit_column_name = f\"{column}_Units\"\n","        if split_data.shape[1] > 1:  # Check if there's a second part\n","            df[unit_column_name] = split_data[1]  # Assign unit part to the new column\n","        else:\n","            df[unit_column_name] = pd.NA  # Fill with NA or a placeholder if no unit is present\n","    else:\n","        # For other columns, just clean as before\n","        df[column] = pd.to_numeric(df[column].astype(str).str.split(' ').str[0], errors='coerce')\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/ProcInfo.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":394,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:05.3646463Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:01.0023018Z","execution_finish_time":"2024-03-06T17:09:01.7390767Z","parent_msg_id":"a64d00a5-3c7a-412d-a147-3358ab0725cf"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 394, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":392,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2270aab8-01c6-48d3-a151-3a48545716ea"},{"cell_type":"markdown","source":["### Clean FUEvents"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dcf881c1-3ff5-49be-b3e0-51daa8b426f3"},{"cell_type":"code","source":["# Load data \n","df = pd.read_parquet(\"/lakehouse/default/\" + \"Files/LAAO/Version_1_4/Merged/FUEVENTS.parquet\")\n","\n","# Function to remove \"(Complete Adjudication)\" and trim the string\n","def clean_event(event_str):\n","    cleaned_str = event_str.replace(\"(Complete Adjudication)\", \"\")  # Remove \"(Complete Adjudication)\"\n","    return cleaned_str.strip()  # Trim leading and trailing whitespace\n","\n","# Apply the cleaning function to the 'F_Event' column\n","df['F_Event'] = df['F_Event'].apply(clean_event)\n","\n","# Overwrite the original parquet file with the cleaned data\n","df.to_parquet(\"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FUEVENTS.parquet\", index=False)\n","\n","print(\"File has been successfully overwritten\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":395,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:07.280092Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:02.0534843Z","execution_finish_time":"2024-03-06T17:09:02.7979354Z","parent_msg_id":"42e24870-70ec-479d-91c3-13caedbcb813"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 395, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File has been successfully overwritten\n"]}],"execution_count":393,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"703c9562-f48d-48dd-84be-715c09af155f"},{"cell_type":"markdown","source":["# Version Merge Process\n","\n","Granularity\n","- Base/Initial Encounter tables are at procedures level if not noted as long tables below\n","- FU are at the follow up visit level, there should up to 4 (45 day, 6m, 1y, 2y) unless noted in the long tables below\n","\n","Long Tables\n","- PreProcMeds\n","- AccessSystems\n","- Devices\n","- IPPEvents\n","- DischargeMeds\n","- FUMEDS\n","\n","Did not bring in ADJ tables"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"352480bc-c425-4778-ac29-078550ea6286"},{"cell_type":"markdown","source":["## Demographics"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3d038f51-3590-49a6-ba7e-0d5184c0181f"},{"cell_type":"code","source":["# demographics from v1.4\n","# Load data into pandas DataFrame\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Demographics.parquet\"\n","demographics = pd.read_parquet(file_path)\n","\n","# Convert the specified columns to string after loading\n","columns_to_convert = ['ZipCode', 'SSN', 'NCDRPatientID']\n","for column in columns_to_convert:\n","    demographics[column] = demographics[column].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Apply the function to the ZipCode column\n","demographics['ZipCode'] = demographics['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert 'facility' to int\n","demographics['facility'] = pd.to_numeric(demographics['facility']).astype('Int64')\n","\n","# Convert 'DOB' column to datetime format\n","demographics['DOB'] = pd.to_datetime(demographics['DOB'], format='%Y-%m-%d')\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":396,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:10.4558705Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:03.120288Z","execution_finish_time":"2024-03-06T17:09:03.3251834Z","parent_msg_id":"c55faae7-81f5-4303-b57a-306e2fb7b130"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 396, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":394,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"34eba4c2-922d-4001-9b27-8a9f2b8c95b0"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility']).astype('Int64')\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d',  # Use errors='coerce' for columns without a specific format\n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":397,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:11.2643863Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:03.6252092Z","execution_finish_time":"2024-03-06T17:09:03.8389697Z","parent_msg_id":"288c4b85-1104-4115-bcfd-dad168c994dc"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 397, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":395,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"29c78275-9c86-4506-b2bb-b38aa7419e5a"},{"cell_type":"code","source":["# Identifying matching columns\n","matching_columns = demographics.columns.intersection(in_hospital.columns)\n","\n","# Appending matching columns from in_hospital to demographics\n","combined_df = pd.concat([demographics, in_hospital[matching_columns]], axis=0, ignore_index=True)\n","\n","# Show the DataFrames\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":398,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:11.7535211Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:04.1571566Z","execution_finish_time":"2024-03-06T17:09:04.3753147Z","parent_msg_id":"1fbb0198-a6aa-4664-9637-a49da5ed321d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 398, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":396,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ccc7bd90-8036-48d7-93af-376c4ffadff1"},{"cell_type":"code","source":["schema = StructType([\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"SSN\", StringType(), True),\n","    StructField(\"SSNA\", StringType(), True),\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"DOB\", DateType(), True),\n","    StructField(\"Sex\", StringType(), True),\n","    StructField(\"ZipCode\", StringType(), True),\n","    StructField(\"ZipCodeNA\", StringType(), True),\n","    StructField(\"RaceWhite\", StringType(), True),\n","    StructField(\"RaceBlack\", StringType(), True),\n","    StructField(\"RaceAsian\", StringType(), True),\n","    StructField(\"RaceAmIndian\", StringType(), True),\n","    StructField(\"RaceNatHaw\", StringType(), True),\n","    StructField(\"HispOrig\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True)\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","combined_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","combined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_demographics\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":399,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:12.7899277Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:04.7904374Z","execution_finish_time":"2024-03-06T17:09:08.2408375Z","parent_msg_id":"61ce65b4-dd80-47c6-b1a3-57383a3bf53e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 399, Finished, Available)"},"metadata":{}}],"execution_count":397,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"76e09289-715c-40b9-8c86-8957937efff3"},{"cell_type":"markdown","source":["## Episode"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4856dfdd-e104-41cb-b951-854b84f84fb3"},{"cell_type":"code","source":["# load episode from v1.4\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Episode.parquet\"\n","episode = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID']\n","for col in columns_as_str:\n","    episode[col] = episode[col].astype(str)\n","\n","# Convert 'Facility' to integer type, handling missing or invalid values by converting them to NaN\n","# Note: pd.to_numeric is used for safe conversion\n","episode['facility'] = pd.to_numeric(episode['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    episode[date_col] = pd.to_datetime(episode[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":400,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:14.1312539Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:08.5510459Z","execution_finish_time":"2024-03-06T17:09:08.7938243Z","parent_msg_id":"30fc61cb-c849-4a56-9cf4-51ffdef9bb1e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 400, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":398,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"be767aa7-a8bb-4369-a9ad-cbddd5949b37"},{"cell_type":"code","source":["# Load HIPs from v 1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/HIPS.parquet\"\n","HIPS = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID']\n","for col in columns_as_str:\n","    HIPS[col] = HIPS[col].astype(str)\n","\n","# Convert 'Facility' to integer type, handling missing or invalid values by converting them to NaN\n","# Note: pd.to_numeric is used for safe conversion\n","HIPS['facility'] = pd.to_numeric(HIPS['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    HIPS[date_col] = pd.to_datetime(HIPS[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":401,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:14.798989Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:09.137867Z","execution_finish_time":"2024-03-06T17:09:09.3471787Z","parent_msg_id":"db778200-aaa5-4737-b82f-145659c8ff18"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 401, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":399,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"3a42bfa2-3327-4d9a-87b1-ad5bd4def1af"},{"cell_type":"code","source":["# Identifying matching columns\n","matching_columns = episode.columns.intersection(HIPS.columns)\n","\n","# Appending matching columns from episode to hips\n","combined_df = pd.concat([episode, HIPS[matching_columns]], axis=0, ignore_index=True)\n","\n","# Show the DataFrames\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":402,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:15.2935278Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:09.6545218Z","execution_finish_time":"2024-03-06T17:09:09.8825207Z","parent_msg_id":"574c7936-ac3b-4a45-a0ff-44b14bafade1"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 402, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":400,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7214cf61-47f9-4152-bb60-679caa1ed64a"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d',\n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":403,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:15.7398049Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:10.2526662Z","execution_finish_time":"2024-03-06T17:09:10.4682268Z","parent_msg_id":"09e0dea0-ab55-444c-a55b-0fc4e9601920"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 403, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":401,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6556959f-ee05-4d0c-8c2b-8fc19cc788c4"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from in_hospital 1.3 df\n","\n","\n","# List of columns from 'in_hospital' to bring into 'combined_df'\n","specified_columns = [\n","    'MBI', 'EnrolledStudy', 'LAAO_Adm'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index(['NCDRPatientID', 'facility', 'ArrivalDate'], inplace=True)\n","in_hospital.set_index(['NCDRPatientID', 'facility', 'ArrivalDate'], inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from in_hospital\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(in_hospital[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":404,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:16.6650237Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:10.8088425Z","execution_finish_time":"2024-03-06T17:09:11.0380639Z","parent_msg_id":"b1213a10-310e-4117-8180-02fdaf66c414"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 404, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":402,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"bf49c239-cb9e-4b78-85f7-650a62cdfc3a"},{"cell_type":"code","source":["# rename to be delta table friendly\n","\n","# Here's an example of renaming columns:\n","\n","columns_mapping = {\n","    \"HIPS - Private Health Insurance\": \"HIPS_Private_Health_Insurance\",\n","    \"HIPS - Medicare\": \"HIPS_Medicare\",\n","    \"HIPS - Medicare Advantage\": \"HIPS_Medicare_Advantage\",\n","    \"HIPS - Medicaid\": \"HIPS_Medicaid\",\n","    \"HIPS - Military Health Care\": \"HIPS_Military_Health_Care\",\n","    \"HIPS - State-Specific Plan (non-Medicaid)\": \"HIPS_State_Specific_Plan_non_Medicaid\",\n","    \"HIPS - Indian Health Service\": \"HIPS_Indian_Health_Service\",\n","    \"HIPS - Non-US Insurance\": \"HIPS_Non_US_Insurance\"\n","}\n","\n","# Rename the columns\n","combined_df_renamed = combined_df.rename(columns=columns_mapping)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":405,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:17.6896728Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:11.3555861Z","execution_finish_time":"2024-03-06T17:09:11.5795127Z","parent_msg_id":"18e6537c-f863-4654-9316-c7b9366a15c2"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 405, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":403,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c4bba3d6-aa34-43c7-a91a-712c0f9cdc10"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"ExplicitSchemaExample\").getOrCreate()\n","\n","# Define the schema explicitly with adjusted column names\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"HealthIns\", StringType(), True),\n","    StructField(\"HIPS_Private_Health_Insurance\", StringType(), True),\n","    StructField(\"HIPS_Medicare\", StringType(), True),\n","    StructField(\"HIPS_Medicare_Advantage\", StringType(), True),\n","    StructField(\"HIPS_Medicaid\", StringType(), True),\n","    StructField(\"HIPS_Military_Health_Care\", StringType(), True),\n","    StructField(\"HIPS_State_Specific_Plan_non_Medicaid\", StringType(), True),\n","    StructField(\"HIPS_Indian_Health_Service\", StringType(), True),\n","    StructField(\"HIPS_Non_US_Insurance\", StringType(), True),\n","    StructField(\"MBI\", StringType(), True),\n","    StructField(\"EnrolledStudy\", StringType(), True),\n","    StructField(\"LAAO_Adm\", StringType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","combined_spark_df = spark.createDataFrame(combined_df_renamed, schema=schema)\n","\n","# Now try writing the DataFrame to the Delta table again\n","combined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_episode\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":406,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:19.1434429Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:11.9171584Z","execution_finish_time":"2024-03-06T17:09:15.3897918Z","parent_msg_id":"825bdb6f-8ba4-4b4a-955e-273a72a04fca"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 406, Finished, Available)"},"metadata":{}}],"execution_count":404,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c4835c02-e881-4cb1-82df-294d25e8a9a8"},{"cell_type":"markdown","source":["## Research\n","\n","No data in either. Wrote a blank table to future use based on v1.4 structure."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"53c04bb1-4c6c-4c19-8954-d74490801bb0"},{"cell_type":"code","source":["# load research from v1.4\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Research.parquet\"\n","research = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID']\n","for col in columns_as_str:\n","    research[col] = research[col].astype(str)\n","\n","# Convert 'Facility' to integer type, handling missing or invalid values by converting them to NaN\n","# Note: pd.to_numeric is used for safe conversion\n","research['facility'] = pd.to_numeric(research['facility']).astype('Int64')\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    research[date_col] = pd.to_datetime(research[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":407,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:21.0487969Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:15.7581211Z","execution_finish_time":"2024-03-06T17:09:15.9969844Z","parent_msg_id":"e4452855-cfcc-4eb8-a89f-7a2acc281799"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 407, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":405,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d6a8d838-4558-4fdb-b7c3-34f5f4deaf83"},{"cell_type":"code","source":["# Define the schema based on the provided column information\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"StudyName\", StringType(), True),\n","    StructField(\"StudyPtID\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","spark_df = spark.createDataFrame(research, schema=schema)\n","\n","# Write the Spark DataFrame to the Delta table\n","spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_research\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":408,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:23.4341189Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:16.3338071Z","execution_finish_time":"2024-03-06T17:09:19.7969349Z","parent_msg_id":"f052d38c-0612-4b55-a7f1-d54723d2e7d4"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 408, Finished, Available)"},"metadata":{}}],"execution_count":406,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fc79230a-10ae-47d1-accc-fb61b2361e41"},{"cell_type":"markdown","source":["## HistoryAndRisk"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bcf666b5-7e10-4979-9ff1-dc3eedf8c2cc"},{"cell_type":"markdown","source":["### Define Dataframes Needed"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9ac34d54-27dd-463e-ae76-c2ebcde76ef5"},{"cell_type":"code","source":["# load historyandrisk from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/HistoryAndRisk.parquet\"\n","historyandrisk = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    historyandrisk[col] = historyandrisk[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","historyandrisk['facility'] = pd.to_numeric(historyandrisk['facility'])\n","\n","# Apply the function to the specified columns\n","historyandrisk['OtherID'] = historyandrisk['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d',  # Use errors='coerce' for columns without a specific format\n","    'AFibFlutterCathAblDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        historyandrisk[col] = pd.to_datetime(historyandrisk[col], format=fmt)\n","    else:\n","        historyandrisk[col] = pd.to_datetime(historyandrisk[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":409,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:26.565285Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:20.1308711Z","execution_finish_time":"2024-03-06T17:09:20.3531794Z","parent_msg_id":"c281267c-d1ff-447b-97b5-5189126b9900"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 409, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":407,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"71c8cc38-0602-4bee-b145-389172bd3823"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":410,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:30.2007816Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:20.6867479Z","execution_finish_time":"2024-03-06T17:09:20.9006792Z","parent_msg_id":"9798d534-2f0d-461b-924a-d3f27c11c110"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 410, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":408,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ada49d73-7b38-468a-a29e-82c73a5e338d"},{"cell_type":"code","source":["# load bleedeventtype from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/BleedEventType.parquet\"\n","bleedeventtype = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    bleedeventtype[col] = bleedeventtype[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","bleedeventtype['facility'] = pd.to_numeric(bleedeventtype['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    bleedeventtype[date_col] = pd.to_datetime(bleedeventtype[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":411,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:33.7896487Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:21.2416584Z","execution_finish_time":"2024-03-06T17:09:21.4623907Z","parent_msg_id":"bb17d979-fff1-43ac-971d-8662a9f373ba"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 411, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":409,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c2b9545c-dba2-408a-aa68-15fd6a624f2a"},{"cell_type":"code","source":["# load strucinterventiontype from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/StrucInterventionType.parquet\"\n","strucinterventiontype = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    strucinterventiontype[col] = strucinterventiontype[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","strucinterventiontype['facility'] = pd.to_numeric(strucinterventiontype['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    strucinterventiontype[date_col] = pd.to_datetime(strucinterventiontype[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":412,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:35.4952271Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:21.8073413Z","execution_finish_time":"2024-03-06T17:09:22.0533468Z","parent_msg_id":"a12241f8-c796-4772-8ed2-291a3a639924"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 412, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":410,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"74a944de-aac2-4ad4-a2a8-84d249501487"},{"cell_type":"code","source":["# load priorvd from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorVD.parquet\"\n","priorvd = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    priorvd[col] = priorvd[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","priorvd['facility'] = pd.to_numeric(priorvd['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    priorvd[date_col] = pd.to_datetime(priorvd[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":413,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:36.1832996Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:22.3690009Z","execution_finish_time":"2024-03-06T17:09:22.6025748Z","parent_msg_id":"639f5d4c-3918-4c38-89e0-9bca0dc72d27"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 413, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":411,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ed6b09d4-c939-4445-8c20-0015d6f03e3f"},{"cell_type":"code","source":["# load priorcmtype from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PriorCMType.parquet\"\n","priorcmtype = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    priorcmtype[col] = priorcmtype[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","priorcmtype['facility'] = pd.to_numeric(priorcmtype['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    priorcmtype[date_col] = pd.to_datetime(priorcmtype[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":414,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:36.7541393Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:22.9432501Z","execution_finish_time":"2024-03-06T17:09:23.1616399Z","parent_msg_id":"4b5deb22-bcc5-4bfa-a4ed-966b659b343c"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 414, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":412,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0c338506-d1a6-4738-91a7-bbc64f5d6caa"},{"cell_type":"code","source":["# load laainterventiontype from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/LAAInterventionType.parquet\"\n","laainterventiontype = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    laainterventiontype[col] = laainterventiontype[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","laainterventiontype['facility'] = pd.to_numeric(laainterventiontype['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    laainterventiontype[date_col] = pd.to_datetime(laainterventiontype[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":415,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:37.3044046Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:23.5804634Z","execution_finish_time":"2024-03-06T17:09:23.7995892Z","parent_msg_id":"53036bf4-1657-4f96-aaea-ca27a9f25fcd"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 415, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":413,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ea782f45-b20d-4155-9b37-c90d04dd2c49"},{"cell_type":"code","source":["# load afibpriorablstrategy from v1.3\n","\n","# Load data from a Parquet file\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AFibPriorAblStrategy.parquet\"\n","afibpriorablstrategy = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","columns_as_str = ['NCDRPatientID', 'OtherID']\n","for col in columns_as_str:\n","    afibpriorablstrategy[col] = afibpriorablstrategy[col].astype(str)\n","\n","# Convert 'Facility' to integer type\n","afibpriorablstrategy['facility'] = pd.to_numeric(afibpriorablstrategy['facility'])\n","\n","# Convert date columns to datetime format\n","date_columns = ['ArrivalDate', 'DCDate']\n","for date_col in date_columns:\n","    afibpriorablstrategy[date_col] = pd.to_datetime(afibpriorablstrategy[date_col], format='%Y-%m-%d')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":416,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:37.7751625Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:24.1252706Z","execution_finish_time":"2024-03-06T17:09:24.3708143Z","parent_msg_id":"182d7c40-94a1-4f6f-8bc5-a9682fe5521e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 416, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":414,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9ea02152-4b39-4db9-b71e-6d178124f25b"},{"cell_type":"markdown","source":["### Begin Append and Merging Dataframes"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"7fa37e9b-9688-488b-98f3-f35b815f2b77"},{"cell_type":"code","source":["#start by appending in_hospital \n","\n","# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'DCDate', \n","    'facility', \n","    'ChadCHF', \n","    'NYHA', \n","    'ChadLVDysf', \n","    'ChadHypertCont', \n","    'ChadDM', \n","    'ChadStroke', \n","    'ChadTIA', \n","    'ChadTE', \n","    'HBHyperUncont', \n","    'HBAbnRenal', \n","    'HBAbnLiver', \n","    'HBStroke', \n","    'HBStrokeType - Hemorrhagic Stroke', \n","    'HBStrokeType - Ischemic Stroke', \n","    'HBStrokeType - Undetermined Stroke', \n","    'HBBleed', \n","    'HBLabINR', \n","    'HBAlcohol', \n","    'HBDrugAP', \n","    'HBDrugNSAID', \n","    'IncrFallRisk', \n","    'GeneticCoag', \n","    'ConAntiCoagTx', \n","    'AFibInd', \n","    'AFibClass', \n","    'ValvularAF', \n","    'HxRHVD', \n","    'HxMVReplace', \n","    'MechValveMitPos', \n","    'HxMVRepair', \n","    'PrevAFibTerm', \n","    'PrevAFibTermPC', \n","    'PrevAFibTermDC', \n","    'PrevAFibTermSA', \n","    'AFibSurgAblDate', \n","    'AFlutter', \n","    'AFlutterType', \n","    'PrevAFLTerm', \n","    'PrevAFLTermPC', \n","    'PrevAFLTermCA', \n","    'AFibFlutterCathAblDate', \n","    'ChronicLungDisease', \n","    'CAD', \n","    'SleepApnea', \n","    'SleepApneaRxFollowed', \n","    'EpicardialAppCons', \n","    'MedCond - Cardiac Surgery', \n","    'MedCond - Pericarditis', \n","    'MedCond - Epicardial Access', \n","    'MedCond - Thoracic Radiation Therapy', \n","    'MedCond - Pectus Excavatum', \n","    'MedCond - Epigastric Surgery', \n","    'MedCond - Autoimmune Disease', \n","    'MedCond - Hepatomegaly', \n","    'MedCond - Hiatal Hernia', \n","    'LupusCons'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(historyandrisk.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'historyandrisk' DataFrame\n","new_data_to_append = new_data_to_append[historyandrisk.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([historyandrisk, new_data_to_append], ignore_index=True)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":417,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:38.2480775Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:24.6818806Z","execution_finish_time":"2024-03-06T17:09:24.8946716Z","parent_msg_id":"17807713-d169-45f6-8ccd-01b220aa6554"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 417, Finished, Available)"},"metadata":{}}],"execution_count":415,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9c114eca-5647-4923-914a-34d08cdc9404"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from structinterventiontype 1.3 df\n","\n","\n","# List of columns from 'strucinterventiontype' to bring into 'combined_df'\n","specified_columns = [\n","    'CardStrucInterv', \n","    'CardStrucIntervType - Aortic Balloon Valvuloplasty', \n","    'CardStrucIntervType - Transcatheter Aortic Valve Replacement (TAVR)', \n","    'CardStrucIntervType - AV Replacement - Surgical', \n","    'CardStrucIntervType - AV Repair - Surgical', \n","    'CardStrucIntervType - Mitral Balloon Valvuloplasty', \n","    'CardStrucIntervType -  Transcatheter Mitral Valve Repair (TMVR)', \n","    'CardStrucIntervType - MV Replacement - Surgical', \n","    'CardStrucIntervType - MV Repair - Surgical', \n","    'CardStrucIntervType - Mitral Annuloplasty Ring - Surgical', \n","    'CardStrucIntervType - Mitral Transcatheter - Valve-in-valve', \n","    'CardStrucIntervType - ASD Closure', \n","    'CardStrucIntervType - PFO Closure', \n","    'CardStrucIntervType - Pulmonic Replacement', \n","    'CardStrucIntervType - Pulmonic Repair', \n","    'CardStrucIntervType - Tricuspid Replacement', \n","    'CardStrucIntervType - Tricuspid Repair'\n","]\n","\n","# Set the index of both dataframes to 'Pat_ID'\n","combined_df.set_index('Pat_ID', inplace=True)\n","strucinterventiontype.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from strucinterventiontype\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(strucinterventiontype[column])\n","\n","# Reset the index to return to the original structure, if needed\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":418,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:38.8751165Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:25.2290225Z","execution_finish_time":"2024-03-06T17:09:25.467423Z","parent_msg_id":"8fac7078-9b09-4df6-80e3-423ab1e34622"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 418, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":416,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a43ef9be-fca8-4f0e-a0ba-65bd62998b10"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from priorvd 1.3 df\n","\n","# List of columns from 'priorvd' to bring into 'combined_df'\n","specified_columns = [\n","    'PriorVD - Prior Myocardial Infarction (MI)', \n","    'PriorVD - Peripheral Arterial Occlusive Disease (PAD)', \n","    'PriorVD - Known Aortic Plaque', \n","    'PriorVD - Coronary Artery Disease (CAD)*', \n","    'PriorVD - Percutaneous Coronary Intervention (PCI)*', \n","    'PriorVD - Coronary Artery Bypass Graft (CABG)*', \n","    'PriorVD - Carotid Artery Disease*'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","priorvd.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from priorvd\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(priorvd[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":419,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:39.3329149Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:25.7820215Z","execution_finish_time":"2024-03-06T17:09:26.0090377Z","parent_msg_id":"8f4e76ce-836e-48bc-ac09-0eb4f3a458dd"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 419, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":417,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"eb7b48da-a077-4800-bd9c-aaf2799c69dc"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from priorcmtype 1.3 df\n","\n","# List of columns from 'priorcmtype' to bring into 'combined_df'\n","specified_columns = [\n","    'CM', \n","    'PriorCMType - Non-ischemic cardiomyopathy', \n","    'PriorCMType - Ischemic cardiomyopathy', \n","    'PriorCMType - Restrictive cardiomyopathy', \n","    'PriorCMType - Hypertrophic cardiomyopathy', \n","    'PriorCMType - Other cardiomyopathy type'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","priorcmtype.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from priorcmtype\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(priorcmtype[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":420,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:39.8495719Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:26.3239741Z","execution_finish_time":"2024-03-06T17:09:26.5648202Z","parent_msg_id":"8687325d-9295-4302-8794-1d35ad6e2303"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 420, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":418,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5fbff6b1-acf2-48b7-b7e2-64d3ed7dd01e"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from laainterventiontype 1.3 df\n","\n","# List of columns from 'laainterventiontype' to bring into 'combined_df'\n","specified_columns = [\n","    'LAAOInterv', \n","    'LAAOType - Epicardial Ligation', \n","    'LAAOType - Surgical Amputation', \n","    'LAAOType - Surgical Ligation', \n","    'LAAOType - Percutaneous Occlusion', \n","    'LAAOType - Surgical Closure Device', \n","    'LAAOType - Surgical Stapling'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","laainterventiontype.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from laainterventiontype\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(laainterventiontype[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":421,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:40.3746529Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:26.8886915Z","execution_finish_time":"2024-03-06T17:09:27.1076314Z","parent_msg_id":"80cc0cf3-7306-4de5-a86b-94172ffca270"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 421, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":419,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"772824f3-6876-4fb0-bb01-fe3ed7c07d2c"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from bleedeventtype 1.3 df\n","\n","# List of columns from 'bleedeventtype' to bring into 'combined_df'\n","specified_columns = [\n","    'ClinicBleedEvent', \n","    'BleedEventType - Intracranial Bleed', \n","    'BleedEventType - Epistaxis', \n","    'BleedEventType - Gastrointestinal Bleed', \n","    'BleedEventType - Other'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","bleedeventtype.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from bleedeventtype\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(bleedeventtype[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":422,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:41.498044Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:27.4790695Z","execution_finish_time":"2024-03-06T17:09:27.7419776Z","parent_msg_id":"d3386c0f-c81d-43bc-b492-88a1bb3d4394"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 422, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":420,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"797506b6-418e-4e9a-8092-7557903aafad"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from afibpriorablstrategy 1.3 df\n","\n","# List of columns from 'afibpriorablstrategy' to bring into 'combined_df'\n","specified_columns = [\n","    'PrevAFibTermCA', \n","    'AFibCathAblDate', \n","    'AFibPriorAblStrategyCode - Complex Fractionated Atrial Electrogram', \n","    'AFibPriorAblStrategyCode - Convergent Procedure', \n","    'AFibPriorAblStrategyCode - Cryoablation', \n","    'AFibPriorAblStrategyCode - Empiric LA Linear Lesions', \n","    'AFibPriorAblStrategyCode - Focal Ablation', \n","    'AFibPriorAblStrategyCode - Ganglion Plexus Ablation', \n","    'AFibPriorAblStrategyCode - Pulmonary Vein Isolation', \n","    'AFibPriorAblStrategyCode - Segmental PV Ablation', \n","    'AFibPriorAblStrategyCode - Rotor Based Mapping', \n","    'AFibPriorAblStrategyCode - Wide Area Circumferential Ablation'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index(\"Pat_ID\", inplace=True)\n","afibpriorablstrategy.set_index(\"Pat_ID\", inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from afibpriorablstrategy\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(afibpriorablstrategy[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":423,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:42.0497349Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:28.1311238Z","execution_finish_time":"2024-03-06T17:09:28.3550283Z","parent_msg_id":"9fa2e2a2-aa39-42ad-956a-c619fb301237"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 423, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":421,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"3a2cb612-66f3-4cb4-9717-238a8c2d9490"},{"cell_type":"code","source":["# Rename columns to be compatible with Delta table\n","columns_mapping = {\n","    'HBStrokeType - Hemorrhagic Stroke': 'HBStrokeType_Hemorrhagic_Stroke', \n","    'HBStrokeType - Ischemic Stroke': 'HBStrokeType_Ischemic_Stroke', \n","    'HBStrokeType - Undetermined Stroke': 'HBStrokeType_Undetermined_Stroke',\n","    'MedCond - Cardiac Surgery': 'MedCond_Cardiac_Surgery', \n","    'MedCond - Pericarditis': 'MedCond_Pericarditis', \n","    'MedCond - Epicardial Access': 'MedCond_Epicardial_Access', \n","    'MedCond - Thoracic Radiation Therapy': 'MedCond_Thoracic_Radiation_Therapy', \n","    'MedCond - Pectus Excavatum': 'MedCond_Pectus_Excavatum', \n","    'MedCond - Epigastric Surgery': 'MedCond_Epigastric_Surgery', \n","    'MedCond - Autoimmune Disease': 'MedCond_Autoimmune_Disease', \n","    'MedCond - Hepatomegaly': 'MedCond_Hepatomegaly', \n","    'MedCond - Hiatal Hernia': 'MedCond_Hiatal_Hernia',\n","    'CardStrucIntervType - Aortic Balloon Valvuloplasty': 'CardStrucIntervType_Aortic_Balloon_Valvuloplasty', \n","    'CardStrucIntervType - Transcatheter Aortic Valve Replacement (TAVR)': 'CardStrucIntervType_Transcatheter_Aortic_Valve_Replacement_TAVR', \n","    'CardStrucIntervType - AV Replacement - Surgical': 'CardStrucIntervType_AV_Replacement_Surgical', \n","    'CardStrucIntervType - AV Repair - Surgical': 'CardStrucIntervType_AV_Repair_Surgical', \n","    'CardStrucIntervType - Mitral Balloon Valvuloplasty': 'CardStrucIntervType_Mitral_Balloon_Valvuloplasty', \n","    'CardStrucIntervType - Transcatheter Mitral Valve Repair (TMVR)': 'CardStrucIntervType_Transcatheter_Mitral_Valve_Repair_TMVR', \n","    'CardStrucIntervType - MV Replacement - Surgical': 'CardStrucIntervType_MV_Replacement_Surgical', \n","    'CardStrucIntervType - MV Repair - Surgical': 'CardStrucIntervType_MV_Repair_Surgical', \n","    'CardStrucIntervType - Mitral Annuloplasty Ring - Surgical': 'CardStrucIntervType_Mitral_Annuloplasty_Ring_Surgical', \n","    'CardStrucIntervType - Mitral Transcatheter - Valve-in-valve': 'CardStrucIntervType_Mitral_Transcatheter_Valve_in_valve', \n","    'CardStrucIntervType - ASD Closure': 'CardStrucIntervType_ASD_Closure', \n","    'CardStrucIntervType - PFO Closure': 'CardStrucIntervType_PFO_Closure', \n","    'CardStrucIntervType - Pulmonic Replacement': 'CardStrucIntervType_Pulmonic_Replacement', \n","    'CardStrucIntervType - Pulmonic Repair': 'CardStrucIntervType_Pulmonic_Repair', \n","    'CardStrucIntervType - Tricuspid Replacement': 'CardStrucIntervType_Tricuspid_Replacement', \n","    'CardStrucIntervType - Tricuspid Repair': 'CardStrucIntervType_Tricuspid_Repair',\n","    'PriorVD - Prior Myocardial Infarction (MI)': 'PriorVD_Prior_Myocardial_Infarction_MI', \n","    'PriorVD - Peripheral Arterial Occlusive Disease (PAD)': 'PriorVD_Peripheral_Arterial_Occlusive_Disease_PAD', \n","    'PriorVD - Known Aortic Plaque': 'PriorVD_Known_Aortic_Plaque', \n","    'PriorVD - Coronary Artery Disease (CAD)*': 'PriorVD_Coronary_Artery_Disease_CAD', \n","    'PriorVD - Percutaneous Coronary Intervention (PCI)*': 'PriorVD_Percutaneous_Coronary_Intervention_PCI', \n","    'PriorVD - Coronary Artery Bypass Graft (CABG)*': 'PriorVD_Coronary_Artery_Bypass_Graft_CABG', \n","    'PriorVD - Carotid Artery Disease': 'PriorVD_Carotid_Artery_Disease',\n","    'PriorCMType - Non-ischemic cardiomyopathy': 'PriorCMType_Non_ischemic_cardiomyopathy', \n","    'PriorCMType - Ischemic cardiomyopathy': 'PriorCMType_Ischemic_cardiomyopathy', \n","    'PriorCMType - Restrictive cardiomyopathy': 'PriorCMType_Restrictive_cardiomyopathy', \n","    'PriorCMType - Hypertrophic cardiomyopathy': 'PriorCMType_Hypertrophic_cardiomyopathy', \n","    'PriorCMType - Other cardiomyopathy type': 'PriorCMType_Other_cardiomyopathy_type',\n","    'LAAOType - Epicardial Ligation': 'LAAOType_Epicardial_Ligation', \n","    'LAAOType - Surgical Amputation': 'LAAOType_Surgical_Amputation', \n","    'LAAOType - Surgical Ligation': 'LAAOType_Surgical_Ligation', \n","    'LAAOType - Percutaneous Occlusion': 'LAAOType_Percutaneous_Occlusion', \n","    'LAAOType - Surgical Closure Device': 'LAAOType_Surgical_Closure_Device', \n","    'LAAOType - Surgical Stapling': 'LAAOType_Surgical_Stapling',\n","    'BleedEventType - Intracranial Bleed': 'BleedEventType_Intracranial_Bleed', \n","    'BleedEventType - Epistaxis': 'BleedEventType_Epistaxis', \n","    'BleedEventType - Gastrointestinal Bleed': 'BleedEventType_Gastrointestinal_Bleed', \n","    'BleedEventType - Other': 'BleedEventType_Other',\n","    'AFibPriorAblStrategyCode - Complex Fractionated Atrial Electrogram': 'AFibPriorAblStrategyCode_Complex_Fractionated_Atrial_Electrogram', \n","    'AFibPriorAblStrategyCode - Convergent Procedure': 'AFibPriorAblStrategyCode_Convergent_Procedure', \n","    'AFibPriorAblStrategyCode - Cryoablation': 'AFibPriorAblStrategyCode_Cryoablation', \n","    'AFibPriorAblStrategyCode - Empiric LA Linear Lesions': 'AFibPriorAblStrategyCode_Empiric_LA_Linear_Lesions', \n","    'AFibPriorAblStrategyCode - Focal Ablation': 'AFibPriorAblStrategyCode_Focal_Ablation', \n","    'AFibPriorAblStrategyCode - Ganglion Plexus Ablation': 'AFibPriorAblStrategyCode_Ganglion_Plexus_Ablation', \n","    'AFibPriorAblStrategyCode - Pulmonary Vein Isolation': 'AFibPriorAblStrategyCode_Pulmonary_Vein_Isolation', \n","    'AFibPriorAblStrategyCode - Segmental PV Ablation': 'AFibPriorAblStrategyCode_Segmental_PV_Ablation', \n","    'AFibPriorAblStrategyCode - Rotor Based Mapping': 'AFibPriorAblStrategyCode_Rotor_Based_Mapping', \n","    'AFibPriorAblStrategyCode - Wide Area Circumferential Ablation': 'AFibPriorAblStrategyCode_Wide_Area_Circumferential_Ablation',\n","    'PriorVD - Carotid Artery Disease*': 'PriorVD_Carotid_Artery_Disease',\n","    'CardStrucIntervType -  Transcatheter Mitral Valve Repair (TMVR)': 'CardStrucIntervType_Transcatheter_Mitral_Valve_Repair_TMVR'\n","}\n","\n","# Rename the columns\n","combined_df_renamed = combined_df.rename(columns=columns_mapping)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":424,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:42.5467691Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:28.6880609Z","execution_finish_time":"2024-03-06T17:09:28.9122117Z","parent_msg_id":"23537be1-259f-4aba-8eac-aa173399c249"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 424, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":422,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"19e3d457-b91f-461f-95d3-efa2000ba440"},{"cell_type":"code","source":["# Define the schema explicitly for laao_historyandrisk\n","schema = StructType([\n","    StructField(\"Pat_ID\", StringType(), True),\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"ChadCHF\", StringType(), True),\n","    StructField(\"NYHA\", StringType(), True),\n","    StructField(\"ChadLVDysf\", StringType(), True),\n","    StructField(\"ChadHypertCont\", StringType(), True),\n","    StructField(\"ChadDM\", StringType(), True),\n","    StructField(\"ChadStroke\", StringType(), True),\n","    StructField(\"ChadTIA\", StringType(), True),\n","    StructField(\"ChadTE\", StringType(), True),\n","    StructField(\"ChadVascDis\", StringType(), True),\n","    StructField(\"PriorVD_Prior_Myocardial_Infarction_MI\", StringType(), True),\n","    StructField(\"PriorVD_Peripheral_Arterial_Occlusive_Disease_PAD\", StringType(), True),\n","    StructField(\"PriorVD_Known_Aortic_Plaque\", StringType(), True),\n","    StructField(\"PriorVD_Coronary_Artery_Disease_CAD\", StringType(), True),\n","    StructField(\"PriorVD_Percutaneous_Coronary_Intervention_PCI\", StringType(), True),\n","    StructField(\"PriorVD_Coronary_Artery_Bypass_Graft_CABG\", StringType(), True),\n","    StructField(\"PriorVD_Carotid_Artery_Disease\", StringType(), True),\n","    StructField(\"HBHyperUncont\", StringType(), True),\n","    StructField(\"HBAbnRenal\", StringType(), True),\n","    StructField(\"HBAbnLiver\", StringType(), True),\n","    StructField(\"HBStroke\", StringType(), True),\n","    StructField(\"HBStrokeType_Hemorrhagic_Stroke\", StringType(), True),\n","    StructField(\"HBStrokeType_Ischemic_Stroke\", StringType(), True),\n","    StructField(\"HBStrokeType_Undetermined_Stroke\", StringType(), True),\n","    StructField(\"HBBleed\", StringType(), True),\n","    StructField(\"HBLabINR\", StringType(), True),\n","    StructField(\"HBAlcohol\", StringType(), True),\n","    StructField(\"HBDrugAP\", StringType(), True),\n","    StructField(\"HBDrugNSAID\", StringType(), True),\n","    StructField(\"IncrFallRisk\", StringType(), True),\n","    StructField(\"ClinicBleedEvent\", StringType(), True),\n","    StructField(\"BleedEventType_Intracranial_Bleed\", StringType(), True),\n","    StructField(\"BleedEventType_Epistaxis\", StringType(), True),\n","    StructField(\"BleedEventType_Gastrointestinal_Bleed\", StringType(), True),\n","    StructField(\"BleedEventType_Other\", StringType(), True),\n","    StructField(\"GeneticCoag\", StringType(), True),\n","    StructField(\"ConAntiCoagTx\", StringType(), True),\n","    StructField(\"AFibInd\", StringType(), True),\n","    StructField(\"AFibClass\", StringType(), True),\n","    StructField(\"ValvularAF\", StringType(), True),\n","    StructField(\"HxRHVD\", StringType(), True),\n","    StructField(\"HxMVReplace\", StringType(), True),\n","    StructField(\"MechValveMitPos\", StringType(), True),\n","    StructField(\"HxMVRepair\", StringType(), True),\n","    StructField(\"PrevAFibTerm\", StringType(), True),\n","    StructField(\"PrevAFibTermPC\", StringType(), True),\n","    StructField(\"PrevAFibTermDC\", StringType(), True),\n","    StructField(\"PrevAFibTermCA\", StringType(), True),\n","    StructField(\"AFibCathAblDate\", DateType(), True),  \n","    StructField(\"AFibPriorAblStrategyCode_Complex_Fractionated_Atrial_Electrogram\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Convergent_Procedure\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Cryoablation\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Empiric_LA_Linear_Lesions\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Focal_Ablation\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Ganglion_Plexus_Ablation\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Pulmonary_Vein_Isolation\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Segmental_PV_Ablation\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Rotor_Based_Mapping\", StringType(), True),\n","    StructField(\"AFibPriorAblStrategyCode_Wide_Area_Circumferential_Ablation\", StringType(), True),\n","    StructField(\"PrevAFibTermSA\", StringType(), True),\n","    StructField(\"AFibSurgAblDate\", DateType(), True),\n","    StructField(\"AFlutter\", StringType(), True),\n","    StructField(\"AFlutterType\", StringType(), True),\n","    StructField(\"PrevAFLTerm\", StringType(), True),\n","    StructField(\"PrevAFLTermPC\", StringType(), True),\n","    StructField(\"PrevAFLTermDC\", StringType(), True),\n","    StructField(\"PrevAFLTermCA\", StringType(), True),\n","    StructField(\"AFibFlutterCathAblDate\", DateType(), True), \n","    StructField(\"CardStrucInterv\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Aortic_Balloon_Valvuloplasty\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Transcatheter_Aortic_Valve_Replacement_TAVR\", StringType(), True),\n","    StructField(\"CardStrucIntervType_AV_Replacement_Surgical\", StringType(), True),\n","    StructField(\"CardStrucIntervType_AV_Repair_Surgical\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Mitral_Balloon_Valvuloplasty\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Transcatheter_Mitral_Valve_Repair_TMVR\", StringType(), True),\n","    StructField(\"CardStrucIntervType_MV_Replacement_Surgical\", StringType(), True),\n","    StructField(\"CardStrucIntervType_MV_Repair_Surgical\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Mitral_Annuloplasty_Ring_Surgical\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Mitral_Transcatheter_Valve_in_valve\", StringType(), True),\n","    StructField(\"CardStrucIntervType_ASD_Closure\", StringType(), True),\n","    StructField(\"CardStrucIntervType_PFO_Closure\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Pulmonic_Replacement\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Pulmonic_Repair\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Tricuspid_Replacement\", StringType(), True),\n","    StructField(\"CardStrucIntervType_Tricuspid_Repair\", StringType(), True),\n","    StructField(\"LAAOInterv\", StringType(), True),\n","    StructField(\"LAAOType_Epicardial_Ligation\", StringType(), True),\n","    StructField(\"LAAOType_Surgical_Amputation\", StringType(), True),\n","    StructField(\"LAAOType_Surgical_Ligation\", StringType(), True),\n","    StructField(\"LAAOType_Percutaneous_Occlusion\", StringType(), True),\n","    StructField(\"LAAOType_Surgical_Closure_Device\", StringType(), True),\n","    StructField(\"LAAOType_Surgical_Stapling\", StringType(), True),\n","    StructField(\"CM\", StringType(), True),\n","    StructField(\"PriorCMType_Non_ischemic_cardiomyopathy\", StringType(), True),\n","    StructField(\"PriorCMType_Ischemic_cardiomyopathy\", StringType(), True),\n","    StructField(\"PriorCMType_Restrictive_cardiomyopathy\", StringType(), True),\n","    StructField(\"PriorCMType_Hypertrophic_cardiomyopathy\", StringType(), True),\n","    StructField(\"PriorCMType_Other_cardiomyopathy_type\", StringType(), True),\n","    StructField(\"ChronicLungDisease\", StringType(), True),\n","    StructField(\"CAD\", StringType(), True),\n","    StructField(\"SleepApnea\", StringType(), True),\n","    StructField(\"SleepApneaRxFollowed\", StringType(), True),\n","    StructField(\"EpicardialAppCons\", StringType(), True),\n","    StructField(\"MedCond_Cardiac_Surgery\", StringType(), True),\n","    StructField(\"MedCond_Pericarditis\", StringType(), True),\n","    StructField(\"MedCond_Epicardial_Access\", StringType(), True),\n","    StructField(\"MedCond_Thoracic_Radiation_Therapy\", StringType(), True),\n","    StructField(\"MedCond_Pectus_Excavatum\", StringType(), True),\n","    StructField(\"MedCond_Epigastric_Surgery\", StringType(), True),\n","    StructField(\"MedCond_Autoimmune_Disease\", StringType(), True),\n","    StructField(\"MedCond_Hepatomegaly\", StringType(), True),\n","    StructField(\"MedCond_Hiatal_Hernia\", StringType(), True),\n","    StructField(\"LupusCons\", FloatType(), True),\n","    StructField(\"facility\", IntegerType(), True)\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_historyandrisk_df = spark.createDataFrame(combined_df_renamed, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_historyandrisk_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_historyandrisk\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":425,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:43.121124Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:29.2373784Z","execution_finish_time":"2024-03-06T17:09:32.7315062Z","parent_msg_id":"f3ae85e4-eccd-4ec8-81dc-d37d680c920d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 425, Finished, Available)"},"metadata":{}}],"execution_count":423,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"50859af5-6260-43bf-816e-5cddc64575bb"},{"cell_type":"markdown","source":["## Diagnostics"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8ad65171-af1b-446f-ad83-3c92d6969cbf"},{"cell_type":"code","source":["# load diagnostics from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Diagnostics.parquet\"\n","diagnostics = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    diagnostics[col] = diagnostics[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","diagnostics['facility'] = pd.to_numeric(diagnostics['facility'])\n","\n","# Apply the function to the specified columns\n","diagnostics['OtherID'] = diagnostics['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'TTEDate': '%Y-%m-%d',\n","    'CTImagingDate': '%Y-%m-%d',\n","    'MRDate': '%Y-%m-%d',\n","    'ICEDate':  '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        diagnostics[col] = pd.to_datetime(diagnostics[col], format=fmt)\n","    else:\n","        diagnostics[col] = pd.to_datetime(diagnostics[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":426,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:44.2969234Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:33.0716244Z","execution_finish_time":"2024-03-06T17:09:33.8431938Z","parent_msg_id":"5d793a5d-0e6d-416b-b8b9-f8e129ea6e8b"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 426, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":424,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"07bcab2d-be47-43fb-b5bc-e7a6fbf45c4d"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":427,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:45.04038Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:34.1459534Z","execution_finish_time":"2024-03-06T17:09:34.3745335Z","parent_msg_id":"2fb2aa38-0435-4a2c-9bc4-8d3943caa3f9"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 427, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":425,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"956a6d1a-c214-4e15-bb17-f7506043db59"},{"cell_type":"code","source":["# load atrialrhythm from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AtrialRhythm.parquet\"\n","atrialrhythm = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in [ 'OtherID', 'NCDRPatientID']:\n","    atrialrhythm[col] = atrialrhythm[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","atrialrhythm['facility'] = pd.to_numeric(atrialrhythm['facility'])\n","\n","# Apply the function to the specified columns\n","atrialrhythm['OtherID'] = atrialrhythm['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    # 'AFibSurgAblDate': '%Y-%m-%d', \n","    # 'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    # 'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    # 'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    # 'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        atrialrhythm[col] = pd.to_datetime(atrialrhythm[col], format=fmt)\n","    else:\n","        atrialrhythm[col] = pd.to_datetime(atrialrhythm[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":428,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:45.5201753Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:34.6657646Z","execution_finish_time":"2024-03-06T17:09:35.0160916Z","parent_msg_id":"1dd4263b-df69-4946-b7c1-a5e39c736716"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 428, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":426,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cc0f3f4e-b079-432b-beea-84c85f97e818"},{"cell_type":"code","source":["#start by appending atrialrhythm\n","\n","# List of columns to append from 'atrialrhythm'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'DCDate', \n","    'AtrialRhythm - Sinus node rhythm', \n","    'AtrialRhythm - Atrial fibrillation', \n","    'AtrialRhythm - Atrial tachycardia', \n","    'AtrialRhythm - Atrial flutter', \n","    'AtrialRhythm - Sinus arrest', \n","    'AtrialRhythm - Atrial paced', \n","    'AtrialRhythm - Not Documented', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = atrialrhythm[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(diagnostics.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'diagnostics' DataFrame\n","new_data_to_append = new_data_to_append[diagnostics.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([diagnostics, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":429,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:46.167665Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:35.3561821Z","execution_finish_time":"2024-03-06T17:09:35.5766693Z","parent_msg_id":"c729feaa-4923-4046-92be-e88fabcc88d5"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 429, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":427,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8316e0db-444c-41d0-a7d1-32238babfa09"},{"cell_type":"code","source":["\n","#Bring in needed columns to combined_df from in_hospital 1.3 df\n","\n","# List of columns from 'in_hospital' to bring into 'combined_df'\n","specified_columns = [\n","    'LVEFAssessed', \n","    'LVEF', \n","    'TTEPerf', \n","    'TTEDate', \n","    'BaselineImagingPerf', \n","    'CTPerformed', \n","    'CTImagingDate', \n","    'MRPerformed', \n","    'MRDate', \n","    'ICEPerf', \n","    'ICEDate'\n","\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index(['NCDRPatientID', 'facility', 'ArrivalDate'], inplace=True)\n","in_hospital.set_index(['NCDRPatientID', 'facility', 'ArrivalDate'], inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from in_hospital\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(in_hospital[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":430,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:46.699918Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:35.8857019Z","execution_finish_time":"2024-03-06T17:09:36.1219228Z","parent_msg_id":"5c4d1c17-4a39-43d5-99af-7c814dca6d3d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 430, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":428,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"bcb4b053-657a-4998-bf42-18b1e8573a7b"},{"cell_type":"code","source":["# Rename columns to be compatible with Delta table\n","columns_mapping = {\n","    'AtrialRhythm - Sinus node rhythm': 'AtrialRhythm_Sinus_node_rhythm', \n","    'AtrialRhythm - Atrial fibrillation': 'AtrialRhythm_Atrial_fibrillation', \n","    'AtrialRhythm - Atrial tachycardia': 'AtrialRhythm_Atrial_tachycardia',\n","    'AtrialRhythm - Atrial flutter': 'AtrialRhythm_Atrial_flutter', \n","    'AtrialRhythm - Sinus arrest': 'AtrialRhythm_Sinus_arrest', \n","    'AtrialRhythm - Atrial paced': 'AtrialRhythm_Atrial_paced', \n","    'AtrialRhythm - Not Documented': 'AtrialRhythm_Not_Documented'\n","}\n","\n","# Rename the columns\n","combined_df_renamed = combined_df.rename(columns=columns_mapping)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":431,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:47.3748403Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:36.4895773Z","execution_finish_time":"2024-03-06T17:09:36.7139963Z","parent_msg_id":"d5448d9c-43ea-4460-b907-320262a28082"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 431, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":429,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"17c31162-deb1-4593-a517-9e003f024a88"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoDiagnosticsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly based on the laao_diagnostics table columns\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"AtrialRhythm_Sinus_node_rhythm\", StringType(), True),\n","    StructField(\"AtrialRhythm_Atrial_fibrillation\", StringType(), True),\n","    StructField(\"AtrialRhythm_Atrial_tachycardia\", StringType(), True),\n","    StructField(\"AtrialRhythm_Atrial_flutter\", StringType(), True),\n","    StructField(\"AtrialRhythm_Sinus_arrest\", StringType(), True),\n","    StructField(\"AtrialRhythm_Atrial_paced\", StringType(), True),\n","    StructField(\"AtrialRhythm_Not_Documented\", StringType(), True),\n","    StructField(\"LVEFAssessed\", StringType(), True),\n","    StructField(\"LVEF\", FloatType(), True),\n","    StructField(\"TTEPerf\", StringType(), True),\n","    StructField(\"TTEDate\", DateType(), True),\n","    StructField(\"BaselineImagingPerf\", StringType(), True),\n","    StructField(\"CTPerformed\", StringType(), True),\n","    StructField(\"CTImagingDate\", DateType(), True),\n","    StructField(\"MRPerformed\", StringType(), True),\n","    StructField(\"MRDate\", DateType(), True),\n","    StructField(\"ICEPerf\", StringType(), True),\n","    StructField(\"ICEDate\", DateType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","combined_spark_df = spark.createDataFrame(combined_df_renamed, schema=schema)\n","\n","# Write the DataFrame to the Delta table with the defined schema\n","combined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_diagnostics\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":432,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:47.9646266Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:37.0492685Z","execution_finish_time":"2024-03-06T17:09:40.5062762Z","parent_msg_id":"d1ca45f5-a2f5-4914-b2e0-5cb59e4550cd"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 432, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":430,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e4c7a70b-5ae4-43a1-ac06-28728ab0f341"},{"cell_type":"markdown","source":["## PreProcLabs"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a83c157b-d4f4-41d9-afc2-9bc5fabffa9d"},{"cell_type":"code","source":["# load preproclabs from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PreProcLabs.parquet\"\n","preproclabs = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    preproclabs[col] = preproclabs[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","preproclabs['facility'] = pd.to_numeric(preproclabs['facility'])\n","\n","# Apply the function to the specified columns\n","preproclabs['OtherID'] = preproclabs['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        preproclabs[col] = pd.to_datetime(preproclabs[col], format=fmt)\n","    else:\n","        preproclabs[col] = pd.to_datetime(preproclabs[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":433,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:48.5446123Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:40.8202697Z","execution_finish_time":"2024-03-06T17:09:41.0383609Z","parent_msg_id":"8a9a30dd-7e9f-4615-9b90-042c310ff073"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 433, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":431,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8f6e6477-f857-4723-a204-ca2dd4ea90c4"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":434,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:49.2750269Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:41.4120869Z","execution_finish_time":"2024-03-06T17:09:41.6359914Z","parent_msg_id":"0d3c0827-a126-4b8a-ae3b-cdbf45e4db5e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 434, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":432,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0f913d3f-7e2a-4ffc-84e3-2e53a82d0065"},{"cell_type":"code","source":["#start by appending in_hospital to get natrual key columns\n","\n","# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'DCDate', \n","    'Height', \n","    'Weight', \n","    'Pulse', \n","    'SystolicBP', \n","    'DiastolicBP', \n","    'HGB', \n","    'HGBND', \n","    'PT', \n","    'PTND', \n","    'INR', \n","    'INRND', \n","    'PreProcCreat', \n","    'PreProcCreatND', \n","    'Albumin', \n","    'Albumin_ND', \n","    'PlateletCt', \n","    'PlateletCtND', \n","    'RankinScale', \n","    'PostProc_RankinScaleNA', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(preproclabs.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'preproclabs' DataFrame\n","new_data_to_append = new_data_to_append[preproclabs.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([preproclabs, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":435,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:50.1744701Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:41.9693569Z","execution_finish_time":"2024-03-06T17:09:42.1938874Z","parent_msg_id":"c57b3336-1272-4348-b6f8-cd8b80ab41ba"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 435, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":433,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b58e2a6d-78f0-4897-8d6c-f7f1948baa6c"},{"cell_type":"code","source":["combined_df.info()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":436,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:51.0838646Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:42.4994403Z","execution_finish_time":"2024-03-06T17:09:42.7785359Z","parent_msg_id":"1e694050-255f-444f-adaa-225c6c107512"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 436, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3598 entries, 0 to 3597\nData columns (total 28 columns):\n #   Column                  Non-Null Count  Dtype         \n---  ------                  --------------  -----         \n 0   NCDRPatientID           3598 non-null   object        \n 1   LastName                3598 non-null   object        \n 2   FirstName               3598 non-null   object        \n 3   MidName                 2894 non-null   object        \n 4   OtherID                 3598 non-null   object        \n 5   ArrivalDate             3598 non-null   datetime64[ns]\n 6   DCDate                  3598 non-null   datetime64[ns]\n 7   Height                  3592 non-null   float64       \n 8   Weight                  3595 non-null   float64       \n 9   Pulse                   3588 non-null   float64       \n 10  SystolicBP              3590 non-null   float64       \n 11  DiastolicBP             3590 non-null   float64       \n 12  HGB                     3109 non-null   float64       \n 13  HGBND                   3598 non-null   object        \n 14  PT                      1767 non-null   float64       \n 15  PTND                    3598 non-null   object        \n 16  INR                     1773 non-null   float64       \n 17  INRND                   3598 non-null   object        \n 18  PreProcCreat            3130 non-null   float64       \n 19  PreProcCreatND          3598 non-null   object        \n 20  Albumin                 1736 non-null   float64       \n 21  Albumin_ND              3598 non-null   object        \n 22  PlateletCt              3081 non-null   float64       \n 23  PlateletCtND            3598 non-null   object        \n 24  RankinScale             541 non-null    object        \n 25  PostProc_RankinScaleNA  3598 non-null   object        \n 26  facility                3598 non-null   int64         \n 27  Pat_ID                  3598 non-null   object        \ndtypes: datetime64[ns](2), float64(11), int64(1), object(14)\nmemory usage: 787.2+ KB\n"]}],"execution_count":434,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fed9c6c1-a2aa-44a9-9e67-191384503a93"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LAAPreprocLabsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly for the laao_preproclabs table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"Height\", FloatType(), True),\n","    StructField(\"Weight\", FloatType(), True),\n","    StructField(\"Pulse\", FloatType(), True),\n","    StructField(\"SystolicBP\", FloatType(), True),\n","    StructField(\"DiastolicBP\", FloatType(), True),\n","    StructField(\"HGB\", FloatType(), True),\n","    StructField(\"HGBND\", StringType(), True),\n","    StructField(\"PT\", FloatType(), True),\n","    StructField(\"PTND\", StringType(), True),\n","    StructField(\"INR\", FloatType(), True),\n","    StructField(\"INRND\", StringType(), True),\n","    StructField(\"PreProcCreat\", FloatType(), True),\n","    StructField(\"PreProcCreatND\", StringType(), True),\n","    StructField(\"Albumin\", FloatType(), True),\n","    StructField(\"Albumin_ND\", StringType(), True),\n","    StructField(\"PlateletCt\", FloatType(), True),\n","    StructField(\"PlateletCtND\", StringType(), True),\n","    StructField(\"RankinScale\", StringType(), True),\n","    StructField(\"PostProc_RankinScaleNA\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True)\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","preproclabs_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","preproclabs_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_preproclabs\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":437,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:51.7060597Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:43.1087233Z","execution_finish_time":"2024-03-06T17:09:46.6061876Z","parent_msg_id":"a8478924-1509-4e15-95ff-bfdb928c9dc5"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 437, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":435,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"3f1dcfc3-c273-48f1-813b-0e2b61ef7a98"},{"cell_type":"markdown","source":["## PreProcMeds"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"85bc1f41-18d7-41c0-89bc-1541546614fc"},{"cell_type":"code","source":["# load preprocmeds from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PreProcMeds.parquet\"\n","preprocmeds = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    preprocmeds[col] = preprocmeds[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","preprocmeds['facility'] = pd.to_numeric(preprocmeds['facility'])\n","\n","# Apply the function to the specified columns\n","preprocmeds['OtherID'] = preprocmeds['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        preprocmeds[col] = pd.to_datetime(preprocmeds[col], format=fmt)\n","    else:\n","        preprocmeds[col] = pd.to_datetime(preprocmeds[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":438,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:52.3692892Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:46.9199187Z","execution_finish_time":"2024-03-06T17:09:47.1387543Z","parent_msg_id":"ea92fa3a-5958-4ef7-91d5-8d6ab343c03d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 438, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":436,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9f68b18f-0605-4a40-9cd1-4e66fcd82e9f"},{"cell_type":"code","source":["# load medid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/MedID.parquet\"\n","medid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    medid[col] = medid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","medid['facility'] = pd.to_numeric(medid['facility'])\n","\n","# Apply the function to the specified columns\n","medid['OtherID'] = medid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        medid[col] = pd.to_datetime(medid[col], format=fmt)\n","    else:\n","        medid[col] = pd.to_datetime(medid[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":439,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:52.9442597Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:47.7003389Z","execution_finish_time":"2024-03-06T17:09:47.9327746Z","parent_msg_id":"9b9ce467-84ad-4e56-a724-fe6c1d59df79"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 439, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":437,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0c8376d3-0b47-400a-9932-c83e85711889"},{"cell_type":"code","source":["# pivot (melt) medid to make it longform\n","\n","# Rename the columns to match v 1.4 medication names\n","MedID_renamed = medid.rename(columns={\n","    'Fondaparinux': 'Fondaparinux',\n","    'Heparin Derivative': 'Heparin Derivative',\n","    'Low Molecular Wt Heparin': 'Low Molecular Weight Heparin',\n","    'Unfractionated Heparin': 'Unfractionated Heparin',\n","    'Warfarin': 'Warfarin',\n","    'Aspirin (81-100 mg)': 'Aspirin 81 to 100 mg',\n","    'Aspirin (101-324 mg)': 'Aspirin 101 to 324 mg',\n","    'Aspirin (325 mg)': 'Aspirin 325 mg',\n","    'Aspirin/Dipyridamole': 'Aspirin/Dipyridamole',\n","    'Vorapaxar': 'Vorapaxar',\n","    'Apixaban': 'Apixaban',\n","    'Dabigatran': 'Dabigatran',\n","    'Edoxaban': 'Edoxaban',\n","    'Rivaroxaban': 'Rivaroxaban',\n","    'Cangrelor': 'Cangrelor',\n","    'Clopidogrel': 'Clopidogrel',\n","    'Other P2Y12 Inhibitor': 'Other P2Y12',\n","    'Prasugrel': 'Prasugrel',\n","    'Ticagrelor': 'Ticagrelor',\n","    'Ticlopidine': 'Ticlopidine',\n","    'Aggrenox': 'Aggrenox'\n","})\n","\n","# Now proceed to melt the dataframe as before\n","id_vars = ['NCDRPatientID', 'LastName', 'FirstName', 'MidName', 'OtherID', 'ArrivalDate', 'DCDate', 'facility', 'Pat_ID']\n","\n","# Use the melt function to pivot the dataframe\n","MedID_melted = pd.melt(frame=MedID_renamed, id_vars=id_vars, var_name='MedID', value_name='PreMedAdmin')\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":440,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:53.3708759Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:48.2516657Z","execution_finish_time":"2024-03-06T17:09:48.4793109Z","parent_msg_id":"2d8a9a85-0b02-4b80-a5e9-19672ccedcd4"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 440, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":438,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cc5639d1-b94a-4c32-ab77-4647eabdf5f0"},{"cell_type":"code","source":["# Reorder MedID_melted columns to match preprocmeds\n","MedID_melted = MedID_melted[preprocmeds.columns]\n","\n","# Then concatenate\n","combined_df = pd.concat([preprocmeds, MedID_melted], axis=0, ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":441,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:54.54483Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:48.8532612Z","execution_finish_time":"2024-03-06T17:09:49.0914077Z","parent_msg_id":"13378c31-f997-4883-a03c-725c3eb7f5b0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 441, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":439,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"177c1319-4310-48ca-a3bb-ec2eb10b988d"},{"cell_type":"code","source":["combined_df.info()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":442,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:55.5087616Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:49.3964482Z","execution_finish_time":"2024-03-06T17:09:49.6099194Z","parent_msg_id":"821b0434-5027-4988-bd95-8772cd6b195f"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 442, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 77140 entries, 0 to 77139\nData columns (total 11 columns):\n #   Column         Dtype         \n---  ------         -----         \n 0   NCDRPatientID  object        \n 1   LastName       object        \n 2   FirstName      object        \n 3   MidName        object        \n 4   OtherID        object        \n 5   ArrivalDate    datetime64[ns]\n 6   DCDate         datetime64[ns]\n 7   MedID          object        \n 8   PreMedAdmin    object        \n 9   facility       int64         \n 10  Pat_ID         object        \ndtypes: datetime64[ns](2), int64(1), object(8)\nmemory usage: 6.5+ MB\n"]}],"execution_count":440,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"857442fb-2999-4533-af00-95bf4aafa80c"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoPreprocmedsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly based on the new table requirements\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"MedID\", StringType(), True),\n","    StructField(\"PreMedAdmin\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True)\n","])\n","\n","# Assuming `preprocmeds_df` is your pandas DataFrame containing the data\n","preprocmeds_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","preprocmeds_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_preprocmeds\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":443,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:56.1390294Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:49.9639974Z","execution_finish_time":"2024-03-06T17:09:54.7390251Z","parent_msg_id":"e74c4a83-3923-44a5-b856-c365970a9ec8"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 443, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":441,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6da3a8db-313a-4584-af35-d054c1d33f26"},{"cell_type":"markdown","source":["## ProcInfo"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6bba97c2-39ee-4f01-88c5-3652de88c73a"},{"cell_type":"markdown","source":["### Define Dataframes needed"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4a2612ce-a2a2-44b4-9cbd-52b1af3bfcff"},{"cell_type":"code","source":["# load procinfo from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/ProcInfo.parquet\"\n","procinfo = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID', 'OHSConversionReason']:\n","    procinfo[col] = procinfo[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","procinfo['facility'] = pd.to_numeric(procinfo['facility'])\n","\n","# Apply the function to the specified columns\n","procinfo['OtherID'] = procinfo['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        procinfo[col] = pd.to_datetime(procinfo[col], format=fmt)\n","    else:\n","        procinfo[col] = pd.to_datetime(procinfo[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":444,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:56.7352091Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:55.0586338Z","execution_finish_time":"2024-03-06T17:09:55.3054495Z","parent_msg_id":"ed454078-50a7-44e1-9950-b54028272d76"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 444, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":442,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cd54d75e-3a68-4019-80de-1d62cbffc0e6"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":445,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:57.1638887Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:55.6434449Z","execution_finish_time":"2024-03-06T17:09:55.8548866Z","parent_msg_id":"d3144fb4-e659-4aa8-9bd1-4dd6afe53b1b"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 445, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":443,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4a7e9810-194f-4472-a08c-72498feacde3"},{"cell_type":"code","source":["# load proclaaoind from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcLAAOInd.parquet\"\n","proclaaoind = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    proclaaoind[col] = proclaaoind[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","proclaaoind['facility'] = pd.to_numeric(proclaaoind['facility'])\n","\n","# Apply the function to the specified columns\n","proclaaoind['OtherID'] = proclaaoind['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        proclaaoind[col] = pd.to_datetime(proclaaoind[col], format=fmt)\n","    else:\n","        proclaaoind[col] = pd.to_datetime(proclaaoind[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":446,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:58.1085872Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:56.1790526Z","execution_finish_time":"2024-03-06T17:09:56.386703Z","parent_msg_id":"c889ea99-1762-4ccc-b6cb-7b5ecee307ab"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 446, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":444,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8761c092-1562-4eda-9dd0-03c88f13a57c"},{"cell_type":"code","source":["# load proccanceledreason from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcCanceledReason.parquet\"\n","proccanceledreason = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    proccanceledreason[col] = proccanceledreason[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","proccanceledreason['facility'] = pd.to_numeric(proccanceledreason['facility'])\n","\n","# Apply the function to the specified columns\n","proccanceledreason['OtherID'] = proccanceledreason['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureStopDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        proccanceledreason[col] = pd.to_datetime(proccanceledreason[col], format=fmt)\n","    else:\n","        proccanceledreason[col] = pd.to_datetime(proccanceledreason[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":447,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:08:59.4103732Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:56.7018682Z","execution_finish_time":"2024-03-06T17:09:56.9355512Z","parent_msg_id":"23298217-d37b-4a91-9537-6777ba7b1362"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 447, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":445,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c1ecec02-b8a5-468e-baf0-d56a165e9606"},{"cell_type":"code","source":["# load procabortedreason from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ProcAbortedReason.parquet\"\n","procabortedreason = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    procabortedreason[col] = procabortedreason[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","procabortedreason['facility'] = pd.to_numeric(procabortedreason['facility'])\n","\n","# Apply the function to the specified columns\n","procabortedreason['OtherID'] = procabortedreason['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureStopDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        procabortedreason[col] = pd.to_datetime(procabortedreason[col], format=fmt)\n","    else:\n","        procabortedreason[col] = pd.to_datetime(procabortedreason[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":448,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:01.9183018Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:57.2462653Z","execution_finish_time":"2024-03-06T17:09:57.4738901Z","parent_msg_id":"7182ee33-6de3-4971-8adb-e17f46267c02"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 448, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":446,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"202843bf-a013-42d6-9b80-90afbcbcd49f"},{"cell_type":"code","source":["# load guidancemethodid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/GuidanceMethodID.parquet\"\n","guidancemethodid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    guidancemethodid[col] = guidancemethodid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","guidancemethodid['facility'] = pd.to_numeric(guidancemethodid['facility'])\n","\n","# Apply the function to the specified columns\n","guidancemethodid['OtherID'] = guidancemethodid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        guidancemethodid[col] = pd.to_datetime(guidancemethodid[col], format=fmt)\n","    else:\n","        guidancemethodid[col] = pd.to_datetime(guidancemethodid[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":449,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:04.949242Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:57.8162192Z","execution_finish_time":"2024-03-06T17:09:58.0619261Z","parent_msg_id":"787e1946-1abc-4dd6-b192-aed54874e748"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 449, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":447,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6b62eaa1-5427-4c23-90fe-2a6ed2160538"},{"cell_type":"code","source":["# load concomitantproctype from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/ConcomitantProcType.parquet\"\n","concomitantproctype = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    concomitantproctype[col] = concomitantproctype[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","concomitantproctype['facility'] = pd.to_numeric(concomitantproctype['facility'])\n","\n","# Apply the function to the specified columns\n","concomitantproctype['OtherID'] = concomitantproctype['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        concomitantproctype[col] = pd.to_datetime(concomitantproctype[col], format=fmt)\n","    else:\n","        concomitantproctype[col] = pd.to_datetime(concomitantproctype[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":450,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:09.3352396Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:58.3649046Z","execution_finish_time":"2024-03-06T17:09:58.6036168Z","parent_msg_id":"e4372e25-c7a9-441e-b2f4-4640b0d7fc83"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 450, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":448,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"dec4a5ca-ddcf-4305-ac69-26c206b21e13"},{"cell_type":"markdown","source":["### Begin Append and Merging Dataframes"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3d61cc9d-8ae6-432b-bf4f-7fbae0715164"},{"cell_type":"code","source":["# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'ProcedureLocation', \n","    'Anesthesia', \n","    'DCDate', \n","    'TEEPerfLAAO', \n","    'TEEDateLAAO', \n","    'ProcAtrialThromDetect', \n","    'LAAO_OrWid', \n","    'ProcedureEndDateTime', \n","    'ResidualLeak', \n","    'ResidualLeakNA', \n","    'OHSConversion', \n","    'OHSConversionReason', \n","    'FluoroDoseKerm', \n","    'ContrastVol', \n","    'FluoroDoseDAP2', \n","    'IntraProcAnticoag', \n","    'Warfarin', \n","    'ProcHeparin2', \n","    'ProcHeparinInitAdminTime', \n","    'ProcBivalirudin2', \n","    'ProcOtherAnticoag2', \n","    'AnticoagReversal', \n","    'facility', \n","    'FluoroDoseDAP2_Units', \n","    'FluoroDoseKerm_Units'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(procinfo.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'procinfo' DataFrame\n","new_data_to_append = new_data_to_append[procinfo.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([procinfo, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":451,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:13.3550527Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:58.9209978Z","execution_finish_time":"2024-03-06T17:09:59.1415011Z","parent_msg_id":"100303b6-1cd7-424b-a606-d94c6eeb8649"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 451, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":449,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"99533eed-4a91-42f2-8e56-88a0c10c5601"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from proclaaoind 1.3 df\n","\n","\n","# List of columns from 'proclaaoind' to bring into 'combined_df'\n","specified_columns = [\n","    'ProcLAAOInd - High fall risk', \n","    'ProcLAAOInd - History of major bleed', \n","    'ProcLAAOInd - Increased thromboembolic stroke risk', \n","    'ProcLAAOInd - Labile INR', \n","    'ProcLAAOInd - Non-compliance with anticoagulation therapy', \n","    'ProcLAAOInd - Patient preference'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","proclaaoind.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from proclaaoind\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(proclaaoind[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":452,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:17.9698194Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:59.4344791Z","execution_finish_time":"2024-03-06T17:09:59.6720835Z","parent_msg_id":"8dc4033e-72c5-4932-9a1c-89e80d0c4482"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 452, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":450,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d14db17f-7d68-4703-aaa2-e8cb65a030c5"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from proccanceledreason 1.3 df\n","\n","# List of columns from 'proccanceledreason' to bring into 'combined_df'\n","specified_columns = [\n","    'ProcCanceled', \n","    'ProcCanceledReason - Anatomy not conducive for implant', \n","    'ProcCanceledReason - Appendage too large (for device implant)', \n","    'ProcCanceledReason - Appendage too small (for device implant)', \n","    'ProcCanceledReason - Catherization challenge', \n","    'ProcCanceledReason - Decompensation in patient condition', \n","    'ProcCanceledReason - Epicardial access issue', \n","    'ProcCanceledReason - Thrombus detected', \n","    'ProcCanceledReason - Unanticipated patient condition', \n","    'ProcCanceledReason -  Patient/Family choice'\n","\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","proccanceledreason.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from proccanceledreason\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(proccanceledreason[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":453,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:21.3300158Z","session_start_time":null,"execution_start_time":"2024-03-06T17:09:59.9945378Z","execution_finish_time":"2024-03-06T17:10:00.2123241Z","parent_msg_id":"fd4dd473-b25d-4dd5-904c-6503c7ee7f9e"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 453, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":451,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4b4335bc-9b39-42e7-8d66-927645469b03"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from procabortedreason 1.3 df\n","\n","\n","# List of columns from 'procabortedreason' to bring into 'combined_df'\n","specified_columns = [\n","    'ProcAborted', \n","    'ProcAbortedReason - Anatomy not conducive for implant', \n","    'ProcAbortedReason - Appendage too large (for device implant)', \n","    'ProcAbortedReason - Appendage too small (for device implant)', \n","    'ProcAbortedReason - Catherization challenge', \n","    'ProcAbortedReason - Decompensation in patient condition', \n","    'ProcAbortedReason -  Device related', \n","    'ProcAbortedReason - Transcatheter device retrieval', \n","    'ProcAbortedReason - Device release criteria not met', \n","    'ProcAbortedReason - Epicardial access issue', \n","    'ProcAbortedReason - Surgical device retrieval', \n","    'ProcAbortedReason - Device associated thrombus developed during procedure', \n","    'ProcAbortedReason - Unanticipated patient condition', \n","    'ProcAbortedReason - Patient/Family choice'\n","\n","\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","procabortedreason.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from procabortedreason\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(procabortedreason[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":454,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:23.4667736Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:00.5486086Z","execution_finish_time":"2024-03-06T17:10:00.7621666Z","parent_msg_id":"71251207-3e79-4d0c-b0e3-f71d00d9f782"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 454, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":452,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d1904a7b-5994-4ad3-ae39-098827737553"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from guidancemethodid 1.3 df\n","\n","\n","# List of columns from 'guidancemethodid' to bring into 'combined_df'\n","specified_columns = [\n","    'GuidanceMethodID - Intracardiac three dimensional echocardiography', \n","    'GuidanceMethodID - Electro Anatomic Mapping', \n","    'GuidanceMethodID - Fluoroscopy', \n","    'GuidanceMethodID - Transesophageal Echocardiogram (TEE)'\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","guidancemethodid.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from guidancemethodid\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(guidancemethodid[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":455,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:26.6659832Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:01.0657041Z","execution_finish_time":"2024-03-06T17:10:01.2741372Z","parent_msg_id":"81d34d08-7132-44c8-b870-ed43cbed6b7d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 455, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":453,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1b887f4d-cb4d-46dd-9545-0966053baede"},{"cell_type":"code","source":["#Bring in needed columns to combined_df from concomitantproctype 1.3 df\n","\n","\n","# List of columns from 'concomitantproctype' to bring into 'combined_df'\n","specified_columns = [\n","    'ConcomitantProcPerf', \n","    'ConcomitantProcType - AFib Ablation', \n","    'ConcomitantProcType - ICD', \n","    'ConcomitantProcType - PCI', \n","    'ConcomitantProcType - TAVR', \n","    'ConcomitantProcType - TMVR', \n","    'ConcomitantProcType - ASD Closure Congenital', \n","    'ConcomitantProcType - ASD Closure Iatrogenic', \n","    'ConcomitantProcType - PFO Closure Congenital' \n","\n","]\n","\n","# Set the index of both dataframes to the key columns for alignment\n","combined_df.set_index('Pat_ID', inplace=True)\n","concomitantproctype.set_index('Pat_ID', inplace=True)\n","\n","# Update only the specified columns in combined_df with the values from concomitantproctype\n","for column in specified_columns:\n","    if column in combined_df.columns:\n","        combined_df[column].update(concomitantproctype[column])\n","\n","# Reset the index to return to the original structure\n","combined_df.reset_index(inplace=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":456,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:31.656448Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:01.5929123Z","execution_finish_time":"2024-03-06T17:10:01.8274003Z","parent_msg_id":"165fab7c-8b7b-4fa1-bc04-c32b73b05c6a"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 456, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":454,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fe03546d-5c10-47b7-a14c-bc4cf07d5611"},{"cell_type":"code","source":["columns_mapping = {\n","    'ProcLAAOInd - High fall risk': 'ProcLAAOInd_High_Fall_Risk',\n","    'ProcLAAOInd - History of major bleed': 'ProcLAAOInd_History_Of_Major_Bleed',\n","    'ProcLAAOInd - Increased thromboembolic stroke risk': 'ProcLAAOInd_Increased_Thromboembolic_Stroke_Risk',\n","    'ProcLAAOInd - Labile INR': 'ProcLAAOInd_Labile_INR',\n","    'ProcLAAOInd - Non-compliance with anticoagulation therapy': 'ProcLAAOInd_Non_Compliance_With_Anticoagulation_Therapy',\n","    'ProcLAAOInd - Patient preference': 'ProcLAAOInd_Patient_Preference',\n","    'ProcCanceledReason - Anatomy not conducive for implant': 'ProcCanceledReason_Anatomy_Not_Conducive_For_Implant',\n","    'ProcCanceledReason - Appendage too large (for device implant)': 'ProcCanceledReason_Appendage_Too_Large_For_Device_Implant',\n","    'ProcCanceledReason - Appendage too small (for device implant)': 'ProcCanceledReason_Appendage_Too_Small_For_Device_Implant',\n","    'ProcCanceledReason - Catherization challenge': 'ProcCanceledReason_Catherization_Challenge',\n","    'ProcCanceledReason - Decompensation in patient condition': 'ProcCanceledReason_Decompensation_In_Patient_Condition',\n","    'ProcCanceledReason - Epicardial access issue': 'ProcCanceledReason_Epicardial_Access_Issue',\n","    'ProcCanceledReason - Thrombus detected': 'ProcCanceledReason_Thrombus_Detected',\n","    'ProcCanceledReason - Unanticipated patient condition': 'ProcCanceledReason_Unanticipated_Patient_Condition',\n","    'ProcCanceledReason -  Patient/Family choice': 'ProcCanceledReason_Patient_Family_Choice',\n","    'ProcAbortedReason - Anatomy not conducive for implant': 'ProcAbortedReason_Anatomy_Not_Conducive_For_Implant',\n","    'ProcAbortedReason - Appendage too large (for device implant)': 'ProcAbortedReason_Appendage_Too_Large_For_Device_Implant',\n","    'ProcAbortedReason - Appendage too small (for device implant)': 'ProcAbortedReason_Appendage_Too_Small_For_Device_Implant',\n","    'ProcAbortedReason - Catherization challenge': 'ProcAbortedReason_Catherization_Challenge',\n","    'ProcAbortedReason - Decompensation in patient condition': 'ProcAbortedReason_Decompensation_In_Patient_Condition',\n","    'ProcAbortedReason -  Device related': 'ProcAbortedReason_Device_Related',\n","    'ProcAbortedReason - Transcatheter device retrieval': 'ProcAbortedReason_Transcatheter_Device_Retrieval',\n","    'ProcAbortedReason - Device release criteria not met': 'ProcAbortedReason_Device_Release_Criteria_Not_Met',\n","    'ProcAbortedReason - Epicardial access issue': 'ProcAbortedReason_Epicardial_Access_Issue',\n","    'ProcAbortedReason - Surgical device retrieval': 'ProcAbortedReason_Surgical_Device_Retrieval',\n","    'ProcAbortedReason - Device associated thrombus developed during procedure': 'ProcAbortedReason_Device_Associated_Thrombus_Developed_During_Procedure',\n","    'ProcAbortedReason - Unanticipated patient condition': 'ProcAbortedReason_Unanticipated_Patient_Condition',\n","    'ProcAbortedReason - Patient/Family choice': 'ProcAbortedReason_Patient_Family_Choice',\n","    'GuidanceMethodID - Intracardiac three dimensional echocardiography': 'GuidanceMethodID_Intracardiac_Three_Dimensional_Echocardiography',\n","    'GuidanceMethodID - Electro Anatomic Mapping': 'GuidanceMethodID_Electro_Anatomic_Mapping',\n","    'GuidanceMethodID - Fluoroscopy': 'GuidanceMethodID_Fluoroscopy',\n","    'GuidanceMethodID - Transesophageal Echocardiogram (TEE)': 'GuidanceMethodID_Transesophageal_Echocardiogram_TEE',\n","    'ConcomitantProcType - AFib Ablation': 'ConcomitantProcType_AFib_Ablation',\n","    'ConcomitantProcType - ICD': 'ConcomitantProcType_ICD',\n","    'ConcomitantProcType - PCI': 'ConcomitantProcType_PCI',\n","    'ConcomitantProcType - TAVR': 'ConcomitantProcType_TAVR',\n","    'ConcomitantProcType - TMVR': 'ConcomitantProcType_TMVR',\n","    'ConcomitantProcType - ASD Closure Congenital': 'ConcomitantProcType_ASD_Closure_Congenital',\n","    'ConcomitantProcType - ASD Closure Iatrogenic': 'ConcomitantProcType_ASD_Closure_Iatrogenic',\n","    'ConcomitantProcType - PFO Closure Congenital': 'ConcomitantProcType_PFO_Closure_Congenital',\n","}\n","\n","# Rename the columns\n","combined_df_renamed = combined_df.rename(columns=columns_mapping)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":457,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:38.346288Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:02.1220853Z","execution_finish_time":"2024-03-06T17:10:02.3795233Z","parent_msg_id":"00f6b5a2-a969-4f03-8805-2af8e10dbcb1"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 457, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":455,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d2c5857a-fe99-4737-86ee-8c1d5b909c1e"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoProcInfoIngestion\").getOrCreate()\n","\n","# Define the schema explicitly with all column names and types\n","schema = StructType([\n","    StructField(\"Pat_ID\", StringType(), True),\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"TEEPerfLAAO\", StringType(), True),\n","    StructField(\"TEEDateLAAO\", DateType(), True),\n","    StructField(\"ProcAtrialThromDetect\", StringType(), True),\n","    StructField(\"LAAO_OrWid\", DoubleType(), True),\n","    StructField(\"ProcedureEndDateTime\", TimestampType(), True),\n","    StructField(\"SDM_Proc\", StringType(), True),\n","    StructField(\"SDM_Tool\", StringType(), True),\n","    StructField(\"SDM_Tool_Name\", StringType(), True),\n","    StructField(\"ProcedureLocation\", StringType(), True),\n","    StructField(\"Anesthesia\", StringType(), True),\n","    StructField(\"ProcLAAOInd_High_Fall_Risk\", StringType(), True),\n","    StructField(\"ProcLAAOInd_History_Of_Major_Bleed\", StringType(), True),\n","    StructField(\"ProcLAAOInd_Clinically_significant_bleeding_risk_Other_than_those_listed_here\", StringType(), True),\n","    StructField(\"ProcLAAOInd_Increased_Thromboembolic_Stroke_Risk\", StringType(), True),\n","    StructField(\"ProcLAAOInd_Labile_INR\", StringType(), True),\n","    StructField(\"ProcLAAOInd_Non_Compliance_With_Anticoagulation_Therapy\", StringType(), True),\n","    StructField(\"ProcLAAOInd_Patient_Preference\", StringType(), True),\n","    StructField(\"ProcCanceled\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Anatomy_Not_Conducive_For_Implant\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Appendage_Too_Large_For_Device_Implant\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Appendage_Too_Small_For_Device_Implant\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Catherization_Challenge\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Decompensation_In_Patient_Condition\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Epicardial_Access_Issue\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Thrombus_Detected\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Unanticipated_Patient_Condition\", StringType(), True),\n","    StructField(\"ProcCanceledReason_Patient_Family_Choice\", StringType(), True),\n","    StructField(\"ProcAborted\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Anatomy_Not_Conducive_For_Implant\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Appendage_Too_Large_For_Device_Implant\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Appendage_Too_Small_For_Device_Implant\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Catherization_Challenge\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Decompensation_In_Patient_Condition\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Device_Related\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Transcatheter_Device_Retrieval\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Device_Release_Criteria_Not_Met\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Epicardial_Access_Issue\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Surgical_Device_Retrieval\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Device_Associated_Thrombus_Developed_During_Procedure\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Unanticipated_Patient_Condition\", StringType(), True),\n","    StructField(\"ProcAbortedReason_Patient_Family_Choice\", StringType(), True),\n","    StructField(\"ResidualLeak\", DoubleType(), True),\n","    StructField(\"ResidualLeakNA\", StringType(), True),\n","    StructField(\"GuidanceMethodID_Intracardiac_Three_Dimensional_Echocardiography\", StringType(), True),\n","    StructField(\"GuidanceMethodID_Electro_Anatomic_Mapping\", StringType(), True),\n","    StructField(\"GuidanceMethodID_Fluoroscopy\", StringType(), True),\n","    StructField(\"GuidanceMethodID_Transesophageal_Echocardiogram_TEE\", StringType(), True),\n","    StructField(\"OHSConversion\", StringType(), True),\n","    StructField(\"OHSConversionReason\", StringType(), True),\n","    StructField(\"ConcomitantProcPerf\", StringType(), True),\n","    StructField(\"ConcomitantProcType_AFib_Ablation\", StringType(), True),\n","    StructField(\"ConcomitantProcType_ICD\", StringType(), True),\n","    StructField(\"ConcomitantProcType_PCI\", StringType(), True),\n","    StructField(\"ConcomitantProcType_TAVR\", StringType(), True),\n","    StructField(\"ConcomitantProcType_TMVR\", StringType(), True),\n","    StructField(\"ConcomitantProcType_ASD_Closure_Congenital\", StringType(), True),\n","    StructField(\"ConcomitantProcType_ASD_Closure_Iatrogenic\", StringType(), True),\n","    StructField(\"ConcomitantProcType_PFO_Closure_Congenital\", StringType(), True),\n","    StructField(\"FluoroDoseKerm\", DoubleType(), True),\n","    StructField(\"ContrastVol\", DoubleType(), True),\n","    StructField(\"FluoroDoseDAP2\", DoubleType(), True),\n","    StructField(\"IntraProcAnticoag\", StringType(), True),\n","    StructField(\"Warfarin\", StringType(), True),\n","    StructField(\"ProcHeparin2\", StringType(), True),\n","    StructField(\"ProcHeparinInitAdminTime\", StringType(), True),\n","    StructField(\"ProcBivalirudin2\", StringType(), True),\n","    StructField(\"ProcOtherAnticoag2\", StringType(), True),\n","    StructField(\"AnticoagReversal\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"FluoroDoseKerm_Units\", StringType(), True),\n","    StructField(\"FluoroDoseDAP2_Units\", StringType(), True),\n","\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_procinfo_df = spark.createDataFrame(combined_df_renamed, schema=schema)\n","\n","# Now write the DataFrame to the Delta table\n","laao_procinfo_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_procinfo\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":458,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:45.5608778Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:02.6716702Z","execution_finish_time":"2024-03-06T17:10:06.1189639Z","parent_msg_id":"13d021c6-9f8b-4b26-a1f2-7387a751d0e0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 458, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":456,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c4624bcc-2229-4e7c-83e2-f8438ee5d320"},{"cell_type":"markdown","source":["## Operators"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"8b2be1fe-4482-4322-bec5-85a38e074a31"},{"cell_type":"code","source":["# load operators from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Operators.parquet\"\n","operators = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    operators[col] = operators[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","operators['facility'] = pd.to_numeric(operators['facility'])\n","\n","# Apply the function to the specified columns\n","operators['OtherID'] = operators['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        operators[col] = pd.to_datetime(operators[col], format=fmt)\n","    else:\n","        operators[col] = pd.to_datetime(operators[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":459,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:51.4095124Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:06.4089366Z","execution_finish_time":"2024-03-06T17:10:06.6379846Z","parent_msg_id":"01ddfedb-84db-4917-b88a-4b78fe967bfa"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 459, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":457,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"aac9b2c9-fdc9-46d8-9921-dd9f44931b27"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":460,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:09:57.2632338Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:07.0532719Z","execution_finish_time":"2024-03-06T17:10:07.2792655Z","parent_msg_id":"cf8eb430-177e-4700-9593-270d41b423f2"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 460, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":458,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"870b33e8-7dd5-4876-b92d-07897fa33992"},{"cell_type":"code","source":["#start by appending in_hospital\n","\n","# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'DCDate', \n","    'OperA_LastName2', \n","    'OperA_FirstName2', \n","    'OperA_MidName2', \n","    'OperA_NPI2', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(operators.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'operators' DataFrame\n","new_data_to_append = new_data_to_append[operators.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([operators, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":461,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:02.3842717Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:07.5941262Z","execution_finish_time":"2024-03-06T17:10:07.8205743Z","parent_msg_id":"8ab80e4c-dc75-41a9-8d9a-c2a4f89504fb"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 461, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":459,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ca2edbe5-2568-4f9b-98ae-a004dd4abadc"},{"cell_type":"code","source":["combined_df.info()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":462,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:10.4922034Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:10.8089746Z","execution_finish_time":"2024-03-06T17:10:11.0281864Z","parent_msg_id":"d0b9bc65-7b27-4e73-8e76-d51581831091"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 462, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3610 entries, 0 to 3609\nData columns (total 14 columns):\n #   Column                  Non-Null Count  Dtype         \n---  ------                  --------------  -----         \n 0   NCDRPatientID           3610 non-null   object        \n 1   LastName                3610 non-null   object        \n 2   FirstName               3610 non-null   object        \n 3   MidName                 2906 non-null   object        \n 4   OtherID                 3610 non-null   object        \n 5   ArrivalDate             3610 non-null   datetime64[ns]\n 6   ProcedureStartDateTime  3610 non-null   datetime64[ns]\n 7   DCDate                  3610 non-null   datetime64[ns]\n 8   OperA_LastName2         3610 non-null   object        \n 9   OperA_FirstName2        3610 non-null   object        \n 10  OperA_MidName2          774 non-null    object        \n 11  OperA_NPI2              3610 non-null   object        \n 12  facility                3610 non-null   int64         \n 13  Pat_ID                  3610 non-null   object        \ndtypes: datetime64[ns](3), int64(1), object(10)\nmemory usage: 395.0+ KB\n"]}],"execution_count":460,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7645d7f5-d371-471b-a9f0-76508630df3d"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoOperatorsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly based on the given columns\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"OperA_LastName2\", StringType(), True),\n","    StructField(\"OperA_FirstName2\", StringType(), True),\n","    StructField(\"OperA_MidName2\", StringType(), True),\n","    StructField(\"OperA_NPI2\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","combined_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Now try writing the DataFrame to the Delta table again\n","combined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_operators\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":463,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:18.3452201Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:18.6724299Z","execution_finish_time":"2024-03-06T17:10:22.1847729Z","parent_msg_id":"230c56d9-4ccf-4bb5-8969-662e76f5506a"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 463, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:428: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Expected bytes, got a 'int' object\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":461,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"666bd38c-f160-4145-b411-c44678ac4161"},{"cell_type":"markdown","source":["## Fellows\n","New data for v1.4, no data available for v1.3."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"082fa732-3407-452b-ad09-979ae4b8e522"},{"cell_type":"code","source":["# load fellows from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Fellows.parquet\"\n","fellows = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    fellows[col] = fellows[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","fellows['facility'] = pd.to_numeric(fellows['facility'])\n","\n","# Apply the function to the specified columns\n","fellows['OtherID'] = fellows['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        fellows[col] = pd.to_datetime(fellows[col], format=fmt)\n","    else:\n","        fellows[col] = pd.to_datetime(fellows[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":464,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:21.3731774Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:22.5202443Z","execution_finish_time":"2024-03-06T17:10:22.7471577Z","parent_msg_id":"7267c31f-9377-49d2-bccc-05a098c27a54"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 464, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":462,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"77702860-78e6-4013-b8a1-27ae6667696b"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoFellowsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly for laao_fellows table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"FITProgID\", IntegerType(), True),\n","    StructField(\"FIT_LastName\", StringType(), True),\n","    StructField(\"FIT_FirstName\", StringType(), True),\n","    StructField(\"FIT_MidName\", StringType(), True),\n","    StructField(\"FIT_NPI\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","    # Add any additional fields here as needed\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame using the defined schema\n","laao_fellows_spark_df = spark.createDataFrame(fellows, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_fellows_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_fellows\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":465,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:23.4645767Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:23.7823467Z","execution_finish_time":"2024-03-06T17:10:27.2581072Z","parent_msg_id":"05f39c71-5fa5-4b9c-8474-45b95233042d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 465, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:428: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Expected a string or bytes dtype, got int64\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":463,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"59b34003-d6c1-4958-8bb9-699eafd55e53"},{"cell_type":"markdown","source":["## AccessSystems"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e4044218-eaf5-41a2-871d-170f0c236c7c"},{"cell_type":"code","source":["# load accesssystems from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/AccessSystems.parquet\"\n","accesssystems = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    accesssystems[col] = accesssystems[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","accesssystems['facility'] = pd.to_numeric(accesssystems['facility'])\n","\n","# Apply the function to the specified columns\n","accesssystems['OtherID'] = accesssystems['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        accesssystems[col] = pd.to_datetime(accesssystems[col], format=fmt)\n","    else:\n","        accesssystems[col] = pd.to_datetime(accesssystems[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":466,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:26.3476795Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:27.5543261Z","execution_finish_time":"2024-03-06T17:10:27.7650604Z","parent_msg_id":"39954176-3ecb-45da-a3fd-8b551605033b"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 466, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":464,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"83196471-85d7-4995-8b0d-8733ff6e91fe"},{"cell_type":"code","source":["# load accesssysid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AccessSysID.parquet\"\n","accesssysid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    accesssysid[col] = accesssysid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","accesssysid['facility'] = pd.to_numeric(accesssysid['facility'])\n","\n","# Apply the function to the specified columns\n","accesssysid['OtherID'] = accesssysid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        accesssysid[col] = pd.to_datetime(accesssysid[col], format=fmt)\n","    else:\n","        accesssysid[col] = pd.to_datetime(accesssysid[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":467,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:28.2491126Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:28.5633936Z","execution_finish_time":"2024-03-06T17:10:28.7778861Z","parent_msg_id":"08363926-796f-4f10-b106-215f36294913"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 467, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":465,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8c3746c7-1916-45f7-8149-eb3d83f444c7"},{"cell_type":"code","source":["#start by appending accesssysid\n","\n","# List of columns to append from 'accesssysid'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'DCDate', \n","    'AccessSysCounter', \n","    'AccessSysID', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = accesssysid[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(accesssystems.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'accesssystems' DataFrame\n","new_data_to_append = new_data_to_append[accesssystems.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([accesssystems, new_data_to_append], ignore_index=True)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":468,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:30.5948592Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:30.9344894Z","execution_finish_time":"2024-03-06T17:10:31.1627401Z","parent_msg_id":"0c86000b-6b6a-42bb-9cef-f12aa23971c7"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 468, Finished, Available)"},"metadata":{}}],"execution_count":466,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"77ff0d66-7363-49df-b948-16bb3306fe15"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LA_AccessSystems_Ingestion\").getOrCreate()\n","\n","# Define the schema explicitly for the laao_accesssystems table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"AccessSysCounter\", IntegerType(), True),\n","    StructField(\"AccessSysID\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_accesssystems_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_accesssystems_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_accesssystems\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":469,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:33.3750167Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:33.6962235Z","execution_finish_time":"2024-03-06T17:10:37.1712378Z","parent_msg_id":"de5490ef-76db-4cec-8f98-73f39f3b574f"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 469, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":467,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5acbb4db-714d-4dc8-ae60-c5960166ffc5"},{"cell_type":"markdown","source":["## Devices"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"031b2a0b-8313-494a-af5b-60a2ef20c13b"},{"cell_type":"code","source":["# load devices from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Devices.parquet\"\n","devices = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    devices[col] = devices[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","devices['facility'] = pd.to_numeric(devices['facility'])\n","\n","# Apply the function to the specified columns\n","devices['OtherID'] = devices['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        devices[col] = pd.to_datetime(devices[col], format=fmt)\n","    else:\n","        devices[col] = pd.to_datetime(devices[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":470,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:36.1976454Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:37.4942024Z","execution_finish_time":"2024-03-06T17:10:37.7150922Z","parent_msg_id":"35ebffe3-06c0-4e5c-af89-152e339473f7"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 470, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":468,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"43f26cda-357d-44c5-946f-9ec0d4e41357"},{"cell_type":"code","source":["# load accesssysid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/AccessSysID.parquet\"\n","accesssysid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    accesssysid[col] = accesssysid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","accesssysid['facility'] = pd.to_numeric(accesssysid['facility'])\n","\n","# Apply the function to the specified columns\n","accesssysid['OtherID'] = accesssysid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        accesssysid[col] = pd.to_datetime(accesssysid[col], format=fmt)\n","    else:\n","        accesssysid[col] = pd.to_datetime(accesssysid[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":471,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:37.4774015Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:38.0254646Z","execution_finish_time":"2024-03-06T17:10:38.2590185Z","parent_msg_id":"bc7ab1b3-a3a5-49b6-9085-b02de9009a07"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 471, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":469,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ec292f64-1a47-4c86-9f98-9fc70dc7b161"},{"cell_type":"code","source":["#start by appending accesssysid\n","\n","# List of columns to append from 'accesssysid'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'DCDate', \n","    'DevCounter', \n","    'LAADevID', \n","    'Dev_UDIDirectID', \n","    'LAAIsolationApproach', \n","    'DevSucdep', \n","    'OutDevUnsucDepl', \n","    'facility' \n","\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = accesssysid[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(devices.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'devices' DataFrame\n","new_data_to_append = new_data_to_append[devices.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([devices, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":472,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:38.1546306Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:38.5870477Z","execution_finish_time":"2024-03-06T17:10:38.8092711Z","parent_msg_id":"5ca08398-d6f6-48eb-8076-521844641380"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 472, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":470,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6e191da1-1de7-4af0-95a4-be812f8f062d"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LAAODevicesIngestion\").getOrCreate()\n","\n","# Define the schema explicitly to match the laao_accesssystems table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"DevCounter\", IntegerType(), True),\n","    StructField(\"LAADevID\", StringType(), True),\n","    StructField(\"Dev_UDIDirectID\", FloatType(), True),\n","    StructField(\"LAAIsolationApproach\", StringType(), True),\n","    StructField(\"DevSucdep\", StringType(), True),\n","    StructField(\"OutDevUnsucDepl\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame using the defined schema\n","spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_devices\")\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":473,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:40.0009885Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:40.3497458Z","execution_finish_time":"2024-03-06T17:10:43.8247409Z","parent_msg_id":"142bc95d-52df-4ed9-83cb-2966ba2b9d7d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 473, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":471,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"65bd9dcf-d265-4a35-ab14-d3744844b901"},{"cell_type":"markdown","source":["## IPPEvents"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"accee053-6bfa-488d-85c3-d34910143730"},{"cell_type":"code","source":["# load ippevents from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/IPPEvents.parquet\"\n","ippevents = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    ippevents[col] = ippevents[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","ippevents['facility'] = pd.to_numeric(ippevents['facility'])\n","\n","# Apply the function to the specified columns\n","ippevents['OtherID'] = ippevents['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'IntraPostProcEventDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        ippevents[col] = pd.to_datetime(ippevents[col], format=fmt)\n","    else:\n","        ippevents[col] = pd.to_datetime(ippevents[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":474,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:42.0594617Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:44.143135Z","execution_finish_time":"2024-03-06T17:10:44.882352Z","parent_msg_id":"1f7a90c2-2885-4d66-a371-feda028067e0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 474, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":472,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"282342e9-f106-4edf-b9a4-1d8d10d8a195"},{"cell_type":"code","source":["# load event_id from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/Event ID.parquet\"\n","event_id = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    event_id[col] = event_id[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","event_id['facility'] = pd.to_numeric(event_id['facility'])\n","\n","# Apply the function to the specified columns\n","event_id['OtherID'] = event_id['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'IntraPostProcEventDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        event_id[col] = pd.to_datetime(event_id[col], format=fmt)\n","    else:\n","        event_id[col] = pd.to_datetime(event_id[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":475,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:43.4533241Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:45.2213801Z","execution_finish_time":"2024-03-06T17:10:45.4345816Z","parent_msg_id":"a4a65644-7da4-4c1e-b544-6e3823ec041d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 475, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":473,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"76fe4103-4002-4250-9ee4-550df6209216"},{"cell_type":"code","source":["#start by appending event_id\n","\n","# List of columns to append from 'event_id'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'DCDate', \n","    'ProcEvents', \n","    'PostProcOccurred', \n","    'IntraPostProcEventDate', \n","    'facility' \n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = event_id[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(ippevents.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'ippevents' DataFrame\n","new_data_to_append = new_data_to_append[ippevents.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([ippevents, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":476,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:44.4393926Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:45.7629693Z","execution_finish_time":"2024-03-06T17:10:45.9773651Z","parent_msg_id":"ea81cc00-170c-49c7-968e-4e98c0c2adaf"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 476, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":474,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7bd9dee1-9330-4d45-b93c-4155813498e3"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LAOOIPPEventsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly based on the `laao_ippevents` table structure\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"ProcEvents\", StringType(), True),\n","    StructField(\"PostProcOccurred\", StringType(), True),\n","    StructField(\"IntraPostProcEventDate\", DateType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),   \n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","combined_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","#write to delta table\n","combined_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_ippevents\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":477,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:45.5265383Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:46.3028813Z","execution_finish_time":"2024-03-06T17:10:49.7805969Z","parent_msg_id":"bf39c0eb-40a9-4708-9d91-764414900776"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 477, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":475,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d93fbfbc-3c05-4f42-a9fb-b38bd4467356"},{"cell_type":"markdown","source":["## PostProcLabs"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"15289425-04d9-4635-a8d1-700b9d255b20"},{"cell_type":"code","source":["# load postproclabs from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/PostProcLabs.parquet\"\n","postproclabs = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    postproclabs[col] = postproclabs[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","postproclabs['facility'] = pd.to_numeric(postproclabs['facility'])\n","\n","# Apply the function to the specified columns\n","postproclabs['OtherID'] = postproclabs['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        postproclabs[col] = pd.to_datetime(postproclabs[col], format=fmt)\n","    else:\n","        postproclabs[col] = pd.to_datetime(postproclabs[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":478,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:47.4587488Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:50.0801043Z","execution_finish_time":"2024-03-06T17:10:50.2991178Z","parent_msg_id":"d0d4cd85-69a7-4fe3-b99e-25875428bb60"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 478, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":476,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a09249dc-2d7a-40b0-935a-cf9e65542c17"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":479,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:50.3351406Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:50.6500844Z","execution_finish_time":"2024-03-06T17:10:51.4095241Z","parent_msg_id":"20e443ff-36a3-4a3e-8d52-aa4d17f4729c"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 479, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":477,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a52eb46e-abe4-4e2e-8c63-3153225e5adf"},{"cell_type":"code","source":["#start by appending in_hospital\n","\n","# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'ProcedureStartDateTime', \n","    'DCDate', \n","    'PostProcPeakCreat', \n","    'PostProcPeakCreatND', \n","    'PostProcCreat2', \n","    'PostProcCreatND2', \n","    'PostProcHgb2', \n","    'PostProcHgbND2', \n","    'facility'\n","\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(postproclabs.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'postproclabs' DataFrame\n","new_data_to_append = new_data_to_append[postproclabs.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([postproclabs, new_data_to_append], ignore_index=True)\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":480,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:52.0065942Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:52.312597Z","execution_finish_time":"2024-03-06T17:10:52.5284425Z","parent_msg_id":"2e2e988c-3439-46de-bc92-79af45ba9eb6"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 480, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":478,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4fdf6d6d-26a0-41d1-87eb-34861622630f"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LAAOPostProcLabsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"ProcedureStartDateTime\", TimestampType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"PostProcPeakCreat\", DoubleType(), True),\n","    StructField(\"PostProcPeakCreatND\", StringType(), True),\n","    StructField(\"PostProcCreat2\", DoubleType(), True),\n","    StructField(\"PostProcCreatND2\", StringType(), True),\n","    StructField(\"PostProcHgb2\", DoubleType(), True),\n","    StructField(\"PostProcHgbND2\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_postprocmeds_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Now, write the DataFrame to the Delta table\n","laao_postprocmeds_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_postproclabs\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":481,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:54.2196888Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:54.5411152Z","execution_finish_time":"2024-03-06T17:10:56.9258461Z","parent_msg_id":"ab6ca147-7d59-46a1-abb1-a9cfa0492728"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 481, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":479,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cc0a97d7-54ea-486f-b0ea-f560926dc4a1"},{"cell_type":"markdown","source":["## Discharge"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f401f205-39ed-415d-980b-9cb4831b2b3b"},{"cell_type":"code","source":["# load discharge from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/Discharge.parquet\"\n","discharge = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    discharge[col] = discharge[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","discharge['facility'] = pd.to_numeric(discharge['facility'])\n","\n","# Apply the function to the specified columns\n","discharge['OtherID'] = discharge['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        discharge[col] = pd.to_datetime(discharge[col], format=fmt)\n","    else:\n","        discharge[col] = pd.to_datetime(discharge[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":482,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:56.6088701Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:57.2754838Z","execution_finish_time":"2024-03-06T17:10:57.5174264Z","parent_msg_id":"e2a8587d-8397-4b7a-b372-6ec6c73e087f"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 482, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":480,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"07bad0f2-03e3-4630-85d5-e4e5e2181356"},{"cell_type":"code","source":["# load in_hospital from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/In-hospital.parquet\"\n","in_hospital = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['ZipCode', 'OtherID', 'SSN', 'NCDRPatientID', 'OperA_NPI2']:\n","    in_hospital[col] = in_hospital[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","in_hospital['facility'] = pd.to_numeric(in_hospital['facility'])\n","\n","# Apply the function to the specified columns\n","in_hospital['OtherID'] = in_hospital['OtherID'].apply(remove_decimal_point)\n","in_hospital['SSN'] = in_hospital['SSN'].apply(remove_decimal_point)\n","in_hospital['ZipCode'] = in_hospital['ZipCode'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'DOB': '%Y-%m-%d',\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d',\n","    'AFibSurgAblDate': '%Y-%m-%d', \n","    'AFibFlutterCathAblDate': '%Y-%m-%d',\n","    'ProcedureStartDateTime': '%Y-%m-%d %H:%M:%S',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S',\n","    'TEEDateLAAO': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col], format=fmt)\n","    else:\n","        in_hospital[col] = pd.to_datetime(in_hospital[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":483,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:57.7533038Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:58.0990259Z","execution_finish_time":"2024-03-06T17:10:58.3008844Z","parent_msg_id":"32ef4d5c-1b51-4a47-923c-66bfee0af17a"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 483, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":481,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"08e516bc-eb48-4887-8ccc-e6ee2851258d"},{"cell_type":"code","source":["#start by appending in_hospital to get natrual key columns\n","\n","# List of columns to append from 'in_hospital'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'ArrivalDate', \n","    'DCDate', \n","    'Sx_F', \n","    'PCIOther', \n","    'DCStatus', \n","    'DCLocation', \n","    'DCHospice', \n","    'DeathProcedure', \n","    'DeathCause', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = in_hospital[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(discharge.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'discharge' DataFrame\n","new_data_to_append = new_data_to_append[discharge.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([discharge, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":484,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:10:58.9292685Z","session_start_time":null,"execution_start_time":"2024-03-06T17:10:59.232977Z","execution_finish_time":"2024-03-06T17:10:59.4543143Z","parent_msg_id":"77a73bca-8491-437c-9351-52f8279ac346"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 484, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":482,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1fe40672-33c9-4764-9059-b80fb23ae835"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"DischargeIngestion\").getOrCreate()\n","\n","# Define the schema explicitly for laao_discharge\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"Sx_F\", StringType(), True),\n","    StructField(\"PCIOther\", StringType(), True),\n","    StructField(\"DCStatus\", StringType(), True),\n","    StructField(\"DCLocation\", StringType(), True),\n","    StructField(\"DCHospice\", StringType(), True),\n","    StructField(\"DeathProcedure\", StringType(), True),\n","    StructField(\"DeathCause\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","discharge_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Writing the DataFrame to the Delta table\n","discharge_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_discharge\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":485,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:00.9459424Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:01.2544771Z","execution_finish_time":"2024-03-06T17:11:03.5563656Z","parent_msg_id":"521376d0-b972-4861-9d0e-72691bb14d0c"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 485, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":483,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"59a1a4c3-9ef7-478a-ab14-420faadedbbf"},{"cell_type":"markdown","source":["## DischargeMeds"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3455326f-2bcc-4821-aae3-f9c5d7956fe7"},{"cell_type":"code","source":["# load dischargemeds from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/DischargeMeds.parquet\"\n","dischargemeds = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    dischargemeds[col] = dischargemeds[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","dischargemeds['facility'] = pd.to_numeric(dischargemeds['facility'])\n","\n","# Apply the function to the specified columns\n","dischargemeds['OtherID'] = dischargemeds['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        dischargemeds[col] = pd.to_datetime(dischargemeds[col], format=fmt)\n","    else:\n","        dischargemeds[col] = pd.to_datetime(dischargemeds[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":486,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:02.8599009Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:03.8604651Z","execution_finish_time":"2024-03-06T17:11:04.2991584Z","parent_msg_id":"a4b2d242-f4b5-4cfa-891c-3c04f4d6019a"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 486, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":484,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"33285675-3405-45ca-b2f5-7274ce0ebbf4"},{"cell_type":"code","source":["# load postprocmedstrategy from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/PostProcMedStrategy_MedID.parquet\"\n","postprocmedstrategy = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    postprocmedstrategy[col] = postprocmedstrategy[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","postprocmedstrategy['facility'] = pd.to_numeric(postprocmedstrategy['facility'])\n","\n","# Apply the function to the specified columns\n","postprocmedstrategy['OtherID'] = postprocmedstrategy['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'ArrivalDate': '%Y-%m-%d',\n","    'DCDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        postprocmedstrategy[col] = pd.to_datetime(postprocmedstrategy[col], format=fmt)\n","    else:\n","        postprocmedstrategy[col] = pd.to_datetime(postprocmedstrategy[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":487,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:03.9457074Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:04.6270377Z","execution_finish_time":"2024-03-06T17:11:04.8596178Z","parent_msg_id":"7e6846b0-0f0d-4ee4-b89f-e9b57d8467ae"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 487, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":485,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0ff8a409-24db-461e-b5ec-6b8444b920e9"},{"cell_type":"code","source":["# Step 1: Melting the DataFrame to create 'DC_MedID'\n","melted_df = pd.melt(postprocmedstrategy, \n","                    id_vars=['NCDRPatientID', 'LastName', 'FirstName', 'MidName', 'OtherID', 'ArrivalDate', 'DCDate', 'facility', 'Pat_ID'], \n","                    value_vars=['Aspirin (81-100 mg)', 'Aspirin (101-324 mg)', 'Aspirin 325 mg', 'DOAC', 'P2Y12', 'Warfarin'], \n","                    var_name='DC_MedID', value_name='Value')\n","\n","# Step 2: Generating 'DC_MedAdmin'\n","melted_df['DC_MedAdmin'] = np.where(\n","    (melted_df['Value'].notna()) & (melted_df['Value'].str.contains('Implant', na=False)), \n","    'Yes', \n","    'No - No Reason'\n",")\n","#Step 3: Create DC_MedDose\n","# Using a lambda function to check if 'Aspirin' is in 'DC_MedID', then clean up the text\n","melted_df['DC_MedDose'] = melted_df.apply(\n","    lambda row: re.sub(r'\\(|\\)', '', row['DC_MedID']) if 'Aspirin' in row['DC_MedID'] and \n","    pd.notna(row['Value']) and 'Implant' in str(row['Value']) else np.nan, axis=1\n",")\n","\n","# Step for updating DC_MedID for Aspirin entries\n","melted_df['DC_MedID'] = melted_df.apply(\n","    lambda x: 'Aspirin' if 'Aspirin' in x['DC_MedID'] else x['DC_MedID'], axis=1\n",")\n","\n","# Step to remove rows where DC_MedID is 'Aspirin' and DC_MedDose is null\n","melted_df = melted_df[~((melted_df['DC_MedID'] == 'Aspirin') & (melted_df['DC_MedDose'].isnull()))]\n","\n","melted_df.drop('Value', axis = 1, inplace = True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":488,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:04.6294563Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:05.3412361Z","execution_finish_time":"2024-03-06T17:11:06.0802311Z","parent_msg_id":"01dc82cb-8fc4-4df7-858e-cb216220f449"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 488, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":486,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8942e33c-9dd4-430b-a708-81d715eff42c"},{"cell_type":"code","source":["#start by appending melted_df\n","\n","# List of columns to append from 'melted_df'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID',\n","    'ArrivalDate', \n","    'DCDate', \n","    'facility', \n","    'DC_MedID', \n","    'DC_MedAdmin',\n","    'DC_MedDose'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = melted_df[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(dischargemeds.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'dischargemeds' DataFrame\n","new_data_to_append = new_data_to_append[dischargemeds.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([dischargemeds, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":489,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:06.2188358Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:06.5313971Z","execution_finish_time":"2024-03-06T17:11:06.7440868Z","parent_msg_id":"e327e6a0-b371-4a51-9c53-3844549d2ded"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 489, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":487,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ff9f668c-52d9-4ec9-9847-128698594ec5"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n","\n","# Assuming you have a pandas DataFrame named `dischargemeds_df` with the data for ingestion\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoDischargemedsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly for the laao_dischargemeds table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"ArrivalDate\", DateType(), True),\n","    StructField(\"DCDate\", DateType(), True),\n","    StructField(\"DC_MedID\", StringType(), True),\n","    StructField(\"DC_MedAdmin\", StringType(), True),\n","    StructField(\"DC_MedDose\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True)\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_dischargemeds_spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_dischargemeds_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_dischargemeds\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":490,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:08.4724409Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:08.8011703Z","execution_finish_time":"2024-03-06T17:11:11.1564358Z","parent_msg_id":"403d8a80-20eb-41bd-a3ee-7af62a058059"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 490, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":488,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7638745c-9b09-4ed7-a090-fb1c57b69053"},{"cell_type":"markdown","source":["## FollowUp"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9bc525e1-ab32-4d1b-a494-cc38207fdd1d"},{"cell_type":"code","source":["# load followup from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FollowUp.parquet\"\n","followup = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    followup[col] = followup[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","followup['facility'] = pd.to_numeric(followup['facility'])\n","\n","# Apply the function to the specified columns\n","followup['OtherID'] = followup['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'F_DeathDate':'%Y-%m-%d',\n","    'TTEDate_F':'%Y-%m-%d',\n","    'F_TEEDate':'%Y-%m-%d',\n","    'F_CardiacCTDate':'%Y-%m-%d',\n","    'F_CardiacMRIDate':'%Y-%m-%d',\n","    'F_ICEDate':'%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        followup[col] = pd.to_datetime(followup[col], format=fmt)\n","    else:\n","        followup[col] = pd.to_datetime(followup[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":491,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:10.4384055Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:11.4607843Z","execution_finish_time":"2024-03-06T17:11:11.6996805Z","parent_msg_id":"bf09fa08-ccaa-4954-b32a-e63e287aba66"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 491, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":489,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"02cd58e1-cac9-4ace-a348-8654dfd6598e"},{"cell_type":"code","source":["# load follow_up from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/Follow-up.parquet\"\n","follow_up = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    follow_up[col] = follow_up[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","follow_up['facility'] = pd.to_numeric(follow_up['facility'])\n","\n","# Apply the function to the specified columns\n","follow_up['OtherID'] = follow_up['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'F_DeathDate':'%Y-%m-%d',\n","    'TTEDate_F':'%Y-%m-%d',\n","    'F_TEEDate':'%Y-%m-%d',\n","    'F_CardiacCTDate':'%Y-%m-%d',\n","    'F_CardiacMRIDate':'%Y-%m-%d',\n","    'F_ICEDate':'%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        follow_up[col] = pd.to_datetime(follow_up[col], format=fmt)\n","    else:\n","        follow_up[col] = pd.to_datetime(follow_up[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":492,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:11.7301813Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:12.0492158Z","execution_finish_time":"2024-03-06T17:11:12.7681351Z","parent_msg_id":"2f636af1-b408-4b9a-bc3d-78ed5e5197a0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 492, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":490,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"46a00b5d-2d27-4948-9301-cb6ea960eba9"},{"cell_type":"code","source":["#start by appending follow_up\n","\n","# List of columns to append from 'follow_up'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'FURefArrivalDate', \n","    'FU_RefDischargeDate', \n","    'RefProcStartDateTime', \n","    'F_AssessmentDate', \n","    'FUInterv', \n","    'F_Method - Office Visit', \n","    'F_Method - Medical Records', \n","    'F_Method - Letter from Medical Provider', \n","    'F_Method - Phone Call', \n","    'F_Method - Social Security Death Master File', \n","    'F_Method - Hospitalized', \n","    'F_Method - Other', \n","    'F_Status', \n","    'F_DeathDate', \n","    'F_DeathCause', \n","    'FU_LVEF', \n","    'F_LVEF', \n","    'TTEPerfFU', \n","    'TTEDate_F', \n","    'F_TEEPerf', \n","    'F_TEEDate', \n","    'F_CardiacCTPerf', \n","    'F_CardiacCTDate', \n","    'F_CardiacMRIPerf', \n","    'F_CardiacMRIDate', \n","    'F_ICEPerformed', \n","    'F_ICEDate', \n","    'F_AtrialThromDetect', \n","    'ResidualLeakFU', \n","    'ResidualLeakNAFU', \n","    'Creat_FU', \n","    'F_CreatND', \n","    'LowHgbValue_F', \n","    'HGBND_FU', \n","    'F_RankinScore', \n","    'F_mRS_NA', \n","    'F_BIEPerf', \n","    'F_BIEFeeding', \n","    'F_BIEBathing', \n","    'F_BIEGrooming', \n","    'F_BIEDressing', \n","    'F_BIEBowels', \n","    'F_BIEBladder', \n","    'F_BIEToilet', \n","    'F_BIETransfers', \n","    'F_BIEMobility', \n","    'F_BIEStairs', \n","    'facility'\n","\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = follow_up[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(followup.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'followup' DataFrame\n","new_data_to_append = new_data_to_append[followup.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([followup, new_data_to_append], ignore_index=True)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":493,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:12.4151713Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:13.1154708Z","execution_finish_time":"2024-03-06T17:11:13.3466856Z","parent_msg_id":"2152c2ba-2d06-47e6-9975-a19fc2f10ba1"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 493, Finished, Available)"},"metadata":{}}],"execution_count":491,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"206cf1ba-6a07-44e5-a8f2-a6c914cc44f0"},{"cell_type":"code","source":["# Rename columns to be compatible with Delta table\n","columns_mapping = {\n","    'F_Method - Office Visit': 'F_Method_Office_Visit',\n","    'F_Method - Medical Records': 'F_Method_Medical_Records',\n","    'F_Method - Letter from Medical Provider': 'F_Method_Letter_From_Medical_Provider',\n","    'F_Method - Phone Call': 'F_Method_Phone_Call',\n","    'F_Method - Social Security Death Master File': 'F_Method_Social_Security_Death_Master_File',\n","    'F_Method - Hospitalized': 'F_Method_Hospitalized',\n","    'F_Method - Other': 'F_Method_Other'\n","}\n","\n","# Rename the columns\n","combined_df_renamed = combined_df.rename(columns=columns_mapping)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":494,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:14.2288498Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:14.540423Z","execution_finish_time":"2024-03-06T17:11:14.7635579Z","parent_msg_id":"9b5b0fa7-3be4-42fb-8a9d-4834715a4438"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 494, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":492,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c12506dd-a47b-4723-8719-1b8ef9cf50ff"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType, FloatType\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"IngestionToDeltaTable\").getOrCreate()\n","\n","# Define the schema explicitly based on the provided columns\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"FURefArrivalDate\", DateType(), True),\n","    StructField(\"FU_RefDischargeDate\", DateType(), True),\n","    StructField(\"RefProcStartDateTime\", TimestampType(), True),\n","    StructField(\"F_AssessmentDate\", DateType(), True),\n","    StructField(\"FUInterv\", StringType(), True),\n","    StructField(\"F_Method_Office_Visit\", StringType(), True),\n","    StructField(\"F_Method_Medical_Records\", StringType(), True),\n","    StructField(\"F_Method_Letter_From_Medical_Provider\", StringType(), True),\n","    StructField(\"F_Method_Phone_Call\", StringType(), True),\n","    StructField(\"F_Method_Social_Security_Death_Master_File\", StringType(), True),\n","    StructField(\"F_Method_Hospitalized\", StringType(), True),\n","    StructField(\"F_Method_Other\", StringType(), True),\n","    StructField(\"F_Status\", StringType(), True),\n","    StructField(\"F_DeathDate\", DateType(), True),\n","    StructField(\"F_DeathCause\", StringType(), True),\n","    StructField(\"FU_LVEF\", StringType(), True),\n","    StructField(\"F_LVEF\", FloatType(), True),\n","    StructField(\"TTEPerfFU\", StringType(), True),\n","    StructField(\"TTEDate_F\", DateType(), True),\n","    StructField(\"F_TEEPerf\", StringType(), True),\n","    StructField(\"F_TEEDate\", DateType(), True),\n","    StructField(\"F_CardiacCTPerf\", StringType(), True),\n","    StructField(\"F_CardiacCTDate\", DateType(), True),\n","    StructField(\"F_CardiacMRIPerf\", StringType(), True),\n","    StructField(\"F_CardiacMRIDate\", DateType(), True),\n","    StructField(\"F_ICEPerformed\", StringType(), True),\n","    StructField(\"F_ICEDate\", DateType(), True),\n","    StructField(\"F_AtrialThromDetect\", StringType(), True),\n","    StructField(\"ResidualLeakFU\", FloatType(), True),\n","    StructField(\"ResidualLeakNAFU\", StringType(), True),\n","    StructField(\"Creat_FU\", FloatType(), True),\n","    StructField(\"F_CreatND\", StringType(), True),\n","    StructField(\"LowHgbValue_F\", FloatType(), True),\n","    StructField(\"HGBND_FU\", StringType(), True),\n","    StructField(\"F_RankinScore\", StringType(), True),\n","    StructField(\"F_mRS_NA\", StringType(), True),\n","    StructField(\"F_BIEPerf\", StringType(), True),\n","    StructField(\"F_BIEFeeding\", StringType(), True),\n","    StructField(\"F_BIEBathing\", StringType(), True),\n","    StructField(\"F_BIEGrooming\", StringType(), True),\n","    StructField(\"F_BIEDressing\", StringType(), True),\n","    StructField(\"F_BIEBowels\", StringType(), True),\n","    StructField(\"F_BIEBladder\", StringType(), True),\n","    StructField(\"F_BIEToilet\", StringType(), True),\n","    StructField(\"F_BIETransfers\", StringType(), True),\n","    StructField(\"F_BIEMobility\", StringType(), True),\n","    StructField(\"F_BIEStairs\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_followup_df = spark.createDataFrame(combined_df_renamed, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_followup_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_followup\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":495,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:17.1756818Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:17.5147874Z","execution_finish_time":"2024-03-06T17:11:19.8936638Z","parent_msg_id":"18cdb14a-70c9-4b5b-8c3b-8a0d3a1b9b3c"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 495, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":493,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"33223990-3ff2-45fe-bb75-20ec9b75cbe5"},{"cell_type":"markdown","source":["## FMEDS"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"09dade4d-1a59-440c-b91d-d782f316e17c"},{"cell_type":"code","source":["# load fmeds from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FMEDS.parquet\"\n","fmeds = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    fmeds[col] = fmeds[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","fmeds['facility'] = pd.to_numeric(fmeds['facility'])\n","\n","# Apply the function to the specified columns\n","fmeds['OtherID'] = fmeds['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'F_WarfarinDiscontinuedDate':'%Y-%m-%d',\n","    'F_WarfarinResumedDate':'%Y-%m-%d',\n","    'F_DOACTherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_DOACTherapyResumedDate':'%Y-%m-%d',\n","    'F_AspirinTherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_AspirinTherapyResumedDate':'%Y-%m-%d',\n","    'F_P2Y12TherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_P2Y12TherapyResumedDate':'%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        fmeds[col] = pd.to_datetime(fmeds[col], format=fmt)\n","    else:\n","        fmeds[col] = pd.to_datetime(fmeds[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":496,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:19.0210453Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:20.2357674Z","execution_finish_time":"2024-03-06T17:11:20.4600268Z","parent_msg_id":"ac567a8a-973a-4fb7-9b30-365991299ce6"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 496, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":494,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c9bf116d-ae41-4585-a82f-98c347171a3a"},{"cell_type":"code","source":["# load follow_up from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/Follow-up.parquet\"\n","follow_up = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    follow_up[col] = follow_up[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","follow_up['facility'] = pd.to_numeric(follow_up['facility'])\n","\n","# Apply the function to the specified columns\n","follow_up['OtherID'] = follow_up['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'F_DeathDate':'%Y-%m-%d',\n","    'TTEDate_F':'%Y-%m-%d',\n","    'F_TEEDate':'%Y-%m-%d',\n","    'F_CardiacCTDate':'%Y-%m-%d',\n","    'F_CardiacMRIDate':'%Y-%m-%d',\n","    'F_ICEDate':'%Y-%m-%d',\n","    'F_WarfarinDiscontinuedDate':'%Y-%m-%d',\n","    'F_WarfarinResumedDate':'%Y-%m-%d',\n","    'F_DOACTherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_DOACTherapyResumedDate':'%Y-%m-%d',\n","    'F_AspirinTherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_AspirinTherapyResumedDate':'%Y-%m-%d',\n","    'F_P2Y12TherapyDiscontinuedDate':'%Y-%m-%d',\n","    'F_P2Y12TherapyResumedDate':'%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        follow_up[col] = pd.to_datetime(follow_up[col], format=fmt)\n","    else:\n","        follow_up[col] = pd.to_datetime(follow_up[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":497,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:19.677697Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:20.7656542Z","execution_finish_time":"2024-03-06T17:11:20.9995438Z","parent_msg_id":"b7904764-d7ab-40ea-9724-dc047373d135"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 497, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":495,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6676b9c9-25ef-4531-b955-7632070e9e97"},{"cell_type":"code","source":["#start by appending follow_up\n","\n","# List of columns to append from 'follow_up'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'FURefArrivalDate', \n","    'FU_RefDischargeDate', \n","    'RefProcStartDateTime', \n","    'F_AssessmentDate', \n","    'F_WarfarinDiscontinued', \n","    'F_WarfarinDiscontinuedDate', \n","    'F_WarfarinResumed', \n","    'F_WarfarinResumedDate', \n","    'F_DOACTherapyDiscontinued', \n","    'F_DOACTherapyDiscontinuedDate', \n","    'F_DOACTherapyResumed', \n","    'F_DOACTherapyResumedDate', \n","    'F_AspirinTherapyDiscontinued', \n","    'F_AspirinTherapyDiscontinuedDate', \n","    'F_AspirinTherapyResumed', \n","    'F_AspirinTherapyResumedDate', \n","    'F_P2Y12TherapyDiscontinued', \n","    'F_P2Y12TherapyDiscontinuedDate', \n","    'F_P2Y12TherapyResumed', \n","    'F_P2Y12TherapyResumedDate', \n","    'facility' \n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = follow_up[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(fmeds.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'fmeds' DataFrame\n","new_data_to_append = new_data_to_append[fmeds.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([fmeds, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":498,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:20.138883Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:21.3053994Z","execution_finish_time":"2024-03-06T17:11:21.5389881Z","parent_msg_id":"63db0df6-2c52-4ee2-96e5-517535fec22b"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 498, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":496,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4bf98c16-853e-45a8-a8f6-9929103ec50c"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoFmedsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"FURefArrivalDate\", DateType(), True),\n","    StructField(\"FU_RefDischargeDate\", DateType(), True),\n","    StructField(\"RefProcStartDateTime\", TimestampType(), True),\n","    StructField(\"F_AssessmentDate\", DateType(), True),\n","    StructField(\"F_WarfarinDiscontinued\", StringType(), True),\n","    StructField(\"F_WarfarinDiscontinuedDate\", DateType(), True),\n","    StructField(\"F_WarfarinResumed\", StringType(), True),\n","    StructField(\"F_WarfarinResumedDate\", DateType(), True),\n","    StructField(\"F_DOACTherapyDiscontinued\", StringType(), True),\n","    StructField(\"F_DOACTherapyDiscontinuedDate\", DateType(), True),\n","    StructField(\"F_DOACTherapyResumed\", StringType(), True),\n","    StructField(\"F_DOACTherapyResumedDate\", DateType(), True),\n","    StructField(\"F_AspirinTherapyDiscontinued\", StringType(), True),\n","    StructField(\"F_AspirinTherapyDiscontinuedDate\", DateType(), True),\n","    StructField(\"F_AspirinTherapyResumed\", StringType(), True),\n","    StructField(\"F_AspirinTherapyResumedDate\", DateType(), True),\n","    StructField(\"F_P2Y12TherapyDiscontinued\", StringType(), True),\n","    StructField(\"F_P2Y12TherapyDiscontinuedDate\", DateType(), True),\n","    StructField(\"F_P2Y12TherapyResumed\", StringType(), True),\n","    StructField(\"F_P2Y12TherapyResumedDate\", DateType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True)\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","laao_fmeds_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","laao_fmeds_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_fmeds\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":499,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:20.6285876Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:21.8605974Z","execution_finish_time":"2024-03-06T17:11:24.2336249Z","parent_msg_id":"a2cce100-fb84-477c-a63c-471109abcb3d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 499, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":497,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"00017dd2-189f-419e-bb66-69753c93f213"},{"cell_type":"markdown","source":["## FUMEDS"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cd1b44e6-54e2-4335-bb33-1bfdb468777e"},{"cell_type":"code","source":["# load FUMEDS from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FUMEDS.parquet\"\n","fumeds = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    fumeds[col] = fumeds[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","fumeds['facility'] = pd.to_numeric(fumeds['facility'])\n","\n","# Apply the function to the specified columns\n","fumeds['OtherID'] = fumeds['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        fumeds[col] = pd.to_datetime(fumeds[col], format=fmt)\n","    else:\n","        fumeds[col] = pd.to_datetime(fumeds[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":500,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:21.6398895Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:24.5319646Z","execution_finish_time":"2024-03-06T17:11:25.2663456Z","parent_msg_id":"2835b55d-3db2-4b94-b87c-48c0b2be633d"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 500, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":498,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1234f2a2-8759-47e9-a97a-ffff4de50a40"},{"cell_type":"code","source":["# load f_medid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/F_MedID.parquet\"\n","f_medid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    f_medid[col] = f_medid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","f_medid['facility'] = pd.to_numeric(f_medid['facility'])\n","\n","# Apply the function to the specified columns\n","f_medid['OtherID'] = f_medid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'ProcedureEndDateTime': '%Y-%m-%d %H:%M:%S'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        f_medid[col] = pd.to_datetime(f_medid[col], format=fmt)\n","    else:\n","        f_medid[col] = pd.to_datetime(f_medid[col])\n","\n","#rename to align with v1.4 convention\n","f_medid = f_medid.rename(columns={\n","    'Low Molecular Wt Heparin': 'Low Molecular Weight Heparin',\n","    'Other P2Y12 Inhibitor': 'Other P2Y12'\n","})\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":501,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:23.2256304Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:25.5924202Z","execution_finish_time":"2024-03-06T17:11:25.8261314Z","parent_msg_id":"c822e4d2-2f1c-4af4-8842-cc5afdc8d7cf"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 501, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":499,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1e9d487d-0f82-4aa5-b182-974fe451d328"},{"cell_type":"code","source":["# Step 1: Melting the DataFrame to create 'F_MedID' & 'F_MedAdmin2'\n","melted_df = pd.melt(f_medid, \n","                    id_vars=['NCDRPatientID', 'LastName', 'FirstName', 'MidName', 'OtherID',\n","                    'FURefArrivalDate', 'FU_RefDischargeDate', 'F_AssessmentDate', 'facility', \n","                    'RefProcStartDateTime', 'ProcedureEndDateTime', 'Dose', 'Pat_ID'], \n","                    value_vars=['Aggrenox', 'Aspirin (81 mg)', 'Aspirin (325 mg)', 'Aspirin', 'Dose',\n","                    'Aspirin/Dipyridamole', 'Durlaza', 'Vorapaxar', 'Cangrelor',\n","                    'Clopidogrel', 'Prasugrel', 'Ticlopidine', 'Ticagrelor',\n","                    'Other P2Y12', 'Warfarin', 'Apixaban', 'Dabigatran',\n","                    'Rivaroxaban', 'Edoxaban', 'Unfractionated Heparin', 'Fondaparinux',\n","                    'Low Molecular Weight Heparin', 'Heparin Derivative'], \n","                    var_name='F_MedID', value_name='F_MedAdmin2')\n","\n","#Step 2: Create F_MedDose2\n","# Using a lambda function to check if 'Aspirin' is in 'F_MedID', then clean up the text\n","melted_df['F_MedDose2'] = melted_df.apply(\n","    lambda row: re.sub(r'\\(|\\)', '', row['F_MedID']) \n","    if 'Aspirin' in row['F_MedID'] \n","    and pd.notna(row['F_MedAdmin2']) \n","    and 'Yes' in str(row['F_MedAdmin2']) \n","    and '(' in row['F_MedID'] and ')' in row['F_MedID']  # Check for both parentheses\n","    else np.nan, \n","    axis=1\n",")\n","\n","# Step for updating F_MedID for Aspirin entries\n","melted_df['F_MedID'] = melted_df.apply(\n","    lambda x: 'Aspirin' if 'Aspirin (' in x['F_MedID'] else x['F_MedID'], axis=1\n",")\n","\n","# Replace \"blank\" values with NaN\n","melted_df.replace('', np.nan, inplace=True)  # Replace empty strings with np.nan\n","melted_df.replace(' ', np.nan, inplace=True)  # Replace spaces with np.nan if necessary\n","\n","# Drop rows where 'F_MedAdmin2' is now NaN after replacements\n","melted_df = melted_df.dropna(subset=['F_MedAdmin2'])\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":502,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:25.4586187Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:26.1227918Z","execution_finish_time":"2024-03-06T17:11:30.8863987Z","parent_msg_id":"5f2fa0f8-646a-4c13-9602-3e486253c3fa"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 502, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":500,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"f51289c3-a7fb-4782-a104-84d2d95d89cb"},{"cell_type":"code","source":["#start by appending melted_df\n","\n","# List of columns to append from 'melted_df'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'FURefArrivalDate', \n","    'FU_RefDischargeDate', \n","    'RefProcStartDateTime', \n","    'F_AssessmentDate', \n","    'F_MedID', \n","    'F_MedAdmin2', \n","    'F_MedDose2', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = melted_df[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(fumeds.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'fumeds' DataFrame\n","new_data_to_append = new_data_to_append[fumeds.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([fumeds, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":503,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:27.5809012Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:31.2347825Z","execution_finish_time":"2024-03-06T17:11:31.4552744Z","parent_msg_id":"030b5042-9276-4488-8b31-47a5b2a09393"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 503, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":501,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5b6ec926-fc93-44d8-932a-52bce3442bd1"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType\n","\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"LaaoFumedsIngestion\").getOrCreate()\n","\n","# Define the schema explicitly for the laao_fumeds table\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"FURefArrivalDate\", DateType(), True),\n","    StructField(\"FU_RefDischargeDate\", DateType(), True),\n","    StructField(\"RefProcStartDateTime\", TimestampType(), True),\n","    StructField(\"F_AssessmentDate\", DateType(), True),\n","    StructField(\"F_MedID\", StringType(), True),\n","    StructField(\"F_MedAdmin2\", StringType(), True),\n","    StructField(\"F_MedDose2\", StringType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_fumeds\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":504,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:30.3775107Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:31.7496362Z","execution_finish_time":"2024-03-06T17:11:36.593079Z","parent_msg_id":"3b8c5114-25c9-4c4e-ba8f-68d0d68fe39f"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 504, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":502,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"79bc6afc-9fe8-4702-be33-bf88137750cb"},{"cell_type":"markdown","source":["## FUEVENTS"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9b511f7d-98f0-4918-981c-27d952bea8da"},{"cell_type":"code","source":["# load fuevents from v1.4\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_4/Merged/FUEVENTS.parquet\"\n","fuevents = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    fuevents[col] = fuevents[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","fuevents['facility'] = pd.to_numeric(fuevents['facility'])\n","\n","# Apply the function to the specified columns\n","fuevents['OtherID'] = fuevents['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'FupEventDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        fuevents[col] = pd.to_datetime(fuevents[col], format=fmt)\n","    else:\n","        fuevents[col] = pd.to_datetime(fuevents[col])\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":505,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:31.1092829Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:36.9254812Z","execution_finish_time":"2024-03-06T17:11:37.6881921Z","parent_msg_id":"3affbcfe-6adf-412b-9ff4-36e8574efd0b"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 505, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":503,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"abee4315-c2b8-40ce-a2b3-cf5b5d69c6bf"},{"cell_type":"code","source":["# load f_eventid from v1.3\n","# Load data into pandas DataFrame from Parquet\n","file_path = \"/lakehouse/default/Files/LAAO/Version_1_3/Merged/F_EventID.parquet\"\n","f_eventid = pd.read_parquet(file_path)\n","\n","# Ensure specified columns are treated as strings\n","for col in ['OtherID', 'NCDRPatientID']:\n","    f_eventid[col] = f_eventid[col].astype(str)\n","\n","# Function to remove '.0' from string representations of numbers\n","def remove_decimal_point(value):\n","    if isinstance(value, str) and value.endswith('.0'):\n","        return value[:-2]  # Remove the last two characters '.0'\n","    return value\n","\n","# Convert 'facility' to int\n","f_eventid['facility'] = pd.to_numeric(f_eventid['facility'])\n","\n","# Apply the function to the specified columns\n","f_eventid['OtherID'] = f_eventid['OtherID'].apply(remove_decimal_point)\n","\n","# Convert date columns to datetime format\n","date_columns = {\n","    'FURefArrivalDate': '%Y-%m-%d',\n","    'FU_RefDischargeDate': '%Y-%m-%d',\n","    'RefProcStartDateTime':'%Y-%m-%d %H:%M:%S',\n","    'F_AssessmentDate':'%Y-%m-%d',\n","    'FupEventDate': '%Y-%m-%d'\n","}\n","\n","for col, fmt in date_columns.items():\n","    if fmt:\n","        f_eventid[col] = pd.to_datetime(f_eventid[col], format=fmt)\n","    else:\n","        f_eventid[col] = pd.to_datetime(f_eventid[col])\n","\n","\n","print(\"Success\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":506,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:31.5981776Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:38.000948Z","execution_finish_time":"2024-03-06T17:11:38.2239535Z","parent_msg_id":"4133d8e4-cb19-417e-a8e5-431fdc882baf"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 506, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":504,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0a7349ab-ff96-449d-91aa-13fc73461dc9"},{"cell_type":"code","source":["#start by appending f_eventid\n","\n","# List of columns to append from 'f_eventid'\n","columns_to_append = [\n","    'Pat_ID',\n","    'NCDRPatientID', \n","    'LastName', \n","    'FirstName', \n","    'MidName', \n","    'OtherID', \n","    'FURefArrivalDate', \n","    'FU_RefDischargeDate', \n","    'RefProcStartDateTime', \n","    'F_AssessmentDate', \n","    'F_Event', \n","    'FupEvOccurred', \n","    'FupEventDate', \n","    'facility'\n","]\n","\n","# Create a new DataFrame with only the specified columns\n","new_data_to_append = f_eventid[columns_to_append].copy()\n","\n","# Make sure that all other columns are filled with NaN\n","additional_columns = set(fuevents.columns) - set(new_data_to_append.columns)\n","for column in additional_columns:\n","    new_data_to_append[column] = np.nan\n","\n","# Reorder the columns in the new data to match the 'fuevents' DataFrame\n","new_data_to_append = new_data_to_append[fuevents.columns]\n","\n","# Use concat instead of append\n","combined_df = pd.concat([fuevents, new_data_to_append], ignore_index=True)\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":507,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:32.7086202Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:38.5201069Z","execution_finish_time":"2024-03-06T17:11:38.7306388Z","parent_msg_id":"1ceb09a2-9cf2-4406-af6c-99b7e7373af0"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 507, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":505,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"422336b3-92be-44fc-9e4a-019c1fe7887d"},{"cell_type":"code","source":["# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"IngestionIntoDeltaTable\").getOrCreate()\n","\n","# Define the schema explicitly for laao_fuevents\n","schema = StructType([\n","    StructField(\"NCDRPatientID\", StringType(), True),\n","    StructField(\"LastName\", StringType(), True),\n","    StructField(\"FirstName\", StringType(), True),\n","    StructField(\"MidName\", StringType(), True),\n","    StructField(\"OtherID\", StringType(), True),\n","    StructField(\"FURefArrivalDate\", DateType(), True),\n","    StructField(\"FU_RefDischargeDate\", DateType(), True),\n","    StructField(\"RefProcStartDateTime\", TimestampType(), True),\n","    StructField(\"F_AssessmentDate\", DateType(), True),\n","    StructField(\"F_Event\", StringType(), True),\n","    StructField(\"FupEvOccurred\", StringType(), True),\n","    StructField(\"FupEventDate\", DateType(), True),\n","    StructField(\"facility\", IntegerType(), True),\n","    StructField(\"Pat_ID\", StringType(), True),\n","])\n","\n","# Convert the pandas DataFrame to a Spark DataFrame with the defined schema\n","spark_df = spark.createDataFrame(combined_df, schema=schema)\n","\n","# Write the DataFrame to the Delta table\n","spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://918a39aa-48f9-4458-8609-67a29814b9c8@onelake.dfs.fabric.microsoft.com/83d6ecf5-3497-4c8f-9baf-192fa2d057ab/Tables/laao_fuevents\")\n","\n","print('Success')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"981f704b-223d-4977-ab99-9eb6122ab346","statement_id":508,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-06T17:11:34.4988374Z","session_start_time":null,"execution_start_time":"2024-03-06T17:11:39.0242952Z","execution_finish_time":"2024-03-06T17:11:42.4682533Z","parent_msg_id":"44049f99-2977-4a1d-bd25-a791c9b46c17"},"text/plain":"StatementMeta(, 981f704b-223d-4977-ab99-9eb6122ab346, 508, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Success\n"]}],"execution_count":506,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8c6fd42d-e111-4e25-b6d4-ec6e828d8905"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"83d6ecf5-3497-4c8f-9baf-192fa2d057ab","default_lakehouse_name":"Registries","default_lakehouse_workspace_id":"918a39aa-48f9-4458-8609-67a29814b9c8"}}},"nbformat":4,"nbformat_minor":5}